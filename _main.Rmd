--- 
title: "Alaskan sablefish research"
author: "C.Marsh"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
includes:
 before_body: preamble-mathjax.tex
#url: https:///r4Casal2/
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This Gitbook documents my post-doctoral research relating to Alaskan sablefish.
link-citations: yes

---

# Overview

This Gitbook documents my/our research for the Alaska sablefish (*Anoplopoma fimbria*). The objective is to develop and explore a spatially explicit stock assessment for Alaskan sablefish. However, there will be many other topics that I will likely only scratch the surface on. The following outlines the chapters in this document


## Future things to consider {-}
 
- How to reduce partition dimension when adding tag-release events
- When is the latest you can start the model? Currently the assessment model starts in 1960 because there is early survey and catch info along with some of the largest catches observed over the fishery. I want to explore starting the model at later period i.e., 1990's when start getting consistent survey data. This is a possible way to reduce the number of estimated parameters that have low information, however you may loose some information on production if you miss some of the periods with the largest catches.



## chapter overview  {-}
- Chapter \@ref(objectives) is a list of objectives that we have set or accomplished during this research project. Some of our research cannot be in this book/repo due to the confidential nature of the data. This checklist should include tasks for the wider research

- Chapter \@ref(modeldescription) documents the current stock assessment model and assumptions (work in progress). This first is the first step of the project and helps me get a grasp of data and dynamics that are important

- Chapter \@ref(spatialmodeldescription) documents the spatial stock assessment model used to explore spatially explicit models.


- Chapter \@ref(sexratios) explores how to include sex disaggregated composition observations that can include sex ratio information. It conducts a simple simulation to investigate two different approaches than what is currently done in the assessment


- Chapter \@ref(Fexplore) explores how to parameterise fishing mortality. The current approach is to estimate an annual fishing mortality parameter for each gear. I feel slightly uncomfortable about this approach moving towards a spatial model as the number of estimated parameters will explode. This chapter looks at two alternative approaches that either derive fishing mortality estimates using a Newton Raphson solver which is borrowed from the Stock Synthesis "hybrid" approach [@methot2013stock] and Pope's discrete approach [@pope1972investigation] which uses exploitation rates. All of these methods have been applied in the literature for decades. The aim of this chapter is to do a simulation and make sure the considered approaches are efficient and numerically stability under a range of fishing patterns


- Chapter \@ref(spatialInit) explores how to calculate the plus group in spatially explicit age-structured models which assume markovian movement.



- Chapter \@ref(tagdata) describes the tagging data and how it can be used within a spatial model but also used in a panmictic model for informing population dynamics such as growth.






```{r install_packages, results = 'hide', message=FALSE, warning=FALSE}
library(TMB)
#library(stockassessmenthelper)
library(ggplot2)
library(dplyr)
library(reshape2)
library(gridExtra)
library(knitr)
library(RColorBrewer)
```

```{r auxillary_functions,echo = F,eval =T, results = 'hide', message=FALSE, warning=FALSE}
#' vonbert applies the Von Bertalanffy age-length relationship
#' @param age take an age look in globe scope for the rest of parameters
#' @param L_inf asympototic length
#' @param K growth rate parameter
#' @param t0 age for length = 0
#' @export
#' @return mean length at age
vonbert <- function(age,K,L_inf,t0) {
  return(L_inf * (1-exp(-K*(age -t0))))
}
#'
#' richards_growth provides the mean length at a give age
#' @param age true age
#' @param p is the shape parameter
#' @param k is the growth coefficient
#' @param l_inf is the asymptotic length
#' @param t_0 corresponds to an inflexion point on the curve.
#' @return mean length at age
#'
richards_growth = function(age, p, k, t_0, l_inf) {
  mean_length = l_inf * (1 + 1 / p * exp(-k * (age - t_0)))^-p
}
#' create a function for simulating starting values for model robustness
#' @param n <integer> number of draws you want
#' @param dist <string> distribution to use to draw starting values, allowed "unif", "norm" 
#' @param LB <scalar> Lower bound of starting value, shouldn't use lower bound of parameter
#' @param UB <scalar> Upper Bound of starting balues.
#' @param dist_pars <vector> has distributional parameters, i.e for norm = c(mu, sigma)
#' @return vector of starting values
ran_start = function(n = 100, dist = "unif", LB = -Inf, UB = Inf, dist_pars = NULL) {
  if (!any(dist %in% c("unif", "norm")))
    stop("parameter 'dist', needs to be either unif or norm")
  start_vals = vector();
  if (dist == "unif") {
    start_vals = runif(n, LB, UB)
  } else if (dist == "norm") {
    start_vals = rnorm(n, dist_pars[1],dist_pars[2])
    start_vals[start_vals < LB] = LB
    start_vals[start_vals > UB] = UB
    
  } else {
    stop("something went wrong")
  }
  return(start_vals)
}

#' Logistic selectivity
#' @export
logis<- function(X,a50,a95)
{
  1/(1+19^((a50-X)/a95)) 
}

#' bound_unit constrains Y from -inf -> inf to be between -1 -> 1 
#' @param Y scalar range [-inf, inf]
#' @return X to be between [-1,1] 
bound_unit = function(Y) {
  return(Y / sqrt(1.0 + Y * Y))
}

#' inv_bound_unit constrains Y from -inf -> inf to be between -1 -> 1 
#' @param X scalar range [-1,1] 
#' @return Y to be between [-inf, inf]
inv_bound_unit = function(X) {
  return(sqrt((X*X) / (1 - X*X)) * ifelse(X < 0, -1, 1))
}
#' logit bounds X which is between 0-1 to -inf -> inf based on the logit transformation
#' equivalent to qlogis(X)
#' @param X scalar range [0,1]
#' @return Y to be between [-inf, inf]
logit = function(X) {
  log(X / (1 - X)) 
}
#' invlogit Inverse logit transformation, equivalent to plogis(Y)
#' @param Y scalar between [-inf, inf] 
#' @return X between [0,1]
invlogit<- function(Y) {
  1/(1 + exp(-Y))
}
#' logit_general bounds X which is between [lb,ub] to -inf -> inf based on the logit transformation
#' @param X scalar range [lb,ub]
#' @param ub upper bound for X
#' @param lb lower bound for X
#' @return Y to be between [-inf, inf]
logit_general = function(X, lb, ub) {
  X1 = (X - lb) / (ub - lb)
  log(X1/(1 - X1))
}


simplex <- function (xk, sum_to_one = TRUE)  {
  zk = vector()
  if (!sum_to_one) {
    xk = xk/sum(xk)
  }
  else {
    if (abs(sum(xk) - 1) > 0.001) 
      stop("xk needs to sum = 1, otherwise speify sum_to_one = TRUE")
  }
  K = length(xk)
  zk[1] = xk[1]/(1)
  for (k in 2:(K - 1)) {
    zk[k] = xk[k]/(1 - sum(xk[1:(k - 1)]))
  }
  yk = stats::qlogis(zk) - log(1/(K - 1:(K - 1)))
  return(yk)
}
restoresimplex <- function (yk) {
  K = length(yk) + 1
  zk = stats::plogis(yk + log(1/(K - 1:(K - 1))))
  xk = vector()
  xk[1] = zk[1]
  for (k in 2:(K - 1)) {
    xk[k] = (1 - sum(xk[1:(k - 1)])) * zk[k]
  }
  xk[K] = 1 - sum(xk)
  return(xk)
}


#' invlogit_general bounds X which is between -inf -> inf to [lb,ub] based on the logit transformation
#' @param Y scalar range [-inf, inf]
#' @param ub upper bound for X
#' @param lb lower bound for X
#' @return X to be between [lb,ub]
invlogit_general = function(Y, lb, ub) {
  Y1 = 1 / (1 + exp(-Y))
  lb + (ub - lb)*Y1
}
#' fix_pars 
#' @author C.Marsh
#' @description TMB helper function this function returns a list of factors used in the map argument of the MakeADFun function
#' values with <NA> will not be estimated.
#' @param par_list a named list that you give to the par argument in the MakeADFun
#' @param pars_to_exclude a vector of strings with names of parameters you want to FIX in the objective object.
#' @param vec_elements_to_exclude a named list (names %in% pars_to_exclude) with number of elements = length(vec_pars_to_adjust). each list element 
#' @param array_elements_to_exclude a named list (names %in% pars_to_exclude) with a matrix each row corresponds to an element with the first column being the array row index and second column being the array column index to fix

#' contains a vector of elements that we want to exclude from estimation.
#' @return a list of factors used in the MakeADFun function
#' @export
fix_pars <- function(par_list, pars_to_exclude, vec_elements_to_exclude = NULL, array_elements_to_exclude = NULL) {
  if (!any(pars_to_exclude %in% names(par_list))) {
    stop(paste0("The parameters ", paste(pars_to_exclude[!pars_to_exclude %in% names(par_list)],collapse = " ")," in exclusion parameters could not be found in the 'par_list', please sort this out"))
  }
  pars = names(par_list)
  mapped_pars = list();
  if (!is.null(vec_elements_to_exclude)) {
    if (!all(names(vec_elements_to_exclude) %in% pars_to_exclude))
      stop("parameters names in vec_elements_to_exclude, need to also be in pars_to_exclude")
  }
  if (!is.null(array_elements_to_exclude)) {
    if (!all(names(array_elements_to_exclude) %in% pars_to_exclude))
      stop("parameters names in array_elements_to_exclude, need to also be in pars_to_exclude")
  }
  param_factor = 1;
  for(i in 1:length(pars)) {
    if (pars[i] %in% pars_to_exclude) {
      params_in_this_par = par_list[[pars[i]]];
      if (pars[i] %in% names(vec_elements_to_exclude)) {
        include_element_index = c(1:length(params_in_this_par))[-vec_elements_to_exclude[[pars[i]]]]
        params_vals = factor(rep(NA, length(params_in_this_par)), levels = factor(param_factor:(param_factor + length(include_element_index) - 1)))
        params_vals[include_element_index] = factor(param_factor:(param_factor + length(include_element_index) - 1))#, levels = factor(include_element_index))
        param_factor = param_factor + length(include_element_index)
        mapped_pars[[pars[i]]] = params_vals;
      } else if(pars[i] %in% names(array_elements_to_exclude)) {
        elements_to_drop = array_elements_to_exclude[[pars[i]]]
        mapped_vector = rep(NA, length(params_in_this_par))
        first_param_factor = param_factor
        vec_ndx = 1;
        ## TMB converts arrays to vectors down columns (not by rows)
        for(col_ndx in 1:ncol(params_in_this_par)) {
          for(row_ndx in 1:nrow(params_in_this_par)) {
            ## check if we need to drop this value
            for(drop_ndx in 1:nrow(elements_to_drop)) {
              if(!((row_ndx == elements_to_drop[drop_ndx, 1]) &  (col_ndx == elements_to_drop[drop_ndx, 2]))) {
                mapped_vector[vec_ndx] = param_factor
                param_factor = param_factor + 1
              }
            }
            vec_ndx = vec_ndx + 1;
          }
        }
        mapped_vector = factor(mapped_vector, levels = first_param_factor:max(mapped_vector, na.rm = T))
        mapped_pars[[pars[i]]] = mapped_vector;
      } else {
        ## exclude entire parameters
        mapped_pars[[pars[i]]] = rep(factor(NA),length(params_in_this_par));
        n_params_to_exclude = nrow(vec_elements_to_exclude[[pars[i]]])
      }
    } else {
      params_in_this_par = par_list[[pars[i]]];
      params_vals = factor(param_factor:(param_factor + length(params_in_this_par) - 1))
      param_factor = param_factor + length(params_in_this_par)
      mapped_pars[[pars[i]]] = params_vals
    }
  }
  return(mapped_pars);
}


#' set_pars_to_be_the_same 
#' @author C.Marsh
#' @description TMB helper function this function returns a list of factors used in the map argument of the MakeADFun function
#' values with the same factor level will be estimated as the same value
#' @details TMB will estimate parameters based on the index specified in by the map argument in MakeADFun
#' so parameters with the same factor in map will be estimated as the same value.
#' NOTE: this only works for within the same parameter. It doesn't work across parameters.
#' @param par_list a named list that you give to the par argument in the MakeADFun
#' @param map a list of factors that has been created by fix_pars(). parameters that you want fixed to other values should be set to <NA> in this object
#' @param base_parameters a named list (names) each element contains one index that will be used to set the value in copy_parameters
#' @param copy_parameters a named list (names) each element contains one index that will be set equal to the corresponding base_parameters
#' @return a list of factors used in the MakeADFun function
#' @export
set_pars_to_be_the_same <- function(par_list, map, base_parameters, copy_parameters) {
  if(length(base_parameters) != length(copy_parameters))
    stop("the number of elements in base_parameters must be the same as copy_parameters. Please check these")
  if(!class(map) == "list")
    stop("map needs to be a list")
  if(!any(names(base_parameters) %in% names(par_list)))
    stop(!paste0("The parameters in base_parameters ", paste(names(base_parameters)[!names(base_parameters) %in% names(par_list)],collapse = " ")," could not be found in the 'par_list', please sort this out"))
  if(!any(names(copy_parameters) %in% names(par_list)))
    stop(!paste0("The parameters in copy_parameters ", paste(names(copy_parameters)[!names(copy_parameters) %in% names(par_list)],collapse = " ")," could not be found in the 'par_list', please sort this out"))
  pars = names(par_list)
  
  for(i in 1:length(base_parameters)) {
    if(is.na(map[[names(base_parameters)[i]]][base_parameters[[i]]]))
      stop(paste0("In base_parameters for parameter ", names(base_parameters)[i], " at ndx ", base_parameters[[i]], ". We found an NA. This cannot be, please check"))
    if(!is.na(map[[names(copy_parameters)[i]]][copy_parameters[[i]]]))
      stop(paste0("In copy_parameters for parameter ", names(base_parameters)[i], " at ndx ", base_parameters[[i]], ". Was not an NA. This must be an NA value in 'map', please check"))

    temp_copy_parm = map[[names(copy_parameters)[i]]]
    temp_copy_parm = as.numeric(as.character(temp_copy_parm))
    base_value = as.numeric(as.character(map[[names(base_parameters)[i]]][base_parameters[[i]]]))
    temp_copy_parm[copy_parameters[[i]]] = base_value
    lvls = unique(temp_copy_parm[!is.na(temp_copy_parm)])
    map[[names(copy_parameters)[i]]] = factor(temp_copy_parm, levels = lvls)
  }
  
  return(map);
}

#' get_list_obj gets names objects out of simulated TMB reports.
#' @param est_ls a list of length n_sims
#' @param object_label a charachter that points to a name of an element of the TMB report
#' @return a matrix 

get_list_obj = function(est_ls, object_label) {
  val = Reduce(rbind, lapply(X = est_ls, FUN = function(x){
    temp = x[[object_label]]
    temp
    }))
  elements = nrow(val) / length(est_ls)
  
  cbind(sort(rep(1:length(est_ls), elements)), val)
}

```

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# A list of objectives/milestones that we have set along the project life {#objectives}


- [x]  Translate current stock assessment (Chapter \@ref(modeldescription)) from ADMB to TMB. Planned date of completion is December 1 2022
- [ ]  ~~Conduct self test using TMB stock assessment model. Planned date of completion is December 1 2022~~ I decided not to do this because the assessment had too many bespoke likelihoods
- [x]  Consider improvements i.e., sex disaggregated composition data or sex ratio observations (look at the rock lobster assessment) including age-length observations or tag-increment observations to estimate growth internally. (Chapter \@ref(sexratios))
- [ ]  Characterize both fishery and survey data to get an idea of data limitations when considering spatially explicit stock assessment model.
- [ ]  Develop a spatially explicit estimation model in TMB that generalizes the current assessment model. This requires a lot of thought, especially how we want to integrate the tagging data (Chapter \@ref(tagdata))



<!--chapter:end:01-Objectives.Rmd-->

# Current Alaskan sablefish stock assessment model {#modeldescription}
The latest published stock assessment [@goethel2021assessment] is a single area model (Chapter \@ref(modeldescription)). This chapter intends to extend this model by allowing it to be spatially disaggregated.

disaggregated integrated age-structured model. Let \(\boldsymbol{N_{y,s}}\) denote a vector of ages in year \(y\) for sex \(s\) (the partition) i.e., \(\boldsymbol{N_{y,s}} = (N_{1,y,s}, N_{2,y,s}, \dots, N_{a_+,y,s})^T\). The general process model is sequential and follows the general Equation \@ref(eq:processmodel),

\begin{equation} 
  \boldsymbol{N_{y,s}} = 
  \begin{cases}
  g\left(\boldsymbol{\theta}\right), & y = 1959 \text{ Initial model year}\\
  f\left(\boldsymbol{N_{y-1,s}}|\boldsymbol{\theta}\right), & y > 1959 \\
  \end{cases}
  (\#eq:processmodel)
\end{equation} 
where, \(g(.)\) is the function describing initial conditions for the partition and \(f(.)\) is the function that applies populations dyanmics each year i.e., birth, death, growth and migration. See Section \@ref(symbols) \& \@ref(modelequations) for a detailed description of \(g(.)\) and \(f(.)\) and \(\boldsymbol{\theta}\) is the set of estimable (not all are estimated) parameters.


Maximum Likelihood Estimates (MLE) for estimated parameters \(\widehat{\boldsymbol{\theta}}_{MLE}\) are evaluated,
\begin{equation}
	\widehat{\boldsymbol{\theta}}_{MLE} = \underset{\boldsymbol{\theta}}{\arg\max} \left( L\left(\boldsymbol{\theta} | \boldsymbol{y^{obs}}\right) \right)
	  (\#eq:observationmodel)
\end{equation}
where, \(\boldsymbol{y^{obs}}\) is a set of observations and \(L\left( . \right)\) is an objective function that is made up of priors/penalties and log-likelihood. See Section \@ref(observationsection)


## Process equations {#modelequations}

### Initialisation \left(\(g\left(.\right)\)\right) {-}
\begin{align*}
N_{a,1,s} = 
\begin{cases}
R_1, & a = a_1\\
\exp\bigg( \mu_r + \tau_{a_1 - a + 1}\bigg) \exp-\bigg( a - a_1\bigg) \bigg( M + F_{hist} * \mu_{LL} * S^{LL}_{a,1}\bigg), & a_0 < a < a_+\\
\exp( \mu_r) \exp-( a - 1) ( M + F_{hist} * \mu_{LL} * S^{LL}_{a - 1,1})(1 - \exp( M + F_{hist} * \mu_{LL} * S^{LL}_{a - 1,1}))^{-1}, &  a = a_+
\end{cases}
\end{align*}

### Population dynamics \left(\(f\left(.\right)\)\right) {-}
The assessment assumes a closed population that is only effected by mortality (natural and fishing), recruitment and growth. Mortality is applied assuming 

\[
Z_{a,y,s} = M + \sum_g F^g_{y} S^g_{a,y,s}
\]
where, \(S^g_{a,y,s}\) is the fishery selectivity and \(F^g_{y}\) is the annual estimated fishing mortality. The annual cycle follows,


\begin{align*}
N_{a,y,s} = 
\begin{cases}
p^s_{y} R_y, & a = a_1\\
N_{a - 1,y - 1,s} \times 
\exp\bigg( -Z_{a - 1,y - 1,s} \bigg), & a_0 < a < a_+\\
\exp\bigg( -Z_{a - 1,y - 1,s} \bigg) + \exp\bigg( -Z_{a,y - 1,s} \bigg), &  a = a_+
\end{cases}
\end{align*}
where,
\[
R_y = \exp\{\mu_r + \tau_y + 0.5\sigma_R^2\}
\]


### Determining selectivities for fisheries and surveys {-}
The ADMB model has a hard coded number of selectivities. Some of them relate to changes in the fishery and so represent time-varying blocks. We want to spell these out and simplify for the TMB model. There are nine selectivities labelled `fish1`, `fish2`, `fish3`, `fish4`, `fish5`, `srv1`, `srv2` and `srv10`.


+----------------------------+-----------------------------------------------------------------------------+
| label                      | Selectivity description                            
+============================+=============================================================================+
| `fish1`                    | Longline selectivity from 1960-1994
+----------------------------+-----------------------------------------------------------------------------+
| `fish2`                    | Not sure if this is used, maybe this is used for `srv6`?
+----------------------------+-----------------------------------------------------------------------------+
| `fish3`                    | Trawl selectivity from 1960 - \(T\)
+----------------------------+-----------------------------------------------------------------------------+
| `fish4`                    | Longline selectivity from 1995 -\( \ IFQ_y\) (\(IFQ_y\) can = \(T\)
+----------------------------+-----------------------------------------------------------------------------+
| `fish5`                    | Longline selectivity from \(IFQ_y \ - \ T\) if there is post IFQ block
+----------------------------+-----------------------------------------------------------------------------+
| `srv1`                     | Domestic Longline survey selectivity
+----------------------------+-----------------------------------------------------------------------------+
| `srv2`                     | Japanese Longline survey selectivity
+----------------------------+-----------------------------------------------------------------------------+


## Observation equations {#observationsection}
Three are three observational types in the current Sablefish stock assessment
- Relative abundance indices
- Age composition (aggregated over sex)
- Length composition (disaggregated by sex)

These three observation types come from both fishery dependent i.e., observer programs and CPUE and fishery independent i.e., research surveys.


### Catch at age {-}
Fishery dependent catch at age observations for gear type \(g\) denoted by \(\boldsymbol{C^g}_{a,y,s}\) are calculated as follows

\begin{equation} 
  \boldsymbol{C^g}_{a,y,s} = \frac{F^g_{a,y,s}}{Z_{a,y,s}}   N_{a,y,s} \left(1 - S_{a,y,s} \right)
  (\#eq:catchatage)
\end{equation} 
Currently all age observations are sex aggregated which means the model expected values before applying ageing error is
\[
  \boldsymbol{C^g}_{a,y} = 0.5 \sum_s \frac{\boldsymbol{C^g}_{a,y,s}}{\sum_a\boldsymbol{C^g}_{a,y,s}}
\]
why the 0.5? should be omitted going forward. Ageing error is then incorporated and the values are normalized so that they are proportions, before being passed to the multinomial log-likelihood function.



Survey age composition is similar but instead of being a function of \(F\) it is calculated at the beginning of the year. For survey \(k\) the numbers at age are denoted by \(\boldsymbol{C^k}_{a,y}\) and calculated following
\begin{equation} 
  \boldsymbol{C^k}_{a,y} = p^s N_{a,y,s} S^k_{y,a,s}
  (\#eq:surveyage)
\end{equation} 

I am not sure exactly what the timing of these surveys are, but do we need to account for som mid-year mortality? or changes in timing of the survey? if so we could easily replace 
\[
N_{a,y,s}
\]
with
\[
N_{a,y,s} \exp\{-p^k_y Z_{a,y,s}\} 
\]
where,\(p^k_y\) is the proportion of mortality that we want to account for in year \(y\) for survey \(k\).

The survey numbers at age are then adjusted for ageing error and normalised so they sum to one for each year.


### Relative abundance indices {-}
\begin{equation} 
  \widehat{I}^g_{y} = \sum_s\sum_a p^s N_{a,y,s} \exp \{-0.5 Z_{a,y,s}\} S^g_{y,a,s} \bar{w}_{a,y,s}
  (\#eq:relativeindex)
\end{equation} 
where, \(\bar{w}_{a,y,s}\) is mean weight at age, this can be omitted if the observation is in numbers i.e., abundance instead of biomass and \(p^s\) is the proportion for each sex. This is currently a user input, but should be dealt within the model either as having different sex selectivities or through the sex ratio of recruitment.

A list of slight improvements

- change how sex ratio is handled
- fishery dependent abundance indices i.e., CPUE change \(N_{a,y,s} \exp \{-0.5 Z_{a,y,s}\}\) with \(\boldsymbol{C^g}_{a,y,s}\) which is calculated in the catch at age observations.

### Catch at length {-}

For each year that has a length frequency observation, numbers at length denoted by \(\boldsymbol{C^l}_{y,s} = (C^l_{1,y,s}, \dots, C^l_{n_l,y,s})^T\) (dimension of \(\boldsymbol{C^l}_{y,s}\) is \(n_l \ \times \ 1\)) were calculated for each sex. This involved multiplying the catch at age (see above for how it is calculated) through an age-length transition matrix denoted by \(\boldsymbol{A}^l_{y,s}\) (dimensions of \(\boldsymbol{A}^l_{y,s}\) are \(n_a \ \times \ n_l\) and its rows must sum to 1). The calculation follows Equation \@ref(eq:agelengthtransition),

\begin{equation} 
  \boldsymbol{C^l}_{y,s} =  \left(\boldsymbol{A}^l_{y,s} \right)^T \ \times \ \boldsymbol{C_{y,s}}
  (\#eq:agelengthtransition)
\end{equation} 
where, \(\boldsymbol{C_{y,s}}\) is a column vector of numbers at age (dimension \(n_a \ \times \ 1\)) at the beginning of year \(y\) for sex \(s\).




### Observations for fisheries and surveys {-}

+----------------------------+-----------------------------------------------------------------------------+
| label                      | Relative Abundance description                            
+============================+=============================================================================+
| `srv1`                     | Biomass domestic longline survey uses both `srv1_sel` and `srv10_sel`
+----------------------------+-----------------------------------------------------------------------------+
| `srv3`                     | Abundance domestic longline survey uses both `srv1_sel` and `srv10_sel`
+----------------------------+-----------------------------------------------------------------------------+
| `srv2`                     | Biomass survey uses both `srv2_sel` and `srv9_sel`
+----------------------------+-----------------------------------------------------------------------------+
| `srv4`                     | Abundance survey uses both `srv2_sel` and `srv9_sel`
+----------------------------+-----------------------------------------------------------------------------+
| `srv5`                     | Longline fishery CPUE `fish1_sel`, `fish4_sel`, `fish5_sel`
+----------------------------+-----------------------------------------------------------------------------+
| `srv6`                     | Japanese LL fishery CPUE
+----------------------------+-----------------------------------------------------------------------------+
| `srv7`                     | NMFS bottom trawl survey (currently GOA only; fit in model)
+----------------------------+-----------------------------------------------------------------------------+



+----------------------------+-----------------------------------------------------------------------------+
| label                      | Composition description                            
+============================+=============================================================================+
| `ac_fish1`                 | Longline Fishery Age Comp (sex aggregated)
+----------------------------+-----------------------------------------------------------------------------+
| `sc_fish1`                 | Longline Fishery LF (sex dis-aggregrated)
+----------------------------+-----------------------------------------------------------------------------+
| `sc_fish3`                 | Trawl Fishery LF (sex disaggregrated)
+----------------------------+-----------------------------------------------------------------------------+
| `sc_fish2`                 | LF for japaneses Longline fishery (sex aggregrated) (basically a survey now)
+----------------------------+-----------------------------------------------------------------------------+
| `sc_fish4`                 | LF for japaneses Longline fishery (sex aggregrated) (basically a survey now)
+----------------------------+-----------------------------------------------------------------------------+
| `fish_size`                | LF From japaneses trawl survey? (sex aggregrated)
+----------------------------+-----------------------------------------------------------------------------+
| `ac_srv1`                  | Domestic Longline Survey AF (sex aggregated)
+----------------------------+-----------------------------------------------------------------------------+
| `sc_srv1`                  | Domestic Longline Survey LF (sex disaggregrated)
+----------------------------+-----------------------------------------------------------------------------+
| `ac_srv2`                  | Japanese Longline Survey AF (sex aggregated)
+----------------------------+-----------------------------------------------------------------------------+
| `sc_srv2`                  | Japanese Longline Survey LF (sex disaggregrated)
+----------------------------+-----------------------------------------------------------------------------+
| `ac_srv7`                  | NMFS bottom trawl survey AF (sex aggregated)
+----------------------------+-----------------------------------------------------------------------------+
| `sc_srv7`                  | NMFS bottom trawl survey LF (sex disaggregrated)
+----------------------------+-----------------------------------------------------------------------------+
## Symbol Notation {#symbols}
+----------------------------+-----------------------------------------------------------------------------+
| Symbol                     | Description                            
+============================+=============================================================================+
| \(y\)                      | Year, \(y = 1960, \dots, T\) 
+----------------------------+-----------------------------------------------------------------------------+
| \(T\)                      | Terminal year of the model
+----------------------------+-----------------------------------------------------------------------------+
| \(s\)                      | Sex index \(s \in \{1,2\}\)
+----------------------------+-----------------------------------------------------------------------------+
| \(r\)                      | Region index \(r \in \{1, \dots, n_r\}\)
+----------------------------+-----------------------------------------------------------------------------+
| \(n_r\)                    | number of modeled regions
+----------------------------+-----------------------------------------------------------------------------+
| \(a\)                      | Model age cohort, i.e., \(a = a_0, a_0 + 1, \dots\)
+----------------------------+-----------------------------------------------------------------------------+
| \(a_{1}\)                  | Recruitment age to the model = 2 
+----------------------------+-----------------------------------------------------------------------------+
| \(a_+\)                    | Plus-group age class (oldest age considered plus all older ages)
+----------------------------+-----------------------------------------------------------------------------+
| \(n_a\)                    | Number of age classes modeled \(a_+ \ - a_1\)
+----------------------------+-----------------------------------------------------------------------------+
| \(l\)                      | length class
+----------------------------+-----------------------------------------------------------------------------+
| \(n_l\)                    | Number of length classes
+----------------------------+-----------------------------------------------------------------------------+
| \(g\)                      | gear type index, i.e. longline survey, longline fishery, trawl fishery
+----------------------------+-----------------------------------------------------------------------------+
| \(x\)                      | log-likelihoos index
+----------------------------+-----------------------------------------------------------------------------+
| \(\bar{w}_{a,y, s}\)       | Average weight at age \(a\), year \(y\) and sex \(s\)
+----------------------------+-----------------------------------------------------------------------------+
| \(\phi_{a,y}\)             | Proportion of female mature by age and year
+----------------------------+-----------------------------------------------------------------------------+
| \(p^s_{y}\)                | Proportion of recruits for sex \(s\). Often assumed = 0.5
+----------------------------+-----------------------------------------------------------------------------+
| \(\ln \mu_{r}\)            | Average log-recruitment
+----------------------------+-----------------------------------------------------------------------------+
| \(\ln \mu_{f}\)            | Average log-fishing mortality
+----------------------------+-----------------------------------------------------------------------------+
| \(\phi_{y,g}\)             | annual fishing mortality deviation by gear (log space)
+----------------------------+-----------------------------------------------------------------------------+
| \(\tau_{y}\)               | annual recruitment deviation \(\sim LogNormal\left(0,\sigma_r\right)\)
+----------------------------+-----------------------------------------------------------------------------+
| \(\sigma_r\)               | Recruitment standard deviation
+----------------------------+-----------------------------------------------------------------------------+
| \(N_{a,y,s}\)              | Numbers of fish at age \(a\) in year \(y\) of sex \(s\)
+----------------------------+-----------------------------------------------------------------------------+
| \(M\)                      | Natural mortality
+----------------------------+-----------------------------------------------------------------------------+
| \(F^g_{a,y}\)              | Fishing mortality for year \(y\), age \(a\) and gear \(g\)
+----------------------------+-----------------------------------------------------------------------------+
| \(F_{hist}\)               | Historical proportion of Fishing mortality 
+----------------------------+-----------------------------------------------------------------------------+
| \(Z_{a,y}\)                | Total mortality for year \(y\), age \(a\) \(=\sum\limits_g F^g_{a,y} + M\)
+----------------------------+-----------------------------------------------------------------------------+
| \(R_{y}\)                  | Annual recruitment
+----------------------------+-----------------------------------------------------------------------------+
| \(B_{y}\)                  | Spawning biomass in year \(y\)
+----------------------------+-----------------------------------------------------------------------------+
| \(S^g_{a,y,s}\)            | Selectivity at age \(a\) for gear type \(g\) and sex \(s\)
+----------------------------+-----------------------------------------------------------------------------+
| \(a_50\)                   | age at 50\% selection for ascending limb 
+----------------------------+-----------------------------------------------------------------------------+
| \(d_50\)                   | age at 50\% selection for descending limb 
+----------------------------+-----------------------------------------------------------------------------+
| \(\delta\)                 | slope/shape parameters for different logistic curves
+----------------------------+-----------------------------------------------------------------------------+
| \(\boldsymbol{A}\)         | ageing-error matrix dimensions \(n_a \ \times \ n_a\)
+----------------------------+-----------------------------------------------------------------------------+
| \(\boldsymbol{A}^l_s\)     | age to length conversion matrix by sex. dimensions  \(n_a \ \times \ n_l\)
+----------------------------+-----------------------------------------------------------------------------+
| \(q_g\)                    | abundance index catchability coeffecient by gear
+----------------------------+-----------------------------------------------------------------------------+
| \(\lambda_x\)              | Statistical weight (penalty) for component \(x\)
+----------------------------+-----------------------------------------------------------------------------+
| \(P^g_{l,y,s}\)            | Observed proportions at length for gear \(g\) in year \(y\) and sex \(s\)
+----------------------------+-----------------------------------------------------------------------------+
| \(P^g_{a,y,s}\)            | Observed proportions at age for gear \(g\) in year \(y\) and sex \(s\)
+----------------------------+-----------------------------------------------------------------------------+
| \(\psi^g_{y}\)             | assumed sample size for gear \(g\) in year \(y\) (for multinomial likelihood)
+----------------------------+-----------------------------------------------------------------------------+
| \(n_g\)                    | Number of years that age (or length) composition is available for gear \(g\)
+----------------------------+-----------------------------------------------------------------------------+


### Inference {-}
If random effects are considered the joint probability model follows,
	\begin{equation}
	Pr\left[ \boldsymbol{y^{obs}}, \boldsymbol{u}| \boldsymbol{\theta} \right]  = Pr\left[\boldsymbol{y^{obs}} |\boldsymbol{\theta^f}, \boldsymbol{u} \right] Pr\left[\boldsymbol{u} |\boldsymbol{\theta^h} \right] 
	\end{equation}

Inference is conducted by maximising the marginal likelihood noting \( L\left(\boldsymbol{\theta} | \boldsymbol{y^{obs}} \right) \propto Pr\left[ \boldsymbol{y^{obs}} | \boldsymbol{\theta} \right]\)
	\begin{equation}\label{eq:marginal_ll}
	L\left(\boldsymbol{\theta} | \boldsymbol{y^{obs}}\right) = \int \left(Pr\left[\boldsymbol{y^{obs}} |\boldsymbol{\theta^f}, \boldsymbol{\theta^g}, \boldsymbol{u} \right] Pr\left[\boldsymbol{u} |\boldsymbol{\theta^h} \right] \right) \boldsymbol{du}
	\end{equation}
In general this integral is not tractable, and so approximations are necessary. The software used here implement the Laplace approximation, which relies on Gaussian assumptions.

Maximum Likelihood Estimates (MLE) for fixed effect parameters \(\widehat{\boldsymbol{\theta}}_{MLE}\) are evaluated,
\begin{equation}
	\widehat{\boldsymbol{\theta}}_{MLE} = \underset{\boldsymbol{\theta}}{\arg\max} \left( L\left(\boldsymbol{\theta} | \boldsymbol{y^{obs}}\right) \right)
\end{equation}

and Empirical Bayes estimates are evaluated for \(\widehat{\boldsymbol{u}}\), which are used model diagnostics and other model quantities,
\begin{equation}
\widehat{\boldsymbol{u}} = \underset{\boldsymbol{u}}{\arg\max} \left( Pr\left[ \boldsymbol{y^{obs}}, \boldsymbol{u}| \widehat{\boldsymbol{\theta}}_{MLE} \right] \right)
\end{equation}


### TODO {-}
- Build a validate function to help catch users setting up parameters or data structures that will cause a crash once supplied to TMB.
- Self test
- change some parameter containers. In the ADMB model the often share parameters between male and females. Particularly for selectivity parameters. However TMB will not allow us to fix/map parameters across different arrays or vectors. This means we will want to join the male and female selectivity parameter objects into a single object so that we can share parameters between the sexes.
- Change array column casting from `vector<Type>(array.col(i))` to `array.col(i).vec()`

<!--chapter:end:02-CurrentAssessmentModel.Rmd-->

# Spatial stock assessment model for Alaskan sablefish {#spatialmodeldescription}
The latest published stock assessment [@goethel2021assessment] is a sexually disaggregated integrated age-structured model. Let \(\boldsymbol{N_{r,y,s}}\) denote a vector of ages in year \(y\) sex \(s\) in region \(r\) (the partition) i.e., \(\boldsymbol{N_{r,y,s}} = (N_{1,r,y,s}, N_{2,r,y,s}, \dots, N_{a_+,r,y,s})^T\). 


## Process equations {#spatialmodelequations}


### Initialisation \left(\(g\left(.\right)\)\right) {-}

\begin{align*}
N_{a,r,1,s} = 
\begin{cases}
R_r 0.5, & a = a_1\\
N_{a - 1,r,1,s} \exp\bigg( - (M + F_{hist} * S^{LL}_{a,1})\bigg), & a_0 < a < a_+\\
\exp( \mu_r) \exp-( a - 1) ( M + F_{hist} * S^{LL}_{a - 1,1})(1 - \exp( M + F_{hist}* S^{LL}_{a - 1,1}))^{-1}, &  a = a_+
\end{cases}
\end{align*}
The plus group

### Population dynamics \left(\(f\left(.\right)\)\right) {-}



### To DO {-}

- simulation test a spatial model with three areas no tagging data and equilibrium initial conditions

### Appendix {-}



<!--chapter:end:03-SpatialAssessmentModel.Rmd-->

# Sex ratios in age and length composition data {#sexratios}

An immediate improvement in the current stock assessment (Chapter \@ref(modeldescription)) relates to how sexually disaggregated compositional data are handled. Currently LF's are separated by sex (needed for the different growths) and age compositional data are aggregated over both sexes. Although LFs are disaggregated by sex and should (in theory) be sufficient to estimate sex specific selectivities. It is not ideal to use LFs to estimate age-based selectivities because older cohorts "smush" into single modes and age information is lost.


Before developing a spatially explicit model stock assessment model, I wanted to tidy some loose ends that may come back and bite me in the proverbial butt once we explore the spatially sex disaggregated stock assessment model in anger. These things are exponentially more easier to deal with in "simpler" models. My general intention is to drop length data when we have well sampled age data, currently they both go into the model together. For age composition data I want to structure the observations so that there is potential information on sex ratio. The current assessment can be given information on sex ratio for generating model predicted values which is similar to the approach in @ward2019assessing. Howver, I personally think this should be dealt within the model.


I am aware of two approaches for supplying observations that in theory should provide information on sex ratio. The first ("Approach 1") was taken from Casal2 [@doonan2016casal2]. This treats sexed composition data for a year as a single proportion i.e., proportions across all ages and sexes sum to one for each year,

\[
\boldsymbol{P}^k_{y} = \frac{(C^k_{a,y,1},C^k_{a,y,2})}{\sum_a \sum_s C^k_{a,y,s}}, \quad \sum \boldsymbol{P}^k_{y} = 1
\]
where, \(C^k_{a,y,1}\) is the catch at age (numbers) for males in year \(y\), age \(a\) and survey \(k\). \(\boldsymbol{P}^k_{y}\) is a proportion vector that sums to one that covers both sexes and corresponding ages. The likelihood contribution for this approach follows  
\[
\boldsymbol{P}^k_{y} \sim Multinomial(\mathbb{E}[\boldsymbol{P}^k_{y}], N^{eff, k}_{y}) \ .
\]
where, \(N^{eff, k}_{y}\) is the effective sample size for this survey and year.


The second approach ("Approach 2") is to treat composition for each sex seperately that is proportions at age or length for a sex will sum to one, but also provide a specific sex ratio observation over all ages or lengths as done in the New Zealand rock lobster stock assessment [@webber2021rapid]. 

\[
R^k_{y,s} = \frac{\sum_a C^k_{a,y,s}}{\sum_a \sum_s C^k_{a,y,s}}, \quad  \sum_s R^k_{y,s} = 1
\]
and,
\[
P^k_{a, y,s} = \frac{C^k_{a,y,s}}{\sum_a C^k_{a,y,s}}, \quad  \sum_a P^k_{a, y,s} = 1 \ .
\]
The likelihood assumptions for this model are,
\[
R^k_{y,s} \sim Binomial(\mathbb{E}[R^k_{y,s}], \sum_s N^{eff, k}_{y,s})
\]
and,
\[
\boldsymbol{P}^k_{y,s} \sim Multinomial(\mathbb{E}[\boldsymbol{P}^k_{a, y,s}], N^{eff, k}_{y,s}) \ .
\]
where, \(N^{eff, k}_{y,s}\) is the effective sample size.


## A simple simulation {#sexSimulation}
To explore the utility of these two approaches we conducted a simple simulation using a sexually disaggregated age-structured model (see Section \@ref(sexSimulation)). The Operating Model (OM) used in the simulation assumed a 50:50 sex ratio during the recruitment process however the OM did assume different growth and selectivity among the sexes.

### Results
In summary both approaches resulted in similar estimates in selectivities and SSBs. I prefer Approach 1 as it is a single observation compared with Approach 2 which has two observation types (need to consider how to avoid double counting of samples), but this simulation showed at least within the very small assumptions explored here they resulted in similar performance. This was all I was after in order to move forward to the spatial model.


Another consideration about "Approach 2" is if the selectivity shape differs between sexes i.e., lower age at 50\% retention. Then due to the sex ratio being derived by summing numbers over all ages, and the natural exponential decay in successive age-cohorts, selectivities that capture more younger fish will result in higher sex ratios. "Approach 1"

### Future research that was not considered in this simple simulation {-}
- LF observations with sexual dimorphism in growth. A possible reason LF's could be influencing assessment output is due to mis-specified growth à la @minte2017get 
- Sample size between the two approaches
- Actual sex ratio skewed in the recruitment process, rather than just a selectivity effect which was of focus in the following simulation
- Look at the effect on \(F\)'s I only summarised SSB and selectivities
- Look at some residuals to see if that is a way to discredit some of these models
### Operating Model (OM) Parameters 

```{r setup}
set.seed(123)
n_sims = 5

bio_params = list(
  ages = 1:20,
  L_inf_m = 58,
  K_m = 0.133,
  t0_m = 0,
  L_inf_f = 62,
  K_f = 0.143,
  t0_f = 0,
  M = 0.15,
  a_m = 2.18e-9, ## tonnes
  b_m = 3.2,
  a_f = 2.08e-9, ## tonnes
  b_f = 3.3,
  m_a50 = 2.3,
  m_ato95 = 1.2,
  sigma = 0.6,
  h = 0.85,
  sigma_r = 0.6,
  R0 = 8234132,
  plus_group = 1 # 0 = No, 1 = Yes
)

other_params = list(
  s_a50_m = 3.6,
  s_ato95_m = 2,
  s_a50_f = 4.6,
  s_ato95_f = 1.4,
  s_q = 0.2,
  s_alpha = 1,
  f_a50_m = 4.2,
  f_ato95_m = 1.17,
  f_a50_f = 4.7,
  f_ato95_f = 1.76,
  f_alpha = 1,
  ssb_prop_Z = 0.5,
  survey_prop_Z = 0.5,
  survey_age_error = c(0.5, 0.4),  ## sd, rho (ignored if iid)
  fishery_age_error = c(0.5, 0.4),  ## sd, rho (ignored if iid)
  survey_bio_cv = c(0.1)
)

ages = bio_params$ages
max_age = max(bio_params$ages)
n_years = 30
years = (2020 - n_years + 1):2020
n_ages = length(ages)
## annual fishing mortality
start_F = c(rlnorm(10, log(seq(from = 0.02, to = 0.1, length = 10)), 0.1), rlnorm(10, log(0.1), 0.1), rlnorm(10, log(0.07), 0.1))
recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r))
```


```{r Buildtmpsex, echo = F, eval = T, results = 'hide', warning=FALSE, message=FALSE, error = FALSE}
##################
## Plot Biology
##################
length_at_age_m = vonbert(bio_params$ages, bio_params$K_m, bio_params$L_inf_m, bio_params$t0_m)
length_at_age_f = vonbert(bio_params$ages, bio_params$K_f, bio_params$L_inf_f, bio_params$t0_f)
fishery_ogive_m = logis(bio_params$ages, other_params$f_a50_m, other_params$f_ato95_m)
fishery_ogive_f = logis(bio_params$ages, other_params$f_a50_f, other_params$f_ato95_f)

survey_ogive_m = logis(bio_params$ages, other_params$s_a50_m, other_params$s_ato95_m)
survey_ogive_f = logis(bio_params$ages, other_params$s_a50_f, other_params$s_ato95_f)
mat_age = logis(bio_params$ages, bio_params$m_a50, bio_params$m_ato95)
weight_at_age_m = bio_params$a_m * length_at_age_m^bio_params$b_m
weight_at_age_f = bio_params$a_m * length_at_age_f^bio_params$b_f

## can change these if we want biennial surveys, or truncated observatons.
## Using the ALN method doesn't allow zeros so consider truncating tail ages.
survey_year_obs = seq(from = min(years), to = max(years), by = 2)
survey_ages = ages
fishery_year_obs = seq(from = min(years) + 1, to = max(years), by = 2)
fishery_ages = ages

############
## Build a multinomial model to double check estimability of all parameters
## In this case we have 'good' data, annual data, no ageing error.
##  survey index cv = 0.05
##  year effective sample size = 1000
############
TMB_data = list()
TMB_data$ages = ages
TMB_data$maxAgePlusGroup = 1;
TMB_data$years = years
TMB_data$nyears = length(TMB_data$years)
TMB_data$nages = length(TMB_data$ages)

## No ageing error
TMB_data$ageing_error_matrix = matrix(0, nrow = TMB_data$nages, ncol = TMB_data$nages)
diag(TMB_data$ageing_error_matrix) = 1;

TMB_data$survey_year_indicator = as.integer(TMB_data$years %in% survey_year_obs)
TMB_data$survey_obs = rnorm(sum(TMB_data$survey_year_indicator), 100, 4)
TMB_data$survey_cv = rep(0.15,sum(TMB_data$survey_year_indicator))
TMB_data$survey_sample_time = rep(0.5,sum(TMB_data$survey_year_indicator))
TMB_data$survey_AF_obs = array(2, dim = c(n_ages * 2, sum(TMB_data$survey_year_indicator)))
TMB_data$survey_AF_type = 0;
TMB_data$survey_numbers_male = colSums(TMB_data$survey_AF_obs)/ 2
TMB_data$fishery_year_indicator = as.integer(TMB_data$years %in% fishery_year_obs)
TMB_data$fishery_AF_obs = array(2, dim = c(n_ages * 2, sum(TMB_data$fishery_year_indicator)))
TMB_data$fishery_AF_type = 0;
TMB_data$fishery_numbers_male = colSums(TMB_data$fishery_AF_obs)/ 2
TMB_data$catches = rep(1000, n_years)# this will be overriden in the simulate() call
TMB_data$ycs_estimated = rep(1, n_years)
TMB_data$standardise_ycs = 0;

TMB_data$catchMeanLength = TMB_data$stockMeanLength = array(0, dim = c(TMB_data$nages, TMB_data$nyears,2))
TMB_data$catchMeanLength[,,1] = TMB_data$stockMeanLength[,,1] = matrix(length_at_age_m, byrow = F, ncol = TMB_data$nyears, nrow = TMB_data$nages)
TMB_data$catchMeanLength[,,2] = TMB_data$stockMeanLength[,,2] =  matrix(length_at_age_f, byrow = F, ncol = TMB_data$nyears, nrow = TMB_data$nages)

TMB_data$prop_mature = matrix(mat_age, byrow = F, ncol = TMB_data$nyears, nrow = TMB_data$nages)
TMB_data$natMor = bio_params$M
TMB_data$steepness = bio_params$h
TMB_data$stockRecruitmentModelCode = 2 ## BH
TMB_data$propZ_ssb = rep(other_params$ssb_prop_Z, TMB_data$nyears)
TMB_data$propZ_survey = rep(other_params$survey_prop_Z, TMB_data$nyears)
TMB_data$sel_ato95_bounds = c(0.1,20)
TMB_data$sel_a50_bounds = c(0.1,20)
TMB_data$sel_alpha_bounds = c(0.5, 2)

TMB_data$mean_weight_a = c(bio_params$a_m,bio_params$a_f) 
TMB_data$mean_weight_b = c(bio_params$b_m,bio_params$b_f)


## The same parameters as OM, to check for consistency
true_pars = list(
  ln_R0 = log(bio_params$R0),
  ln_ycs_est =  log(exp(recruit_devs[TMB_data$ycs_estimated == 1] - 0.5*bio_params$sigma_r^2)),
  ln_sigma_r = log( bio_params$sigma_r),
  ln_extra_survey_cv = log(0.0001),
  logit_f_a50 = logit_general(c(other_params$f_a50_m, other_params$f_a50_f), TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2]),
  logit_f_ato95 = logit_general(c(other_params$f_ato95_m, other_params$f_ato95_f), TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2]),
  logit_f_alpha_f = logit_general(other_params$f_alpha, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2]),
  logit_survey_a50 = logit_general(c(other_params$s_a50_m, other_params$s_a50_f), TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2]),
  logit_survey_ato95 = logit_general(c(other_params$s_ato95_m, other_params$s_ato95_f), TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2]),
  logit_surveyQ = qlogis(other_params$s_q),
  logit_survey_alpha_f = logit_general(other_params$s_alpha, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2]),
  ln_F = log(start_F),
  logit_proportion_male = rep(0, TMB_data$nyears),
  ln_catch_sd = log(0.02)
)

ran_start_vals = function() {
  start_params = list()
  start_params$ln_R0 = ran_start(n = 1, LB = log(bio_params$R0 * 0.2), UB = log(bio_params$R0 * 2))
  start_params$ln_ycs_est = ran_start(n = sum(TMB_data$ycs_estimated), LB = -1, UB = 1)
  start_params$ln_sigma_r = log(ran_start(n = 1,LB = 0.2, UB = 1))
  start_params$ln_extra_survey_cv = log(0.01)
  start_params$logit_f_a50 = logit_general(ran_start(n = 2, LB = 3, UB = 8),TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2])
  start_params$logit_f_ato95 = logit_general(ran_start(n = 2, LB = 3, UB = 8), TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2])
  start_params$logit_survey_a50 = logit_general(ran_start(n = 2, LB = 3 , UB = 8),TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2])
  start_params$logit_survey_ato95 = logit_general(ran_start(n = 2, LB = 3, UB = 8), TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2])
  
  start_params$logit_survey_alpha_f = logit_general(ran_start(n = 1,LB = 0.8, UB = 1.2),TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])
  start_params$logit_f_alpha_f = logit_general(ran_start(n = 1,LB = 0.8, UB = 1.2),TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])
  
  start_params$logit_surveyQ = qlogis(ran_start(n = 1, LB = 0.04, UB = 0.3))
  start_params$ln_F = log(ran_start(n = TMB_data$nyears, LB = 0.02, UB = 0.4))
  start_params$logit_proportion_male = rep(0, TMB_data$nyears)

  start_params$ln_catch_sd = log(0.02)
  return(start_params)
}
##################################
### Build TMB OM with Multinomial
##################################
#dyn.unload(dynlib(file.path(DIR$book,"TMB","SexDisaggregatedAgeStructuredModel")))
compile(file.path("TMB","SexDisaggregatedAgeStructuredModel.cpp"), flags = "-Wignored-attributes -O3",DLLFLAGS="");
dyn.load(dynlib(file.path("TMB","SexDisaggregatedAgeStructuredModel")))
## tolerance form model convergence, all gradients need to be less than this.
grad_tol = 0.001
# these parameters we are not estimating.
na_map = fix_pars(par_list = true_pars, pars_to_exclude = c("ln_catch_sd","ln_extra_survey_cv","ln_sigma_r", "logit_proportion_male"))
na_map_fix_alphas = fix_pars(par_list = true_pars, pars_to_exclude = c("logit_survey_alpha_f","logit_f_alpha_f","ln_catch_sd","ln_extra_survey_cv","ln_sigma_r", "logit_proportion_male"))
ASM_obj <- MakeADFun(TMB_data, true_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map,checkParameterOrder=T)

#invlogit_general(true_pars$logit_survey_alpha_f, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])

TMB_data_alt = TMB_data
TMB_data_alt$survey_AF_type = 1
TMB_data_alt$fishery_AF_type = 1
ASM_obj_alt_sex <- MakeADFun(TMB_data_alt, true_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map,checkParameterOrder=T)
true_report = ASM_obj$report()
##################################
### Generate predictions from both methods to compare
##################################
sim_data = ASM_obj$simulate(complete = T)
sim_data_alt = ASM_obj_alt_sex$simulate(complete = T)
```




```{r compilesexplot, warning=F, echo = F, eval = T, fig.cap="Examples of the two approaches for the survey (top row) and fishery (bottom row). The black and red line in approach 1 will sum to one, where as the black line and red line in approach will each sum to one. Approach 2 has an extra observation which is the proportion male (not shown)."}
par(mfrow = c(2,2))
plot(survey_ages, sim_data_alt$survey_comp_fitted[1:n_ages,9], type = "l", lwd = 3, ylab = "Survey predicted values", main = "Approach 1", xlab = "", ylim = c(0,0.2))
lines(survey_ages, sim_data_alt$survey_comp_fitted[(n_ages + 1):(n_ages*2),9], type = "l", lwd = 3, lty = 2, col = "red")
plot(survey_ages, sim_data$survey_comp_fitted[1:n_ages,9], type = "l", lwd = 3, ylab = "", main = "Approach 2", xlab = "", ylim = c(0,0.2))
lines(survey_ages, sim_data$survey_comp_fitted[(n_ages + 1):(n_ages*2),9], type = "l", lwd = 3, lty = 2, col = "red")

plot(fishery_ages, sim_data_alt$fishery_comp_fitted[1:n_ages,9], type = "l", lwd = 3, ylab = "Fishery predicted values", main = "", xlab = "", ylim = c(0,0.3))
lines(fishery_ages, sim_data_alt$fishery_comp_fitted[(n_ages + 1):(n_ages*2),9], type = "l", lwd = 3, lty = 2, col = "red")

plot(fishery_ages, sim_data$fishery_comp_fitted[1:n_ages,9], type = "l", lwd = 3, ylab = "", main = "", xlab = "", ylim = c(0,0.3))
lines(fishery_ages, sim_data$fishery_comp_fitted[(n_ages + 1):(n_ages*2),9], type = "l", lwd = 3, lty = 2, col = "red")
legend('topright', legend = c("Male","Female"), col = c("black", "red"), lty = c(1,2), lwd = 3)
```


### Scenario 1 
The first simulation assumed the OM had 50:50 males and female sex ratio at recruitment, and selectivities were as described in the above OM section. We simulated 100 data sets for each of the two approach's for sexually disaggregated compositional data outlined in the introduction. These were then fitted to in two EM's, where the EM's differed in the approach they used. Both EM's estimated a scalar on the female selectivity that allowed females to be more or less selected compared to males for both the fishery and survey. This was done be introducing an estimable \(\alpha\) parameter into the selectivity. Males selectivities were constrained to have a max value = 1 using,
\begin{equation}
S^{male}_a = 1/(1+19^{(a_{50}-a)/a_{to95})})
	  (\#eq:maleselectivity)

\end{equation}
where as the female was
\begin{equation}
S^{female}_a = \alpha/(1+19^{(a_{50}-a)/a_{to95})}) 
	  (\#eq:femaleselectivity)
\end{equation}


Although this scenario assumed both male and female had the same max selectivity I wanted to see the effect of estimating this additional parameter.

A third EM (EM3) was also explored, this structured compositional data using Approach 1 but fixed the female \(\alpha\) = 1 in Equation \@ref(eq:femaleselectivity). This is often the default approach. For scenario 1 this should be the best performing EM as it has the \(\alpha\) set at the values of the OM.


#### EM 1 (using approach 1) {-}
```{r run_scenario_1_EM_1, warning=F, echo = F, eval = T, cache = TRUE}
##################################
### Simulate 100 data sets for Scenario 1
##################################
est_pars_alt = NULL
ssbs_alt = NULL
convergence_alt = NULL
max_grad_alt = NULL
est_list_alt = list()
for(sim_iter in 1:n_sims) {
  #if(sim_iter %% 10 == 0)
  #  cat("iter = ", sim_iter, "\n")
  sim_data = ASM_obj_alt_sex$simulate(complete = T)
  start_pars = ran_start_vals()
  est_model_alt = MakeADFun(sim_data, start_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map, silent = T)
  opt_model_alt = nlminb(est_model_alt$par, est_model_alt$fn, est_model_alt$gr, control = list(iter.max = 10000, eval.max = 10000))
  ## Do two newton steps to try get parameters closer to the solution
  for(i in 1:2) {
    g = as.numeric(est_model_alt$gr(opt_model_alt$par))
    h = optimHess(opt_model_alt$par, fn = est_model_alt$fn, gr = est_model_alt$gr)
    opt_model_alt$par = opt_model_alt$par - solve(h,g)
    opt_model_alt$objective = est_model_alt$fn(opt_model_alt$par)
  }
  convergence_alt[sim_iter] = opt_model_alt$convergence
  max_grad_alt[sim_iter] = max(abs(est_model_alt$gr(est_model_alt$env$last.par.best)))
  est_pars_alt = rbind(est_pars_alt, opt_model_alt$par)
  est_rep_alt = est_model_alt$report(opt_model_alt$par)
  ssbs_alt = rbind(ssbs_alt, est_rep_alt$ssb)
  est_list_alt[[sim_iter]] = est_rep_alt
}
cat("max gradient from 100 simualtions = ", max(max_grad_alt), "\n")
R0s = get_list_obj(est_ls = est_list_alt, object_label = "R0")
sel_survey = get_list_obj(est_ls = est_list_alt, object_label = "survey_selectivity")
sel_survey_df = data.frame(sim = factor(sel_survey[,1]), male = sel_survey[,2], female = sel_survey[,3], age = ages)
sel_fishery = get_list_obj(est_ls = est_list_alt, object_label = "fishery_selectivity")
sel_fishery_df = data.frame(sim = factor(sel_fishery[,1]), male = sel_fishery[,2], female = sel_fishery[,3], age = ages)
annual_fs = get_list_obj(est_ls = est_list_alt, object_label = "annual_F")
colnames(annual_fs) = c("Sim", as.character(TMB_data$years))
molten_Fs = melt(as.data.frame(annual_fs), id.vars = "Sim", variable.name = "year", value.name = "F")
## plot selectivities
male_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$survey_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Male", col = "")+
  theme_bw()

female_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$survey_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Female", col = "")+
  theme_bw()
male_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$fishery_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Male", col = "")+
  theme_bw()

female_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$fishery_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Female", col = "")+
  theme_bw()

grid.arrange(grobs = list(male_s_sel, female_s_sel, male_f_sel, female_f_sel), ncol= 2)
```

```{r runscenario1EM1ssb, warning=F, echo = F, eval = T, fig.cap="Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
molten_ssbs = melt(ssbs_alt)
colnames(molten_ssbs) = c("sim", "year", "value")
ggplot() +
  geom_line(data =molten_ssbs, aes(x = year, y = value, group = sim)) +
  geom_line(data = data.frame(year = 1:31, value = true_report$ssb),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "SSB (t)") +
  theme_bw()
```

```{r runscenario1EM1Fs, warning=F, echo = F, eval = T, fig.cap="Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
ggplot() +
  geom_line(data = molten_Fs, aes(x = as.numeric(as.character(year)), y = F, group = Sim)) +
  geom_line(data = data.frame(year = TMB_data$years, value = true_report$annual_F),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "F") +
  theme_bw()
```

#### EM 2 (using approach 2) {-}
```{r run_scenario_1_EM_2, warning=F, echo = F, eval = T, cache = TRUE}
##################################
### Simulate 100 data sets for Scenario 1
##################################
est_pars = NULL
ssbs = NULL
convergence = NULL
max_grad = NULL
est_list = list()
for(sim_iter in 1:n_sims) {
  #if(sim_iter %% 10 == 0)
  #  cat("iter = ", sim_iter, "\n")
  sim_data = ASM_obj$simulate(complete = T)
  start_pars = ran_start_vals()
  est_model = MakeADFun(sim_data, start_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map, silent = T)
  opt_modelc = nlminb(est_model$par, est_model$fn, est_model$gr, control = list(iter.max = 10000, eval.max = 10000))
  ## Do two newton steps to try get parameters closer to the solution
  for(i in 1:2) {
    g = as.numeric(est_model$gr(opt_modelc$par))
    h = optimHess(opt_modelc$par, fn = est_model$fn, gr = est_model$gr)
    opt_modelc$par = opt_modelc$par - solve(h,g)
    opt_modelc$objective = est_model$fn(opt_modelc$par)
  }
  convergence[sim_iter] = opt_modelc$convergence
  max_grad[sim_iter] = max(abs(est_model$gr(est_model$env$last.par.best)))
  est_pars = rbind(est_pars, opt_modelc$par)
  est_rep = est_model$report(opt_modelc$par)
  ssbs = rbind(ssbs, est_rep$ssb)
  est_list[[sim_iter]] = est_rep
}
cat("max gradient from 100 simualtions = ", max(max_grad), "\n")
R0s = get_list_obj(est_ls = est_list, object_label = "R0")
sel_survey = get_list_obj(est_ls = est_list, object_label = "survey_selectivity")
sel_survey_df = data.frame(sim = factor(sel_survey[,1]), male = sel_survey[,2], female = sel_survey[,3], age = ages)
sel_fishery = get_list_obj(est_ls = est_list, object_label = "fishery_selectivity")
sel_fishery_df = data.frame(sim = factor(sel_fishery[,1]), male = sel_fishery[,2], female = sel_fishery[,3], age = ages)
annual_fs = get_list_obj(est_ls = est_list, object_label = "annual_F")
colnames(annual_fs) = c("Sim", as.character(TMB_data$years))
molten_Fs = melt(as.data.frame(annual_fs), id.vars = "Sim", variable.name = "year", value.name = "F")

## plot selectivities
male_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$survey_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Male", col = "")+
  theme_bw()

female_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$survey_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Female", col = "")+
  theme_bw()
male_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$fishery_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Male", col = "")+
  theme_bw()

female_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$fishery_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Female", col = "")+
  theme_bw()

grid.arrange(grobs = list(male_s_sel, female_s_sel, male_f_sel, female_f_sel), ncol= 2)
```

```{r runscenario1EM2ssb, warning=F, echo = F, eval = T, fig.cap="Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
molten_ssbs = melt(ssbs)
colnames(molten_ssbs) = c("sim", "year", "value")
ggplot() +
  geom_line(data =molten_ssbs, aes(x = year, y = value, group = sim)) +
  geom_line(data = data.frame(year = 1:31, value = true_report$ssb),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "SSB (t)") +
  theme_bw()
```

```{r runscenario1EM2Fs, warning=F, echo = F, eval = T, fig.cap="Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
ggplot() +
  geom_line(data = molten_Fs, aes(x = as.numeric(as.character(year)), y = F, group = Sim)) +
  geom_line(data = data.frame(year = TMB_data$years, value = true_report$annual_F),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "F") +
  theme_bw()
```


#### EM 3 (using approach 1 with female fixed at \(\alpha = 1\)) {-}
```{r run_scenario_1_EM_3, warning=F, echo = F, eval = T, cache = TRUE}
##################################
### Simulate 100 data sets for Scenario 1
##################################
est_pars = NULL
ssbs = NULL
convergence = NULL
max_grad = NULL
est_list = list()
for(sim_iter in 1:n_sims) {
  #if(sim_iter %% 10 == 0)
  #  cat("iter = ", sim_iter, "\n")
  sim_data = ASM_obj_alt_sex$simulate(complete = T)
  start_pars = ran_start_vals()
  start_pars$logit_survey_alpha_f = logit_general(1, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])
  start_pars$logit_f_alpha_f = logit_general(1, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])

  est_model = MakeADFun(sim_data, start_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map_fix_alphas, silent = T)
  opt_modelc = nlminb(est_model$par, est_model$fn, est_model$gr, control = list(iter.max = 10000, eval.max = 10000))
  ## Do two newton steps to try get parameters closer to the solution
  for(i in 1:2) {
    g = as.numeric(est_model$gr(opt_modelc$par))
    h = optimHess(opt_modelc$par, fn = est_model$fn, gr = est_model$gr)
    opt_modelc$par = opt_modelc$par - solve(h,g)
    opt_modelc$objective = est_model$fn(opt_modelc$par)
  }
  convergence[sim_iter] = opt_modelc$convergence
  max_grad[sim_iter] = max(abs(est_model$gr(est_model$env$last.par.best)))
  est_pars = rbind(est_pars, opt_modelc$par)
  est_rep = est_model$report(opt_modelc$par)
  ssbs = rbind(ssbs, est_rep$ssb)
  est_list[[sim_iter]] = est_rep
}
cat("max gradient from 100 simualtions = ", max(max_grad), "\n")
R0s = get_list_obj(est_ls = est_list, object_label = "R0")
sel_survey = get_list_obj(est_ls = est_list, object_label = "survey_selectivity")
sel_survey_df = data.frame(sim = factor(sel_survey[,1]), male = sel_survey[,2], female = sel_survey[,3], age = ages)
sel_fishery = get_list_obj(est_ls = est_list, object_label = "fishery_selectivity")
sel_fishery_df = data.frame(sim = factor(sel_fishery[,1]), male = sel_fishery[,2], female = sel_fishery[,3], age = ages)
annual_fs = get_list_obj(est_ls = est_list, object_label = "annual_F")
colnames(annual_fs) = c("Sim", as.character(TMB_data$years))
molten_Fs = melt(as.data.frame(annual_fs), id.vars = "Sim", variable.name = "year", value.name = "F")

## plot selectivities
male_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$survey_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Male", col = "")+
  theme_bw()

female_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$survey_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Female", col = "")+
  theme_bw()
male_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$fishery_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Male", col = "")+
  theme_bw()

female_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$fishery_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Female", col = "")+
  theme_bw()

grid.arrange(grobs = list(male_s_sel, female_s_sel, male_f_sel, female_f_sel), ncol= 2)
```

```{r runscenario1EM3ssb, warning=F, echo = F, eval = T, fig.cap="Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
molten_ssbs = melt(ssbs)
colnames(molten_ssbs) = c("sim", "year", "value")
ggplot() +
  geom_line(data =molten_ssbs, aes(x = year, y = value, group = sim)) +
  geom_line(data = data.frame(year = 1:31, value = true_report$ssb),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "SSB (t)") +
  theme_bw()
```


```{r runscenario1EM3Fs, warning=F, echo = F, eval = T, fig.cap="Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
ggplot() +
  geom_line(data = molten_Fs, aes(x = as.numeric(as.character(year)), y = F, group = Sim)) +
  geom_line(data = data.frame(year = TMB_data$years, value = true_report$annual_F),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "F") +
  theme_bw()
```



### Scenario 2 
The second scenario assumed sex ratio was 50:50 at recruitment and females were more selective than males to the fishery. This was done by setting \(\alpha\) = 1.2 in Equation \@ref(eq:femaleselectivity). 

```{r ChangeOMSceneario2, warning=F, echo = T, eval = T}
true_pars$logit_f_alpha_f = logit_general(1.2, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])
```

```{r RecompileTMBForScenario2, echo = F, eval = T, results = 'hide', warning=FALSE, message=FALSE, error = FALSE}
ASM_obj <- MakeADFun(TMB_data, true_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map_fix_alphas, checkParameterOrder=T)
ASM_obj_alt_sex <- MakeADFun(TMB_data_alt, true_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map_fix_alphas, checkParameterOrder=T)
true_report = ASM_obj$report()
```

#### EM 1 (using approach 1) {-}
```{r run_scenario_2_EM_1, warning=F, echo = F, eval = T, cache = TRUE}
##################################
### Simulate 100 data sets for Scenario 1
##################################
est_pars_alt = NULL
ssbs_alt = NULL
convergence_alt = NULL
max_grad_alt = NULL
est_list_alt = list()
for(sim_iter in 1:n_sims) {
  #if(sim_iter %% 10 == 0)
  #  cat("iter = ", sim_iter, "\n")
  sim_data = ASM_obj_alt_sex$simulate(complete = T)
  start_pars = ran_start_vals()
  est_model_alt = MakeADFun(sim_data, start_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map, silent = T)
  opt_model_alt = nlminb(est_model_alt$par, est_model_alt$fn, est_model_alt$gr, control = list(iter.max = 10000, eval.max = 10000))
  ## Do two newton steps to try get parameters closer to the solution
  for(i in 1:2) {
    g = as.numeric(est_model_alt$gr(opt_model_alt$par))
    h = optimHess(opt_model_alt$par, fn = est_model_alt$fn, gr = est_model_alt$gr)
    opt_model_alt$par = opt_model_alt$par - solve(h,g)
    opt_model_alt$objective = est_model_alt$fn(opt_model_alt$par)
  }
  convergence_alt[sim_iter] = opt_model_alt$convergence
  max_grad_alt[sim_iter] = max(abs(est_model_alt$gr(est_model_alt$env$last.par.best)))
  est_pars_alt = rbind(est_pars_alt, opt_model_alt$par)
  est_rep_alt = est_model_alt$report(opt_model_alt$par)
  ssbs_alt = rbind(ssbs_alt, est_rep_alt$ssb)
  est_list_alt[[sim_iter]] = est_rep_alt
}
cat("max gradient from 100 simualtions = ", max(max_grad_alt), "\n")
R0s = get_list_obj(est_ls = est_list_alt, object_label = "R0")
sel_survey = get_list_obj(est_ls = est_list_alt, object_label = "survey_selectivity")
sel_survey_df = data.frame(sim = factor(sel_survey[,1]), male = sel_survey[,2], female = sel_survey[,3], age = ages)
sel_fishery = get_list_obj(est_ls = est_list_alt, object_label = "fishery_selectivity")
sel_fishery_df = data.frame(sim = factor(sel_fishery[,1]), male = sel_fishery[,2], female = sel_fishery[,3], age = ages)
annual_fs = get_list_obj(est_ls = est_list_alt, object_label = "annual_F")
colnames(annual_fs) = c("Sim", as.character(TMB_data$years))
molten_Fs = melt(as.data.frame(annual_fs), id.vars = "Sim", variable.name = "year", value.name = "F")

## plot selectivities
male_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$survey_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Male", col = "")+
  theme_bw()

female_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$survey_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Female", col = "")+
  theme_bw()
male_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$fishery_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Male", col = "")+
  theme_bw()

female_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$fishery_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Female", col = "")+
  theme_bw()

grid.arrange(grobs = list(male_s_sel, female_s_sel, male_f_sel, female_f_sel), ncol= 2)
```

```{r runscenario2EM1ssb, warning=F, echo = F, eval = T, fig.cap="Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
molten_ssbs = melt(ssbs_alt)
colnames(molten_ssbs) = c("sim", "year", "value")
ggplot() +
  geom_line(data =molten_ssbs, aes(x = year, y = value, group = sim)) +
  geom_line(data = data.frame(year = 1:31, value = true_report$ssb),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "SSB (t)") +
  theme_bw()
```


```{r runscenario2EM1Fs, warning=F, echo = F, eval = T, fig.cap="Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
ggplot() +
  geom_line(data = molten_Fs, aes(x = as.numeric(as.character(year)), y = F, group = Sim)) +
  geom_line(data = data.frame(year = TMB_data$years, value = true_report$annual_F),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "F") +
  theme_bw()
```

#### EM 2 (using approach 2) {-}
```{r run_scenario_2_EM_2, warning=F, echo = F, eval = T, cache = TRUE}
##################################
### Simulate 100 data sets for Scenario 1
##################################
est_pars = NULL
ssbs = NULL
convergence = NULL
max_grad = NULL
est_list = list()
for(sim_iter in 1:n_sims) {
  #if(sim_iter %% 10 == 0)
  #  cat("iter = ", sim_iter, "\n")
  sim_data = ASM_obj$simulate(complete = T)
  start_pars = ran_start_vals()
  est_model = MakeADFun(sim_data, start_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map, silent = T)
  opt_modelc = nlminb(est_model$par, est_model$fn, est_model$gr, control = list(iter.max = 10000, eval.max = 10000))
  ## Do two newton steps to try get parameters closer to the solution
  for(i in 1:2) {
    g = as.numeric(est_model$gr(opt_modelc$par))
    h = optimHess(opt_modelc$par, fn = est_model$fn, gr = est_model$gr)
    opt_modelc$par = opt_modelc$par - solve(h,g)
    opt_modelc$objective = est_model$fn(opt_modelc$par)
  }
  convergence[sim_iter] = opt_modelc$convergence
  max_grad[sim_iter] = max(abs(est_model$gr(est_model$env$last.par.best)))
  est_pars = rbind(est_pars, opt_modelc$par)
  est_rep = est_model$report(opt_modelc$par)
  ssbs = rbind(ssbs, est_rep$ssb)
  est_list[[sim_iter]] = est_rep
}
cat("max gradient from 100 simualtions = ", max(max_grad), "\n")
R0s = get_list_obj(est_ls = est_list, object_label = "R0")
sel_survey = get_list_obj(est_ls = est_list, object_label = "survey_selectivity")
sel_survey_df = data.frame(sim = factor(sel_survey[,1]), male = sel_survey[,2], female = sel_survey[,3], age = ages)
sel_fishery = get_list_obj(est_ls = est_list, object_label = "fishery_selectivity")
sel_fishery_df = data.frame(sim = factor(sel_fishery[,1]), male = sel_fishery[,2], female = sel_fishery[,3], age = ages)
annual_fs = get_list_obj(est_ls = est_list, object_label = "annual_F")
colnames(annual_fs) = c("Sim", as.character(TMB_data$years))
molten_Fs = melt(as.data.frame(annual_fs), id.vars = "Sim", variable.name = "year", value.name = "F")

## plot selectivities
male_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$survey_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Male", col = "")+
  theme_bw()

female_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$survey_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Female", col = "")+
  theme_bw()
male_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$fishery_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Male", col = "")+
  theme_bw()

female_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$fishery_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Female", col = "")+
  theme_bw()

grid.arrange(grobs = list(male_s_sel, female_s_sel, male_f_sel, female_f_sel), ncol= 2)
```

```{r runscenario2EM2ssb, warning=F, echo = F, eval = T, fig.cap="Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
molten_ssbs = melt(ssbs)
colnames(molten_ssbs) = c("sim", "year", "value")
ggplot() +
  geom_line(data =molten_ssbs, aes(x = year, y = value, group = sim)) +
  geom_line(data = data.frame(year = 1:31, value = true_report$ssb),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "SSB (t)") +
  theme_bw()
```


```{r runscenario2EM2Fs, warning=F, echo = F, eval = T, fig.cap="Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
ggplot() +
  geom_line(data = molten_Fs, aes(x = as.numeric(as.character(year)), y = F, group = Sim)) +
  geom_line(data = data.frame(year = TMB_data$years, value = true_report$annual_F),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "F") +
  theme_bw()
```
#### EM 3 (using approach 1 with female fixed at \(\alpha = 1\)) {-}
```{r run_scenario_2_EM_3, warning=F, echo = F, eval = T, cache = TRUE}
##################################
### Simulate 100 data sets for Scenario 1
##################################
est_pars = NULL
ssbs = NULL
convergence = NULL
max_grad = NULL
est_list = list()
for(sim_iter in 1:n_sims) {
  #if(sim_iter %% 10 == 0)
  #  cat("iter = ", sim_iter, "\n")
  sim_data = ASM_obj_alt_sex$simulate(complete = T)
  start_pars = ran_start_vals()
  start_pars$logit_survey_alpha_f = logit_general(1, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])
  start_pars$logit_f_alpha_f = logit_general(1, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2])

  est_model = MakeADFun(sim_data, start_pars, DLL= "SexDisaggregatedAgeStructuredModel", map = na_map_fix_alphas, silent = T)
  opt_modelc = nlminb(est_model$par, est_model$fn, est_model$gr, control = list(iter.max = 10000, eval.max = 10000))
  ## Do two newton steps to try get parameters closer to the solution
  for(i in 1:2) {
    g = as.numeric(est_model$gr(opt_modelc$par))
    h = optimHess(opt_modelc$par, fn = est_model$fn, gr = est_model$gr)
    opt_modelc$par = opt_modelc$par - solve(h,g)
    opt_modelc$objective = est_model$fn(opt_modelc$par)
  }
  convergence[sim_iter] = opt_modelc$convergence
  max_grad[sim_iter] = max(abs(est_model$gr(est_model$env$last.par.best)))
  est_pars = rbind(est_pars, opt_modelc$par)
  est_rep = est_model$report(opt_modelc$par)
  ssbs = rbind(ssbs, est_rep$ssb)
  est_list[[sim_iter]] = est_rep
}
cat("max gradient from 100 simualtions = ", max(max_grad), "\n")
R0s = get_list_obj(est_ls = est_list, object_label = "R0")
sel_survey = get_list_obj(est_ls = est_list, object_label = "survey_selectivity")
sel_survey_df = data.frame(sim = factor(sel_survey[,1]), male = sel_survey[,2], female = sel_survey[,3], age = ages)
sel_fishery = get_list_obj(est_ls = est_list, object_label = "fishery_selectivity")
sel_fishery_df = data.frame(sim = factor(sel_fishery[,1]), male = sel_fishery[,2], female = sel_fishery[,3], age = ages)
annual_fs = get_list_obj(est_ls = est_list, object_label = "annual_F")
colnames(annual_fs) = c("Sim", as.character(TMB_data$years))
molten_Fs = melt(as.data.frame(annual_fs), id.vars = "Sim", variable.name = "year", value.name = "F")

## plot selectivities
male_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$survey_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Male", col = "")+
  theme_bw()

female_s_sel = ggplot(data  = sel_survey_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$survey_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Survey - Female", col = "")+
  theme_bw()
male_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = male, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, male = true_report$fishery_selectivity[,1]), aes(x = age, y = male, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Male", col = "")+
  theme_bw()

female_f_sel = ggplot(data  = sel_fishery_df) +
  geom_line(aes(x = age, y = female, group = factor(sim), alpha = 0.3, col = "EMs"), linewidth = 1.3) +
  geom_line(data = data.frame(age = ages, female = true_report$fishery_selectivity[,2]), aes(x = age, y = female, col = "OM"), linewidth= 1.2, linetype = "dashed")+
  guides(alpha = "none") +
  labs(x = "Age", y = "Selectivity", title = "Fishery - Female", col = "")+
  theme_bw()

grid.arrange(grobs = list(male_s_sel, female_s_sel, male_f_sel, female_f_sel), ncol= 2)
```

```{r runscenario2EM3ssb, warning=F, echo = F, eval = T, fig.cap="Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
molten_ssbs = melt(ssbs)
colnames(molten_ssbs) = c("sim", "year", "value")
ggplot() +
  geom_line(data =molten_ssbs, aes(x = year, y = value, group = sim)) +
  geom_line(data = data.frame(year = 1:31, value = true_report$ssb),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "SSB (t)") +
  theme_bw()
```


```{r runscenario2EM3Fs, warning=F, echo = F, eval = T, fig.cap="Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs"}
## plpt SSBs
ggplot() +
  geom_line(data = molten_Fs, aes(x = as.numeric(as.character(year)), y = F, group = Sim)) +
  geom_line(data = data.frame(year = TMB_data$years, value = true_report$annual_F),aes(x = year, y = value), col = "red", linetype = "dashed", linewidth = 1.2) +
  ylim(0,NA) +
  labs(x = "Time", y = "F") +
  theme_bw()
```




<!--chapter:end:04-DealWithSexRatios.Rmd-->

# Fishing mortality approaches {#Fexplore}

The current Alaskan sablefish stock assessment (Chapter \@ref(modeldescription)) estimates annual fishing mortality values for each gear \(g\) denoted by \(F^g_{y}\). This parametersation poses to potential problems when considering future assessment models and spatial models. The first is, the number of parameters will increase as the number of gears increase. The fishery is currently going through a transformation whereby there is a switch from longline to pots. The second consideration is how to set this up in a spatially explicit model where catch have an added spatial dimension. There are two alternative approaches to the current approach which treat \(F\) as a derived quantity rather than an estimable parameter. The first is to use Newton Raphson method to solve for \(F^g_{y}\). This is the recommended approach in Stock Synthesis [@methot2013stock], termed the "hybrid" approach. The previous two methods assume the Baranov catch equation for mortality [@baranov1918question]. An alternative is to assume Popes discrete formulation [@pope1972investigation] which uses exploitation proportions (sometimes called harvest rates or fishing pressure) and has a closed form solution.

A good general overview on these methods can be found in @branch2009differences. They describe and compared the continuous Baranov catch equation [@baranov1918question] with Pope's discrete formulation [@pope1972investigation]. Arguments for using the continuous case is that $M$ and $F$ occur simultaneously, also with the continuous case, $F$ allows for multiple event encounters, this is assuming a fleet has the same selectivity and availability, that a fish that escapes one net can be caught in another. In contrast, the discrete formulation only allows a fish to be caught or escape from an instantaneous event. I have tried to summarize the benefits of the continuous equation in the following list,

*  Allows the entire population to be caught (not sure this is that relevant)
*  Allows simultaneous $M$ and $F$, no need to worry about order of operations. From a coding/practical perspective this is quite attractive. Once you have an F and M you can easily derive all mid-mortality quantities. Where as using a \(U\) approach you need save the population before and after to interpolate to derive mid-mortality quantities.
*  The magnitude of $F$ effects composition data, where as in the discrete case, composition is independent of the magniture of $U$.
*  Allows for multiple catch events of an individual
*  Can fit to catch observations thus allows for uncertainty in catches. In practice the uncertainty/variance on catch is very small i.e., coeffecient of variations ranging from 0.01 to 0.1. This essentially states catch is observed with high confidence and in my opinion isn't that much different to saying catch is known exactly. Note often this high precision on observed catch is needed in order to make the \(F\)'s identifiable. This high precision also muddies the "degrees of freedom" for the model. Although the \(F\)'s look like independent and free parameters they are heavily constrained by the assumptiosn on observed catch variance.


The arguments for the discrete approximation is that there is an analytical solution for \(U\) and so is fast to calculate expected catch, where as $F$ has to be either solved numerically or estimated as a free parameter (as mentioned earlier). 
 
Chris Francis's wrote a response to this paper [@francisCommentBranch] where he argues the discrete formulation does not preclude the multiple encounters and that only the data can truly tell us which catch equation is the best one to use.

- Need to make a point about how there may be Automatic differentiation issues with the \(U\) approach. Because there is an `if(U > 0.99)` which can cause a fork in the chain rule which can equal a coding nightmare.

The relationship between $F$ (Instantaneous fishing mortality) and $U$ exploitation rate for a simple scenario (single fishery) is illustrated in the following R code.


```{r illustrate_F_vs_U_sim}
exploitation_rates = seq(0,0.8,by = 0.02)
## calculate F given a U
fishing_mortalites = -log(1 - exploitation_rates)
## back calculate U given a F
# 1 - exp(-fishing_mortalites) 
```



The objective of this simulation

- Is the method efficient i.e., no loss of speed.
- Is the method numerically stable (No NaNs during optimization), particularly under high fishing pressure




```{r illustrateFvsU, echo = F, eval = T, fig.fullwidth=T, fig.cap="Illustration of how mortality is applied to an age cohort continuously over time (y)."}
## the application throught time.
N_1 = 100
par(mfrow = c(2,2), mar = c(2,2,2,1), oma = c(3,2,2,0))
Fs = c(0.2,0.6,1,1.4)
for(i in 1:length(Fs)) {
  F_t = Fs[i]
  U_t = 1 - exp(-F_t)
  M = 0.5
  time_ = seq(0,1, by = 0.001)
  change_over_time = N_1 * exp(-(F_t+M)*time_)
  change_over_time_alt = N_1 * exp(-M*time_[time_<0.5]) 
  change_over_time_alt = c(change_over_time_alt, change_over_time_alt[length(change_over_time_alt)] * (1 - U_t))
  change_over_time_alt = c(change_over_time_alt, change_over_time_alt[length(change_over_time_alt)] * exp(-M*time_[time_ < 0.5]) )
  
  plot(1,1, type = "n", xlab = "", ylab = "", ylim = c(0,100), xlim = c(0,1), xaxt = "n", yaxt = "n", cex.main = 1.5,cex.lab = 1.5, main = substitute(paste(F[y], " = ", this_F, " M = ", M), list(this_F = F_t, M= M)))#paste0(, " = ", F_t))
  lines(time_, change_over_time, lwd = 4)
  lines(time_, change_over_time_alt, lwd = 4, col = "red")
  if (i > 2)
    axis(side = 1, tick = T, at = c(0,1), labels = c("y", "y+1"), cex.axis = 2)
  if (i == 1)
    legend('bottomleft', legend = c("F","U"), lwd = 3, col = c("black","red"), cex = 0.8)
}
mtext(side = 1, text = "Time", outer = T, line = 0.7, cex = 1.3)
mtext(side = 2, text = "N", outer = T, line = -1, cex = 1.3)
```



## Set up a simulation {-}
To explore the above described methods a simple simulation was conducted using a simple age-structured stock assessment operating model. The model assumed 15 seperate fisheries all with a common selectivity. The purpose was to check that the derived methods were reliable (provided unbiased stock quantities) and that they are computationally efficient.


```{r setupfirstsim}
bio_params = list(
  ages = 1:20,
  L_inf = 58,
  K = 0.133,
  t0 = 0,
  M = 0.15,
  a = 2.08e-9, ## tonnes
  b = 3.5,
  m_a50 = 6.3,
  m_ato95 = 1.2,
  sigma = 0.6,
  h = 0.85,
  sigma_r = 0.6,
  R0 = 8234132,
  plus_group = 1 # 0 = No, 1 = Yes
)

other_params = list(
  s_a50 = 3.6,
  s_ato95 = 2,
  s_q = 0.2,
  f_a50 = 5,
  f_ato95 = 2,
  ssb_prop_Z = 0.5,
  survey_prop_Z = 0.5,
  survey_age_error = c(0.5, 0.4),  ## sd, rho (ignored if iid)
  fishery_age_error = c(0.5, 0.4),  ## sd, rho (ignored if iid)
  survey_bio_cv = c(0.1)
)

ages = bio_params$ages
max_age = max(bio_params$ages)
n_years = 30
years = (2020 - n_years + 1):2020
n_ages = length(ages)
## annual fishing mortality
start_F = c(rlnorm(10, log(seq(from = 0.05, to = 0.2, length = 10)), 0.1), rlnorm(10, log(0.13), 0.1), rlnorm(10, log(0.07), 0.1))
recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r))

length_at_age = vonbert(bio_params$ages, bio_params$K, bio_params$L_inf, bio_params$t0)
fishery_ogive = logis(bio_params$ages, other_params$f_a50, other_params$f_ato95)
survey_ogive = logis(bio_params$ages, other_params$s_a50, other_params$s_ato95)
mat_age = logis(bio_params$ages, bio_params$m_a50, bio_params$m_ato95)
weight_at_age = bio_params$a * length_at_age^bio_params$b

## observation temporal frequency
survey_year_obs = years
survey_ages = 1:20
fishery_year_obs = years
fishery_ages = 1:20
```

```{r poptmbobjects, echo = F, eval = T, results = 'hide', warning=FALSE, message=FALSE, error = FALSE}
############
## Build a multinomial model to double check estimability of all parameters
## In this case we have 'good' data, annual data, no ageing error.
##  survey index cv = 0.05
##  year effective sample size = 1000
############
TMB_data = list()
TMB_data$ages = ages
TMB_data$maxAgePlusGroup = bio_params$plus_group
TMB_data$years = years
TMB_data$n_years = length(TMB_data$years)
TMB_data$n_ages = length(TMB_data$ages)
TMB_data$n_fisheries = 15
## No ageing error
TMB_data$ageing_error_matrix = matrix(0, nrow = TMB_data$n_ages, ncol = TMB_data$n_ages)
diag(TMB_data$ageing_error_matrix) = 1;

TMB_data$survey_year_indicator = as.integer(TMB_data$years %in% survey_year_obs)
TMB_data$survey_obs = rnorm(sum(TMB_data$survey_year_indicator), 100, 4)
TMB_data$survey_cv = rep(0.15,sum(TMB_data$survey_year_indicator))
TMB_data$survey_sample_time = rep(0.5,sum(TMB_data$survey_year_indicator))
TMB_data$survey_AF_obs = matrix(5, nrow = TMB_data$n_ages, ncol = sum(TMB_data$survey_year_indicator))

TMB_data$fishery_year_indicator = array(as.integer(TMB_data$years %in% fishery_year_obs), dim = c(length(fishery_year_obs), TMB_data$n_fisheries))
TMB_data$fishery_AF_obs = array(5, dim = c(TMB_data$n_ages, length(fishery_year_obs), TMB_data$n_fisheries))

TMB_data$catches = array(1000, dim = c(TMB_data$n_years, TMB_data$n_fisheries))# this will be overriden in the simulate() call
TMB_data$F_method = 0
TMB_data$F_iterations = 4
TMB_data$F_max = 3

TMB_data$catch_indicator = array(1, dim = c(TMB_data$n_years, TMB_data$n_fisheries))
TMB_data$ycs_estimated = rep(1, n_years)
TMB_data$standardise_ycs = 0;

TMB_data$catchMeanLength = TMB_data$stockMeanLength = matrix(length_at_age, byrow = F, ncol = TMB_data$n_years, nrow = TMB_data$n_ages)
TMB_data$propMat = matrix(mat_age, byrow = F, ncol = TMB_data$n_years, nrow = TMB_data$n_ages)
TMB_data$natMor = bio_params$M
TMB_data$steepness = bio_params$h
TMB_data$stockRecruitmentModelCode = 2 ## BH
TMB_data$propZ_ssb = rep(other_params$ssb_prop_Z, TMB_data$n_years)
TMB_data$propZ_survey = rep(other_params$survey_prop_Z, TMB_data$n_years)
TMB_data$sel_ato95_bounds = c(0.1,20)
TMB_data$sel_a50_bounds = c(0.1,20)
TMB_data$mean_weight_a = bio_params$a
TMB_data$mean_weight_b = bio_params$b


## fishery_probs
fishery_probs = rlnorm(TMB_data$n_fisheries, meanlog = log(1), 0.6)
fishery_probs = fishery_probs / sum(fishery_probs)
prob_F = rmultinom(n = TMB_data$n_years, size = 500, prob = fishery_probs)
prob_F = (sweep(prob_F, MARGIN = 2, FUN = "/", STATS = colSums(prob_F)))
F_by_fishery = sweep(prob_F, MARGIN = 2, FUN = "*", STATS = start_F)

## The same parameters as OM, to check for consistency
true_pars = list(
  ln_R0 = log(bio_params$R0),
  ln_ycs_est =  log(exp(recruit_devs[TMB_data$ycs_estimated == 1] - 0.5*bio_params$sigma_r^2)),
  ln_sigma_r = log( bio_params$sigma_r),
  ln_extra_survey_cv = log(0.0001),
  logit_f_a50 = logit_general(rep(other_params$f_a50, TMB_data$n_fisheries), TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2]),
  logit_f_ato95 = logit_general(rep(other_params$f_ato95, TMB_data$n_fisheries), TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2]),
  logit_survey_a50 = logit_general(other_params$s_a50, TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2]),
  logit_survey_ato95 = logit_general(other_params$s_ato95, TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2]),
  logit_surveyQ = qlogis(other_params$s_q),
  ln_F = array(log(F_by_fishery), dim = c(TMB_data$n_fisheries,TMB_data$n_years)),
  ln_catch_sd = log(0.02)
)

ran_start_vals = function() {
  start_params = list()
  start_params$ln_R0 = ran_start(n = 1, LB = log(bio_params$R0 * 0.2), UB = log(bio_params$R0 * 2))
  start_params$ln_ycs_est = ran_start(n = sum(TMB_data$ycs_estimated), LB = -1, UB = 1)
  start_params$ln_sigma_r = log(ran_start(n = 1,LB = 0.2, UB = 1))
  start_params$ln_extra_survey_cv = log(0.01)
  start_params$logit_f_a50 = logit_general(rep(ran_start(n = 1, LB = 3, UB = 8), TMB_data$n_fisheries),TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2])
  start_params$logit_f_ato95 = logit_general(rep(ran_start(n = 1, LB = 3, UB = 8), TMB_data$n_fisheries), TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2])
  start_params$logit_survey_a50 = logit_general(ran_start(n = 1, LB = 3 , UB = 8),TMB_data$sel_a50_bounds[1], TMB_data$sel_a50_bounds[2])
  start_params$logit_survey_ato95 = logit_general(ran_start(n = 1, LB = 3, UB = 8), TMB_data$sel_ato95_bounds[1], TMB_data$sel_ato95_bounds[2])
  start_params$logit_surveyQ = qlogis(ran_start(n = 1, LB = 0.01, UB = 0.3))
  start_params$ln_F = array(log(ran_start(n = TMB_data$n_years * TMB_data$n_fisheries, LB = 0.02, UB = 0.4)), dim = c(TMB_data$n_fisheries,TMB_data$n_years))
  start_params$ln_catch_sd = log(0.02)
  return(start_params)
}
##################################
### Build TMB OM with Multinomial
##################################
#dyn.unload(dynlib(file.path("TMB","SimpleAgestructuredModelMultiFs")))
compile(file.path("TMB","SimpleAgestructuredModelMultiFs.cpp"), flags = "-Wignored-attributes -O3",DLLFLAGS="");
dyn.load(dynlib(file.path("TMB","SimpleAgestructuredModelMultiFs")))
## tolerance form model convergence, all gradients need to be less than this.
grad_tol = 0.001
# these parameters we are not estimating.
na_map = fix_pars(par_list = true_pars, pars_to_exclude = c("ln_catch_sd", "ln_extra_survey_cv","ln_sigma_r", "logit_f_a50", "logit_f_ato95"),
                  vec_elements_to_exclude = list(logit_f_a50 = 2:length(true_pars$logit_f_a50), logit_f_ato95 = 2:length(true_pars$logit_f_ato95)))
na_map = set_pars_to_be_the_same(par_list = true_pars, map = na_map,
                                 base_parameters = append(rep(list(logit_f_a50 = c(1)), TMB_data$n_fisheries - 1),rep(list(logit_f_ato95 = c(1)), TMB_data$n_fisheries - 1)),
                                 copy_parameters = list(
                                   logit_f_a50 = 2,
                                   logit_f_a50 = 3,
                                   logit_f_a50 = 4,
                                   logit_f_a50 = 5,
                                   logit_f_a50 = 6,
                                   logit_f_a50 = 7,
                                   logit_f_a50 = 8,
                                   logit_f_a50 = 9,
                                   logit_f_a50 = 10,
                                   logit_f_a50 = 11,
                                   logit_f_a50 = 12,
                                   logit_f_a50 = 13,
                                   logit_f_a50 = 14,
                                   logit_f_a50 = 15,
                                   logit_f_ato95 = 2,
                                   logit_f_ato95 = 3,
                                   logit_f_ato95 = 4,
                                   logit_f_ato95 = 5,
                                   logit_f_ato95 = 6,
                                   logit_f_ato95 = 7,
                                   logit_f_ato95 = 8,
                                   logit_f_ato95 = 9,
                                   logit_f_ato95 = 10,
                                   logit_f_ato95 = 11,
                                   logit_f_ato95 = 12,
                                   logit_f_ato95 = 13,
                                   logit_f_ato95 = 14,
                                   logit_f_ato95 = 15
                                   )
                                 )
na_map$logit_f_a50
na_map$logit_f_ato95


na_map_hybrid = fix_pars(par_list = true_pars, pars_to_exclude = c("ln_catch_sd", "ln_extra_survey_cv","ln_sigma_r", "ln_F", "logit_f_a50", "logit_f_ato95"),
                         vec_elements_to_exclude = list(logit_f_a50 = 2:length(true_pars$logit_f_a50), logit_f_ato95 = 2:length(true_pars$logit_f_ato95)))
na_map_hybrid = set_pars_to_be_the_same(par_list = true_pars, map = na_map_hybrid,
                                 base_parameters = append(rep(list(logit_f_a50 = c(1)), TMB_data$n_fisheries - 1),rep(list(logit_f_ato95 = c(1)), TMB_data$n_fisheries - 1)),
                                 copy_parameters = list(
                                   logit_f_a50 = 2,
                                   logit_f_a50 = 3,
                                   logit_f_a50 = 4,
                                   logit_f_a50 = 5,
                                   logit_f_a50 = 6,
                                   logit_f_a50 = 7,
                                   logit_f_a50 = 8,
                                   logit_f_a50 = 9,
                                   logit_f_a50 = 10,
                                   logit_f_a50 = 11,
                                   logit_f_a50 = 12,
                                   logit_f_a50 = 13,
                                   logit_f_a50 = 14,
                                   logit_f_a50 = 15,
                                   logit_f_ato95 = 2,
                                   logit_f_ato95 = 3,
                                   logit_f_ato95 = 4,
                                   logit_f_ato95 = 5,
                                   logit_f_ato95 = 6,
                                   logit_f_ato95 = 7,
                                   logit_f_ato95 = 8,
                                   logit_f_ato95 = 9,
                                   logit_f_ato95 = 10,
                                   logit_f_ato95 = 11,
                                   logit_f_ato95 = 12,
                                   logit_f_ato95 = 13,
                                   logit_f_ato95 = 14,
                                   logit_f_ato95 = 15
                                   )
)
ASM_obj <- MakeADFun(TMB_data, true_pars, DLL= "SimpleAgestructuredModelMultiFs", map = na_map, checkParameterOrder = T)
true_report = ASM_obj$report()
TMB_data_alt = TMB_data
TMB_data_alt$F_method = 1
ASM_obj_hybrid_F <- MakeADFun(TMB_data_alt, true_pars, DLL= "SimpleAgestructuredModelMultiFs", map = na_map, checkParameterOrder = T)
```

```{r self_test, echo = T, eval = T}
## simulate data
set.seed(123)
sim_data = ASM_obj$simulate(complete = T)

## Build AD TMB functions
start_pars = ran_start_vals()
est_model_est_F = MakeADFun(sim_data, true_pars, DLL= "SimpleAgestructuredModelMultiFs", map = na_map, silent = T)
sim_data$F_method = 1
sim_data$F_iterations = 4
est_model_hybrid_F = MakeADFun(sim_data, true_pars, DLL= "SimpleAgestructuredModelMultiFs", map = na_map_hybrid, silent = T)
## optimise
opt_model_est_F = nlminb(est_model_est_F$par, est_model_est_F$fn, est_model_est_F$gr, control = list(iter.max = 10000, eval.max = 10000))
opt_model_hybrid_F = nlminb(est_model_hybrid_F$par, est_model_hybrid_F$fn, est_model_hybrid_F$gr, control = list(iter.max = 10000, eval.max = 10000))

## look at the number of iterations used to solve
opt_model_hybrid_F$iterations
opt_model_est_F$iterations

## get reports = 
rep_est_hybrid = est_model_hybrid_F$report(est_model_hybrid_F$env$last.par.best)
rep_est_F = est_model_est_F$report(est_model_est_F$env$last.par.best)

plot(TMB_data$years, rep_est_hybrid$ssb[-1], type = "l", lwd = 3, xlab = "Year", ylab = "SSB", ylim = c(0,46000))
lines(TMB_data$years, rep_est_F$ssb[-1], type = "l", lwd = 3, lty = 2, col = "purple")
lines(TMB_data$years, sim_data$ssb[-1], type = "l", lwd = 4, lty = 3, col = "red")
legend("topright", col = c("black", "purple", "red"), legend = c("Hybrid", "Est F", "OM"), lwd = 3)
```


```{r firstbenchmarks, echo = T, eval = T}
est_F_bench = benchmark(obj = est_model_est_F, n = 1000)
hybrid_F_bench = benchmark(obj = est_model_hybrid_F, n = 1000)
est_F_bench
hybrid_F_bench
```



```{r secondbenchmarks, echo = T, eval = T}
ben_est_F <- benchmark(obj = est_model_est_F, n=20,expr=expression(do.call("optim",obj)))
ben_hybrid_F <- benchmark(obj = est_model_hybrid_F, n=20,expr=expression(do.call("optim",obj)))
ben_est_F
ben_hybrid_F
```


These results have highlighted the following

- Both the Free \(F\) and hybrid estimate very similar model quantities i.e., SSB's and F's
- The Free \(F\) method is much faster on average for a single gradient calculation and function call compared to the hybrid method
- However, the hybrid method requires less iterations due to there being less estimated parameters. For this simulation where we assumed 15 fisheries both optimised in similar amounts of time


## Appendix - Hybrid approach {-}
The hybrid fishing mortality process uses the methods and algorithms applied in Stock Synthesis [@methot2013stock]. The descriptions below are heavily based on the text describing this approach in the Appendix of [@methot2013stock].

This process begins by calculating popes discrete approximation, and then converts this to Baranov fishing mortality coefficients. A tuning algorithm is then done to tune these coefficients to match input catch nearly exactly, rather than the full Baranov approach.

Total mortality, denoted by \(Z_{a,y,s,r}\) for sex \(s\), region \(r\), age \(a\) and year \(y\) will hereby be denoted by \(Z_{a,y,s}\) i.e., drop the region index. This is because mortality rates are calculated independently (in isolation) among regions (**NOTE** consider parallelising this in the model).

\begin{equation*}
	Z_{a,y,s} = M_{a,y,s} + \sum\limits_{f} S^g_{y,s} F^g_y
\end{equation*}

where, \( M_{a,s}\) is the natural mortality rate, \( F^g_y\) is fishing mortality and \(S^g_{a,s}\) is the selectivity.

The hybrid fishing mortality method allows the \(F\) values to be "tuned" to match input catch nearly exactly, rather than estimating them as free model parameters. The process begins by calculating mid year exploitation rate using Pope’s approximation. This exploitation rate is then converted to an approximation of the Baranov continuous \(F\). The \(F\) values for all fisheries operating in that year and region are then tuned over a set number of iterations (`f_iterations`) to match the observed catch for each fishery with its corresponding \(F\). Differentiability is achieved by the use of Pope's approximation to obtain the starting value for each \(F\) and then the use of a fixed number of tuning iterations, typically 4. Tests from Stock Synthesis have shown that modelling \(F\) as hybrid versus \(F\) as a parameter has trivial impact on the estimates of the variances of other model derived quantities. 

The hybrid method calculates the harvest rate using the Pope's approximation then converts to an approximation of the corresponding F as:

\begin{align}
	V^g_{y} &= \sum\limits_s\sum\limits_a N_{a,y,s} \exp\left(-\delta_t M_{a,s}\right) \nonumber \\
	\tilde{U}^g_{y} &= \frac{C^g_{y}}{V^g_{y} + 0.1 C^g_{y}}\\
	j^g_{y} &= \left(1 + \exp \left(30 (\tilde{U}^g_{y} - 0.95) \right)\right)^{-1}\\
	U^g_{y} &= 	j^g_{y} \tilde{U}^g_{y} + 0.95 (1 - j^g_{y} )\\
	\tilde{F}^g_{y} &= \frac{-\log\left(1 - U^g_{y}\right)}{\delta_t}
\end{align}

where, \(C^{g}_y\) is the observed catch, \(\delta_t\) is the duration of the period of observation within the year. In most situations where the entire catch has been observed in a time-step. This should be one. \(V^g_{y}\) is partway vulnerable biomass and \(\tilde{F}^g_{y}\) is the initial \(F\).

The formulation above is designed so that high exploitation rates (above 0.95) are converted into an F that corresponds to a harvest rate of close to 0.95, thus providing a more robust starting point for subsequent iterative adjustment of this F. The logistic joiner, \(j\), is used at other places in Stock Synthesis to link across discontinuities.

The tuning algorithm begins by setting \(F^g_{y} = \tilde{F}^g_{y}\) and repeating the following algorithm `f_iteration` times.

\[
\widehat{C}_{a,y,s}  = \sum\limits_g {F}^g_{y}S^g_{a,s} N_{a,y,s}\bar{w}_{a,y,s} \lambda^*_{a,y,s}
\]

where, \( \lambda^*_{a,y,s}\) denotes the survivorship and is calculated as:

\begin{equation}
 \lambda^*_{a,y,s} = \frac{1 - \exp\left(-\delta_t Z_{a,y,s}  \right) }{Z_{a,y,s}}
   (\#eq:survival)
\end{equation}

Total fishing mortality is then adjusted over several fixed number of iterations (typically four, but more in high F and multiple fishery situations). The first step is to calculate the ratio of the total observed catch over all fleets to the predicted total catch according to the current F estimates. This ratio provides an overall adjustment factor to bring the total mortality closer to what it will be after adjusting the individual \(F\) values.

\[
\widehat{C}_{y}  =  \sum\limits_g \sum\limits_s\sum\limits_a {F}^g_{y}\left(S^g_{a,s} N_{a,y,s}\right) \lambda^*_{a,y,s}
\]

This is different from Equation A.1.25 in the Appendix of [@methot2013stock]. They include \(Z_{a,y,s}\) in the denominator when describing \({F}^g_{y}\), I think this is a typo error because \(Z_{a,y,s}\) is already included in the denominator when calculating \(\lambda^*_{a,y,s}\) (see Equation \@ref(eq:survival)).

\[
Z^{adj}_y = \frac{\sum\limits_g C^g_{y}}{\widehat{C}_{y}}
\]

The total mortality if this adjuster was applied to all the Fs is then calculated:

\[
Z^*_{a,y,s} = M_{a,s} + Z^{adj}_y \left(Z_{a,y,s} -M_{a,s} \right)
\]

\[
\lambda^*_{a,y,s} = \frac{1 - \exp\left(-\delta_t Z^*_{a,y,s}  \right) }{Z^*_{a,y,s}}
\]

The adjusted mortality rate is used to calculate the total removals for each fishery, and then the new \(F\) estimate is calculated by the ratio of observed catch to total removals, with a constraint to prevent unreasonably high \(F\) calculations (`max_f`):

\begin{align*}
	\tilde{V}^g_{y} &= \sum\limits_s\sum\limits_a \left(N_{a,y,s} \bar{w}_{a,y,s}S^g_{a,s} \right)\lambda^*_{a,y,s} \\
	F^{g*}_{y} &= \frac{C^g_{y}}{\tilde{V}^g_{y} + 0.0001}\\
	j^{g*}_{y} &= \left(1 + \exp \left(30 (F^{g*}_{y} - 0.95 F_{max}) \right)\right)^{-1}\\
\end{align*}

where, \(F_{max}\) is a user defined maximum fishing mortality `f_max`. The \(F\) at the end of each tuning iteration follows: 

\[
F^g_{y} = j^{g*}_{y} F^{g*}_{y} + \left(1 - j^{g*}_{y}\right)F_{max}
\]

After the tuning algorithm removals at age, and other derived quantities are recorded. The final total mortality is updated
\[
	Z_{a,y,s} = M_{a,s} + \sum\limits_{g} S^g_{a,s} F^g_{y}
\]

This process generates catch at age and sex for each year (and region) (\(\widehat{C}^g_{a,y,s}\)) which can be accessed by `process_removals` observations. Numbers at age are calculated as

\[
\widehat{C}^g_{a,y,s} = \frac{F^g_{a,s,y}}{Z_{a,y,s}} N_{a,y,s} \exp\left(-Z_{a,y,s}\right)
\]

Total catch is the summed over all sexes and age 

\[
\widehat{C}^g_{y} = \sum\limits_s\sum\limits_a \widehat{C}^g_{a,y,s}  \bar{w}_{a,y,s}
\]

where \(\bar{w}_{a,y,s}\) is the mean weight


<!--chapter:end:05-ExploreFParameterisations.Rmd-->

# Initialising the plus group in spatial models {#spatialInit}

In single area age-structured models, the plus age group is calculated using a solution to an infinite geometric series. This solution for an age-structured model is used to derive initial (equilibrium) state of the partition. The partition consists of a vector of numbers at age for each category denoted by \(\textbf{N}\);
\[
\textbf{N} = (N_1, N_2, ... , N_{a_+})^T
\]

where \(N_{a_+}\) denotes the numbers in the plus group. The numbers at age for a single area population with no density-dependent processes is derived as,

\[
N_a = \left\{ \begin{array}{lcl}
	R_0 & \mbox{for} & a = 1
	\\ 
	R_0e^{-aM}  & \mbox{for} & 1 < a < a_+
    \\
	R_0e^{\sum_{i = a_+}^\infty-iM} & \mbox{for} & a = a_+
\end{array}\right.
\]

Initialization for ages \(1 \leq a < a_+\) is easy, all you need to do is iterate the model \(a_+ - 1\) times and the age classes will be populated with there respected initial numbers at age. However, for the plus group (\(N_{a_+}\)) the solution is needed.

Although the plus group may start at let say 30 years old, it actually represents 30 and 31 and 32 up to some biological plausible value lets say 130, but mathematically can be thought of as \(\infty\). The plus group is modeled for practical reasons and care should be given when choosing the cut-off maximum age. The plus group is an infinite geometric series that is defined by the common ratio \(r_{a_+}\).

\begin{align}
N_{a_+} &= R_0e^{\sum_{a = a_+}^\infty-aM}\\
        &= R_0 \frac{e^{M - a_+M}}{1 - e^{-M}}
\end{align}
```{r illustrateplusGroup}
M = 0.1
R0 = 4e6
plus_group_age = 30
N_age = R0 * exp(-M * 1:plus_group_age)
## numerically calculate it
N_plus_group =  tail(N_age, n = 1)
for(i in 1:10000) {
  N_plus_group = N_plus_group * exp(-M) + tail(N_age, n = 1) * exp(-M)
}
N_plus_group
## using the geometric series calculation
R0 * exp(-M - plus_group_age*M) / (1 - exp(-M))
```

The question becomes, how do we calculate this plus group when there is markovian movement as well as? This code shows how the same infinite geometric series solution works for the plus group with movement. Instead of using just natural mortality (\(M\)) you also need how much the plus group accumulates from the movement process. Let \(c\) denote the initial accumulation the plus group in a given region receives from ageing, natural mortality and movement. Then the plus group for that region can be 

\[
N_{a+, r} = N_{a+ - 1, r} \frac{1}{1 - c}
\]
where, \(N_{a+ - 1, r}\) is the numbers at age for the second to last age cohort in the plus group. The following R code shows how this is equivalent to running the annual cycle for 1000 years.

```{r spatialcase}
M = 0.1
R0 = 4e6
n_regions = 3
movement_matrix = matrix(0, nrow = n_regions, ncol = n_regions);
movement_matrix[1,] = c(0.7, 0.2, 0.1)
movement_matrix[2,] = c(0.1, 0.6, 0.3)
movement_matrix[3,] = c(0.15, 0.05, 0.8)
## rows are "from" cols are "to"
plus_group_age = 30
## partition
N_age = matrix(0, nrow = n_regions, ncol = plus_group_age)
## initialise with no movement initially
N_age[1,] = R0 * exp(-M * 1:plus_group_age) ##
N_age[2,] = R0 * exp(-M * 1:plus_group_age) ## 
N_age[3,] = R0 * exp(-M * 1:plus_group_age) ##

## apply an annual cycle 10000 times to see what the "initial conditions should be"
N_next_year_age = N_age
for(i in 1:1000) {
  ## recruitment
  N_next_year_age[,1] = R0 * exp(-M)
  ## ageing and mortality
  N_next_year_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M)
  ## plus group
  N_next_year_age[,plus_group_age] = N_next_year_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M)
  ## movement
  N_age = t(movement_matrix) %*% N_next_year_age
}
iterative_N_age = N_age
plot(1:plus_group_age, N_age[3,], xlab = "Age", ylab= "Initial numbers", ylim = c(0,R0* 1.4), type = "l", lwd = 3)
lines(1:plus_group_age, N_age[2,], lwd = 3, col = "red", lty = 2)
lines(1:plus_group_age, N_age[1,], lwd = 3, col = "blue", lty = 2)
legend('topright', col = c("black","red","blue"), legend = c("Region 3", "Region 2", "Region 1"), lwd = 3)

```

```{r spatialcase_alt}
N_age = matrix(0, nrow = n_regions, ncol = plus_group_age)
update_N_age = N_age
for(i in 1:(plus_group_age)) {
  # recruitment
  update_N_age[,1] = R0 * exp(-M)
  # ageing and mortality
  update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M)
  # plus group
  update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M)
  # movement
  N_age = t(movement_matrix) %*% update_N_age
}
## calculate one more annual cycle
# recruitment
update_N_age[,1] = R0 * exp(-M)
# ageing and mortality
update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M)
# plus group
update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M)
# movement
update_N_age = t(movement_matrix) %*% update_N_age
## approximate!
c = update_N_age[,plus_group_age] / N_age[,plus_group_age] - 1
update_N_age[,plus_group_age] = N_age[,plus_group_age] * 1 / (1 - c)

iterative_N_age[,plus_group_age]
update_N_age[,plus_group_age]

plot(1:plus_group_age, iterative_N_age[3,], xlab = "Age", ylab= "Initial numbers", ylim = c(0,R0* 1.4), type = "l", lwd = 3)
lines(1:plus_group_age, update_N_age[3,], lwd = 3, col = "red", lty = 2)

lines(1:plus_group_age, iterative_N_age[2,], lwd = 3, col = "black", lty = 1)
lines(1:plus_group_age, update_N_age[2,], lwd = 3, col = "red", lty = 2)
lines(1:plus_group_age, iterative_N_age[1,], lwd = 3, col = "black", lty = 1)
lines(1:plus_group_age, update_N_age[1,], lwd = 3, col = "red", lty = 2)
legend('topright', col = c("black","red"), legend = c("Numerical", "Analytical"), lwd = 3, lty = c(1,2))

```




<!--chapter:end:06-InitialisingTheSpatialModel.Rmd-->

# Spatial model inputs {#spatialmodelInputs}

This chapter describes how raw age/length and catch data were utilised to derive assessment inputs for a myriad of spatially structured assessments. The chapter aims to standardize the methods so that we can easily re-work the data to be fit in an 1,2 or \(n_r\) area assessment model.




```{r LLRegions, out.width = '100%', fig.height= 5, fig.cap="The finest spatial resolution that we are considering for Sablefish assessment", echo = F, eval = T}
include_graphics(file.path("Figures", "Longline_areas.png"))
```


## Survey Abundance data {#surveyData}

I am thinking, when it comes to the real data application that we apply a geostatistical model-based estimator. The survey is a systematic/fixed design (Do the visit the same locations each year? obviously ignoring the AI BS switching), but use a stratified survey estimator for the population mean and variance. I am wondering if this will over state the precision? A useful reference for changes in survey operators for the Alaskan sablefish is @kimura1997standardizing. "The Japanese long-line gear used in the joint surveys and the NMFS long-line gear are similar in many respects...Differences between Japanese sampling gear and NMFS sampling gear were mostly due to hook and gangion construction"


```{r surveycatchgif, fig.cap="A time-series of sablefish catch from the long line survey pooled over 50km by 50km grided cells", eval = T, echo = F}
knitr::include_graphics("Figures/catch.gif")
```

## Age-frequency {#AFs}
A big challenge of any spatial stock assessment is deriving spatially disaggregated age-frequency observations from low age sample sizes. For both the long-line survey and fishery we have both age and length data sets. This means there are multiple estimators available. These include direct ageing, length frequency analysis [@andrade2004estimation] (Length frequency analysis decomposes length frequency histograms into age classes) and age-length key [@ailloud2019general;@hoenig2002generalizing]. The forward age-length key method at face value is the most attractive as it reduces sparsity and variation when compared to direct ageing estimators.


A note on sablefish otolith samping from the survey.
"Otolith collections were length-stratified from 1979-94 and random thereafter" pg 9 of @sigler2001alaska

```{r agesamples, out.width = '100%', fig.height= 5, fig.cap="Number of aged fish by sex, region and year", echo = F, eval = T}
include_graphics(file.path("Figures", "age_samples_by_year_region_sex.png"))
```

### Direct Ageing estimator {-}



### Length-frequency {-}


```{r lengthsamples, out.width = '100%', fig.height= 5, fig.cap="Number of fish measured for length by sex, region and year", echo = F, eval = T}
include_graphics(file.path("Figures", "length_samples_by_year_region_sex.png"))
```


## Observer data {#ObserverData}


## Catch data {#CatchData}


## Appendix {-}

Sampling notation
+----------------------------+-----------------------------------------------------------------------------+
| Symbol                     | Description                            
+============================+=============================================================================+
| \(h\)                      | haul index
+----------------------------+-----------------------------------------------------------------------------+
| \(C^h\)                    | Catch for haul \(h\) can be numbers or biomass
+----------------------------+-----------------------------------------------------------------------------+
| \(n^h_l\)                  | number of fish measured for length from haul \(h\) 
+----------------------------+-----------------------------------------------------------------------------+
| \(n^h_a\)                  | number of fish aged in from haul \(h\). Assumed to be a subsample of \(n^h_l\)
+----------------------------+-----------------------------------------------------------------------------+




```{r femaleCDFagesamples, out.width = '100%', fig.height= 10, fig.cap="CDF of age frequencies for females", echo = F, eval = T}
include_graphics(file.path("Figures", "raw_ecdf_AFs_by_year_region_female.png"))
```

```{r maleCDFagesamples, out.width = '100%', fig.height= 10, fig.cap="CDF of age frequencies for males", echo = F, eval = T}
include_graphics(file.path("Figures", "raw_ecdf_AFs_by_year_region_male.png"))
```


```{r femaleCDFlengthsamples, out.width = '100%', fig.height= 10, fig.cap="CDF of length frequencies for females", echo = F, eval = T}
include_graphics(file.path("Figures", "raw_ecdf_LFs_by_year_region_female.png"))
```

```{r maleCDFlengthsamples, out.width = '100%', fig.height= 10, fig.cap="CDF of length frequencies for males", echo = F, eval = T}
include_graphics(file.path("Figures", "raw_ecdf_LFs_by_year_region_male.png"))
```

<!--chapter:end:07-CalculatingInputsForSpatialModels.Rmd-->

# Tagging data and studies {#tagdata}
Since 1972 there have been approximately 400 000 sablefish tagged in Alaska waters, of which over 38 500 have been recovered. Although there is extensive and long term tagging data, this information is not currently directly included in the stock assessment [@goethel2021assessment].


Historical publications investigating movement of Alaskan sablefish include @heifetz1991movement, @hanselman2015move

## Integrating tagging observations in spatial age-structured models

This project intends to explore a range of methods for utilising tag-recovery observations in spatially disaggregated age-structured stock assessments.

## Tagging things to consider with relevant references {-}

- Years to retain tagged fish in the partition "After approximately 9 yr the number of recaptures was small and contributed more to the variance associated with the trends in movement than an improved understanding of these trends" @beamish_88
- Reporting rates [@heifetz2001estimation]
- Scan detection rates. Is this not a factor of reporting rates?
- Mixing time and how to deal with it?
- Tag loss "tag loss in the fist year was approximately 10% and after that approximately 2% per year." @beamish_88
- Release conditioning vs recapture conditioning [@vincent2020parameter;@mcgarvey2002estimating]
- likelihood choice? [@hanselman2015move]


## Releasing tags {-}
Tag release events involve releasing a tag-cohort at the beginning of a year within a specific area assumes tag cohort indexed by \(k\) has an implied year \(y\) and region \(r\) index. \(\boldsymbol{N}^k\) is used to denote a vector of lengths or ages for tag-cohort \(k\). In general, only the length frequency is known at time of release for each tag-cohort. We explore two different methods for seeding tagged numbers at age for each tag-cohort within spatial age-structured models. The two methods are either do it internal or external. The internal method requires users to supply length frequency for each tag-cohort and the model will use the assumed growth assumptions to convert the lengths to ages. The external approach is to use an age-length key outside of the model to derive an age frequency that can be supplied to the model. 

A frequent assumption of age-structured tagging models in the literature [@maunder1998integration;@vincent2020parameter] is that the age-frequency of each tag-cohort are known. Due to the fact that ageing is a fatal process, we assume they use an age-length key to convert lengths to ages. If the age-length key is representative of the vulnerable population at the time of tagging, then this method is expected to be have better computational performance. Factors to consider at time of release are; Gear method used to select releases, where releases occur, and time of releases. The internal method can attribute the correct age-distribution if the selectivity/availability by age is correct i.e. using the correct selectivity. Also, if growth is internally estimated within the assessment model, then the internal method may be prefered as to keep the growth assumptions consistent between LF observations and tagging observations.


One consideration if the tag releases and recoveries are both length-based is the age-length transition assumptions. Due to age-structured modelling growth as length conditional on age. Moving individuals back and forwards through the age-length transition matrix (length $\rightarrow$ age $\rightarrow$ length) will cause "smearing" of length frequencies. This is demonstrated in Figures \@(ref:addagelength) and \@(ref:showagelengthtransition_problem), and needs to be considered when considering model fitted values for observations and corresponding likelihood assumptions. Given this phenomenon, it could be argued, that the external age-length key approach is better as it makes these assumptions explicit (more transparent). However, both methods will be affected by this growth transition phenomenon to one degree or another. 

```{r addagelength, out.width = '70%', echo = F, eval = T, fig.cap='An example of theoretical length at age, with overlapping length bins used to describe the effect of going back and fourth through the age-length transition matrix.'}
ages = c(1:30) # as.numeric(names(ibm_out$init_1$values))
lens_bins = c(seq(from = 4, to = 10, by = 2), 11:81) # ibm_out$model_attributes$length_mid_points
lens = lens_bins[1:(length(lens_bins) - 1)] + diff(lens_bins) / 2

## simple illustrations
example_ages = 1:3
mean_length = c(13,19,24)
len_bins = seq(10,35,by = 5)
len_midpoints = len_bins[1:5] + diff(len_bins)/2
## randomly get some ages and lengths
Num_age = #rowSums(prob_length_given_age_matrix[c(6,9,13),c(32,35,42,45,50)]) / 100
  c(1757.704, 4320.569, 3129.675)
cv = 0.13
## generate age-length probability transition matrix used in age-based models
prob_length_given_age = matrix(0.0, nrow = length(example_ages), ncol = length(len_bins) - 1)
for(age_ndx in 1:length(example_ages)) {
  for(len_ndx in 2:length(len_bins)) {
    if (len_ndx == 2) {
      prob_length_given_age[age_ndx, len_ndx - 1] = pnorm(len_bins[2], mean_length[age_ndx], mean_length[age_ndx] * cv)
    } else if (len_ndx == length(len_bins)) {
      prob_length_given_age[age_ndx, len_ndx - 1] = 1 - pnorm(len_bins[length(len_bins) - 1], mean_length[age_ndx], mean_length[age_ndx] * cv)
    } else {
      prob_length_given_age[age_ndx, len_ndx - 1] = pnorm(len_bins[len_ndx], mean_length[age_ndx], mean_length[age_ndx] * cv) -  pnorm(len_bins[len_ndx - 1], mean_length[age_ndx], mean_length[age_ndx] * cv)
    }
  }
}

Cols = colorRampPalette(brewer.pal(n = 7, name = "Blues"))(5)[2:5]
plot(1:40, 1:40, type = "n", xlab = "Length", yaxt = "n", ylab = "Frequency", xlim = c(7,35), ylim = c(0,800), main = "Example length at age distribution")
temp_lens = 1:40
probs = seq(0.01,0.99, length = length(temp_lens))
for(i in 1:length(example_ages)) {
  lines(y = Num_age[i] * dnorm(temp_lens, mean_length[i], cv *  mean_length[i]) / sum(dnorm(temp_lens, mean_length[i], cv *  mean_length[i])), x = temp_lens, lwd = 3, col = Cols[i])
}
text(x = mean_length, y = 238, labels = paste0("a = ",example_ages), cex = 1.1, col= Cols)
text(x = len_midpoints, y =  773, labels = c(expression(l[1]),expression(l[2]),expression(l[3]),expression(l[4]),expression(l[5])), cex = 1.5, col= "red")

abline(v = len_bins, lty = 2, col = "red", lwd = 2)
group_name =  c(expression(l[1]),expression(l[2]),expression(l[3]),expression(l[4]),expression(l[5]))
```


```{r showagelengthtransitionproblem, out.width = '100%', fig.height= 4, fig.cap="A visualisation of the effect of going back and forth through an age-length transition matrix. This can happen when tag releases and recaptures are input as length in an age-structured model. The model converts lengths to ages, then reconverts the age to length for observations. This is assuming the same age-length relationship in Figure \\@ref(fig:addagelength)", echo = F, eval = T}
#############
# A fish in length bin l2
#############
# probability of length given age = prob_length_given_age
#rowSums(prob_length_given_age)
# What about probability of age given length? re-scale
prob_age_given_length = sweep(prob_length_given_age, STATS = colSums(prob_length_given_age), MARGIN = 2, FUN = "/")

dimnames(prob_length_given_age) = dimnames(prob_age_given_length)  = list(example_ages, len_midpoints)
prob_length_given_age_long = melt(prob_length_given_age)
colnames(prob_length_given_age_long) = c("age", "length","prop")
prob_length_given_age_long$age = factor(prob_length_given_age_long$age)
prob_length_given_age_long$length = factor(prob_length_given_age_long$length)

prob_length_given_length_long = melt(prob_age_given_length)
colnames(prob_length_given_length_long) = c("age", "length","prop")
prob_length_given_length_long$age = factor(prob_length_given_length_long$age)
prob_length_given_length_long$length = factor(prob_length_given_length_long$length)

test = ggplot(prob_length_given_length_long, aes(fill=age, y=prop, x=length)) + 
  geom_bar(position="stack", stat="identity") +
  xlab("Numbers") +
  ggtitle("Age composition conditioned on length bin")+
  scale_x_discrete(labels=group_name)  # Ad

test_alt = ggplot(prob_length_given_age_long, aes(fill=length, y=prop, x=age)) + 
  geom_bar(position="stack", stat="identity") +
  xlab("") +
  ggtitle("Length composition conditioned on age")+
  scale_fill_discrete(labels=group_name)  # Ad

## In an age based model
## A single Fish in length bin = 2, equates to the following ages
age_from_l2 = prob_age_given_length[,2]
#age_from_l2
## The model derived lenght distribution of this
model_length = age_from_l2 %*% prob_length_given_age
#model_length

P1 = ggplot(data = data.frame(length = factor(len_midpoints), result = c(0,1,0,0,0)), aes(y=result, x=length)) + 
  geom_bar(position="dodge", stat="identity") +
  ylab("Numbers") +
  xlab("Length bin") +
  ylim(0,1) +
  ggtitle(substitute(paste("Single fish in length bin = ", l[len_ndx]), list(len_ndx = 2))) +
  theme(axis.text.x=element_text(size=15),axis.text.y=element_text(size=15),
        axis.title=element_text(size=15,face="bold"),
        title =element_text(size=13)) +
  scale_x_discrete(labels=group_name) +
  theme_bw()

P2 = ggplot(data = data.frame(age = factor(example_ages), result = age_from_l2), aes(x = age, y = result)) + 
  geom_bar(position="dodge", stat="identity") +
  ylab("") +
  ylim(0,1) +
  ggtitle(substitute(paste("Age disribution of fish in length bin = ", l[len_ndx]), list(len_ndx = 2))) +
  theme(axis.text.x=element_text(size=15),axis.text.y=element_text(size=15),
        axis.title=element_text(size=15,face="bold"),
        title =element_text(size=13)) +
  theme_bw()



P3 = ggplot(data = data.frame(length = factor(len_midpoints), result = as.numeric(model_length)), aes(y=result, x=length)) + 
  geom_bar(position="dodge", stat="identity") +
  ylab("") +
  ylim(0,1) +
  xlab("Length bin") +
  ggtitle(substitute(paste("Length distribution of initial fish = ", l[len_ndx]), list(len_ndx = 2))) +
  theme(axis.text.x=element_text(size=15),axis.text.y=element_text(size=15),
        axis.title=element_text(size=15,face="bold"),
        title =element_text(size=13)) +
  scale_x_discrete(labels=group_name) +
  theme_bw()# Ad


P1 = P1 + geom_segment(aes(x = 4, y = 0.5, xend =5, yend = 0.5, size = 1),
               arrow = arrow(length = unit(1, "cm")), col = "red") +
  guides(size = "none")
P2 = P2 + geom_segment(aes(x = 3.8, y = 0.5, xend =5, yend = 0.5, size = 1),
                 arrow = arrow(length = unit(1, "cm")), col = "red") +
  guides(size = "none")
grid.arrange(grobs = list(P1, P2, P3), nrow = 1)
```

#### Internal method {-}
Age-structured stock assessment models contain growth models, which describe length conditioned on age. This requires assumptions on the distribution and associated parameters. The default is often the normal distribution with mean length at age denoted by \(\bar{l}_a\) with standard deviation parameterised as a coefficient of variation (\(\sigma_a = cv*\mu_a\)). This information enables the model to derive a growth transition matrix \(P_{l|a}\). Given the lower and upper limits for each length bin denoted as \(\boldsymbol{b} = (b_1, b_2, \dots, b_{max})'\), the probability of being in length bin \(l\) given age \(a\)

\begin{equation}
P_{l|a} = 
\begin{cases}
\Phi(b_{l + 1}|\mu_a,\sigma_a)\quad &\text{for } l = 1\\
\Phi(b_{l + 1}|\mu_a,\sigma_a) - \Phi(b_l|\mu_a,\sigma_a)\quad &\text{for } 1 < l < n_l\\
1 - \Phi(b_{l}|\mu_a,\sigma_a)\quad &\text{for } l = n_l
\end{cases}
  (\#eq:agelengthtransition)
\end{equation}


where \(\Phi(x|\mu,\sigma)\) is the cumulative normal (but could be generalised to any probability distribution). If growth varies by attributes such as sex, stock or region then this will need to be calculated for each growth model. In the SNA1 stock assessment each stock has a different growth curve and is denote as \(P^s_{a|l}\)

At the point a tag cohort is released, the model can derive the length composition of the vulnerable population using the transition matrix derived in Equation \ref(eq:agelengthtransition). Given the number of estimable parameters that govern the age-stricture at a point in time and growth model, an exploitation rate is calculated so that if there are not enough numbers in a length bin to be tagged, a penalty can be added to the objective function to dissuade the combination of parameters that generated this situation. Tag-release by length is a known quantity and so the model must allow for a minimum vulnerable length composition to that released. To enforce this a exploitation like rate by each length \((u_l)\) is calculated as follows,
\begin{equation}
u_l = \frac{N^k_{l}}{\sum_a}N_{y_k,a,r_k} P_{l|a}
  (\#eq:lengthexploit)
\end{equation}

During parameter estimation there are no constraints within the model to trial a set of parameters than will allow \(u_l > 1\) i.e. more observed tag-releases than in the vulnerable population. To stop negative numbers at age \(u_l\) is set at a level less than 1 and a penalty added to the objective function to discourage parameters from allowing this condition. Finally tag-release at age is calculated as follows,
\begin{equation}
N^k_{a} = N_{y_k,a,r_k}  P_{l|a} u_l
  (\#eq:tagatagerelease)

\end{equation}

Once the tag cohort are created in the model it is assumed that tagged fish are exposed to the same dynamics as un-tagged fish.


#### External method (Age-length key method) {-}
Once a tag-release event has occurred for tag group \(k\), the only known knowledge is the length distribution \(N^k_l\). Assuming there is an accessible forward age-length key which describes the proportion of ages for a given length bin \(\left(P_{a|l}\right)\) that is representative of the vulnerable population to tagging for the same area and time, then the "forward" or "classic" key method can be used @ailloud2019general. If tag-release coincide with a fishing season you could use fishery-dependent derived age length information, assuming the selectivity curves within a length bin are parallel. If only a subset of fish from each haul is released, it would be better to construct an age-length key from a representative sample of fish that were caught by not-tagged. This would be relevant for single vessel survey release events.
\begin{equation}
	N^k_a = \sum\limits_{l = 1}P_{a|l}N^k_l
\end{equation}
where, \(N^k_a\) is used as an known input into the model with no error. 


#### Things to consider for tag release {-}

- we don't have much information regarding sex of tagged fish (36.5\% of recovered tags have sex information). Does this lean towards the internal method? can allocate sex ratio based on vulnerable population which may be important, if there is quite a difference in sex disaggregated selectivities.


## Tag recovery observations {-}
There are tow types of tag-recovery observations that we will consider in this work, tag-release conditioned and tag-recapture conditioned. This conditioning relates to whether we relate recoveries to the release event or whether we only look at the recoveries relative to other recoveries within a year [@vincent2020parameter;@mcgarvey2002estimating]. This conditioning relates more to the log-likelihood formulation rather than the model expected values. We should also explore two different approaches regarding the scanned fish of which tag-recoveries are a subset. The first is recoveries were entirely from a fishery which requires some understanding or assumptions on reporting rates. The other method assumes scanned fish are known, which is the approach used in the Casal2 [@doonan2016casal2] stock assessment program. This information can be recorded if the scanning is done either by observers who are recording LF's for the catch or scientific/trained staff when shed sampling landed catch. Both these scanning approaches will require an assuming or information on detection rates.





## Growth estimation using the Laslett–Eveson–Polacheck (LEP) method 
Going to investigate the use of “Laslett–Eveson–Polacheck (LEP)” based on @laslett2002flexible \& @eveson2004integrated as described in @aires2015improved.


The idea is to use a single growth model that fits to two observational data sets (ideally within the assessment, however we will start outside for now. When including it in the assessment you will also have LF data to help inform growth). The first will describe age-at-length data from direct ageing. The second will be length increment data from tagging experiments. 


### Age-at-length growth model {-}

We start by using the Richards growth curve following @aires2015improved (but this could be extended). The Richards growth formulation follows

\begin{equation} 
  \bar{l}_{a} = L_{\infty} \left( 1 + \frac{1}{p} \exp \{-K(a - a_0)\}\right)^{-p}
  (\#eq:richardsgrowth)
\end{equation} 
where, \( \bar{l}_{a}\) is the mean length at age \(a\), \(L_{\infty}\) is the asymptotic length, \(K\) is the growth coefficient and \(p\) is a shape parameter that is related to the ratio \(\bar{l}_{a} / L_{\infty}\) at the inflexion point.

### Tag recapture growth data {-}
+----------------------------+-----------------------------------------------------------------------------+
| Symbol                     | Description                        
+============================+=============================================================================+
| \(l_{1,i}\)                | length of individual \(i\) at release
+----------------------------+-----------------------------------------------------------------------------+
| \(l_{2,i}\)                | length of individual \(i\) at recapture
+----------------------------+-----------------------------------------------------------------------------+
| \(a_{1,i}\)                | age of individual \(i\) at release. Denoted as \(A\) in @aires2015improved
+----------------------------+-----------------------------------------------------------------------------+
| \(a_{2,i}\)                | age of individual \(i\) at recapture
+----------------------------+-----------------------------------------------------------------------------+
| \(\Delta_t\)               | Time at liberty \(\Delta_t = a_{2,i} - a_{1,i}\)      
+----------------------------+-----------------------------------------------------------------------------+
**Just one comment on notation!!!** in most all the papers that use this method, they ignore the individual notation of \(A\). That is not an issue in general however it confuses me when they describe the prior on this.


The sub-models for the release and recapture lengths follow,
\begin{equation} 
  l_{1,i} = L_{\infty} \left( 1 + \frac{1}{p} \exp \{-K(a_{1,i} - a_0)\}\right)^{-p}
  (\#eq:lengthatrelease)
\end{equation} 

and,
\begin{equation} 
  l_{2,i} = L_{\infty} \left( 1 + \frac{1}{p} \exp \{-K(a_{1,i} + \Delta_t - a_0)\}\right)^{-p}
  (\#eq:lengthatrecapture)
\end{equation} 


The above growth model assumes that we know the age at recovery \(a_{2,i}\). The problem we have is, we have 22 569 tag recoveries with length information but only a handful of these have been aged. This is dealt with by modelling \(a_{1,i}\) as a random effect i.e., \(a_{1,i} \sim LN \left(\mu, \sigma^2\right)\).

What confuses is me here is how to assign a hyper distribution like the one above for the random effect variables \(a_{1,i}\). \(a_{1,i}\) is expected to vary quite a bit because tagged fish at release have a broad length frequency and thus is expected to have a broad age at release? (ask someone about this because I may be misunderstanding something).

## Simulation test the "LEP" method {-}

```{r, simulate_data, echo = T, eval = T}
## going to use parameters from Aires-da-Silva et al. (2015) Table 1 integrated analysis
L_inf = 200.8
k = 0.44
t_0 = 1.26
p = -4.27
cv = 0.15 ## cv of length around length at age

## selectivity paraemters
sel_a50 = 1.3
sel_ato95 = 0.8
## sample sizes for simulation
n_sample_release = 1000
n_sample_recoveries = 1000 * 0.1 ## about the recovery rate from sablefish data
n_sample_age_length = 1000

## generate a pseudo age structure
set.seed(123)
R_0 = 200000
M = 0.29
ages = 1:20
n_ages = length(ages)
#plot(ages, mean_length_at_age, type = "l", lwd = 3, xlab = "Age", ylab = "Length (cm)")
sel_at_age = logis(ages, sel_a50, sel_ato95)

## numbers at age
N_age = vector(length = n_ages, "numeric")
for (age_ndx in 1:n_ages) 
  N_age[age_ndx] = R_0 * exp(-ages[age_ndx] * M) * exp(rnorm(1,0,0.7))

N_age = N_age * sel_at_age ## vulnerable numbers at age

plot(ages, N_age, ylab = "Numbers", xlab = "Age", main = "Population age-structure", type = "o")

## plot growth
mean_length_at_age = richards_growth(ages, p, k, t_0, L_inf)
## randomly sample 1000 individuals with replacement for otolithing no ageing error!!
## 
individual_age_length_df = NULL
for(i in 1:n_sample_age_length) {
  age_i = sample(1:n_ages, size = 1, prob = N_age)
  mean_length_i = richards_growth(age_i, p, k, t_0, L_inf)
  length_i = rnorm(1, mean_length_i, mean_length_i * cv)
  temp_df = data.frame(age = age_i, length = length_i)
  individual_age_length_df = rbind(individual_age_length_df, temp_df)
}

## Simulate a tag-recapture experiment 
# releases
release_ages = sample(1:n_ages, size = n_sample_release, prob = N_age, replace = T)
release_mean_lengths = richards_growth(release_ages, p, k, t_0, L_inf)
release_lengths = rnorm(n_sample_release, release_mean_lengths, release_mean_lengths * cv)
individual_release_df = data.frame(release_age = release_ages, release_length = release_lengths, release_mean_length = release_mean_lengths)
individual_release_df$fish_id = 1:nrow(individual_release_df)

# recaptures sample uniformly without replacement
fish_ndx = sample(1:nrow(individual_release_df), size = n_sample_recoveries, replace = F) 
individual_recovery_df = subset(individual_release_df, subset = individual_release_df$fish_id %in% fish_ndx)
## time-at liberty days randomly recovered on average between 100-600 days
individual_recovery_df$time_at_liberty = rpois(n = n_sample_recoveries, lambda = runif(n_sample_recoveries,100,600))
individual_recovery_df$recovery_age = individual_recovery_df$release_age + individual_recovery_df$time_at_liberty/365
## how to add the length increment between release and recovery?
individual_recovery_df$recovery_mean_length = richards_growth(individual_recovery_df$recovery_age, p, k, t_0, L_inf)
individual_recovery_df$recovery_mean_length_increment = with(individual_recovery_df, recovery_mean_length - release_mean_length)
individual_recovery_df$recovery_length = with(individual_recovery_df, release_length + rlnorm(n_sample_recoveries, log(recovery_mean_length_increment), cv))
individual_recovery_df$growth_change = individual_recovery_df$recovery_length - individual_recovery_df$release_length 

## visualise length at age samples
ggplot(individual_age_length_df, aes(x = age, y = length)) +
  geom_point() +
  geom_line(data= data.frame(length = mean_length_at_age, age = ages), aes(x = age, y = length), col = "red", linewidth = 1.2, inherit.aes = F) +
  labs(x = "Age", y = "Length") +
  ylim(0,NA)
```

Assumptions in the above OM follow.

\[
l_{1,i} \sim \mathcal{N} \left(\bar{l}_{1,a}, \sigma = \bar{l}_{1,a} \times cv\right)
\]
where the mean length at age release (\(\bar{l}_{1,a}\)) follows the Richards growth curve defined in Equation \@ref(eq:richardsgrowth). The age used to derive the mean length at age was a random sample with replacement from the population in shown in the earlier figure. Time at liberty was drawn from a Poisson distribution with a rate parameter randomly drawn from a uniform distribution between 100-600 days. The age at recovery \(a_{2,i} = a_{1,i} + \Delta_t\). An approximation was made when calculating the length at recovery. The length increment (\(l_{\Delta_t}\)) was simulated using a Log Normal distribution with the median set based on the difference between mean length at release age and mean length at recovery age. This was to ensure all recovered fish positively grew at a rate expected by the growth model (less than ideal but will do for now).
\[
l_{i,\Delta_t} \sim \mathcal{LN} \left(\ln (\bar{l}_{a_{2,i}} - \bar{l}_{a_{1,i}}), \sigma = cv\right)
\]

\[
l_{2,i} = l_{1,i} + l_{i, \Delta_t}
\]
In theory we can now pass this data to our LEP model to back estimate growth parameters.


```{r,compile_TMB_model, echo = T, results = 'hide', eval = T}
setwd(file.path("TMB"))
#sink(file = "compile_output.txt")
compile(file = "LEPgrowth_model.cpp", flags = "-Wignored-attributes -O3")
#sink()
dyn.load(dynlib("LEPgrowth_model"))
#setwd(DIR$book)
```


```{r, build_TMB_model, echo = T, eval = T, results = 'hide'}
# data
data = list()
data$ages_from_age_length = individual_age_length_df$age
data$lengths_from_age_length = individual_age_length_df$length
data$lengths_at_release = individual_recovery_df$release_length
data$lengths_at_recovery = individual_recovery_df$recovery_length
data$time_at_liberty = individual_recovery_df$time_at_liberty / 365
data$ages_for_report = ages;

data$p_bounds = c(-20, 20)
data$t0_bounds = c(-6, 4)

# parameters
parameters = list()
parameters$ln_cv_length_at_age = log(cv)
parameters$ln_k = log(k)
parameters$ln_L_inf = log(L_inf)
parameters$logit_p =  logit_general(p, data$p_bounds[1],data$p_bounds[2])
parameters$logit_t0 =  logit_general(t_0, data$t0_bounds[1],data$t0_bounds[2])
parameters$ln_cv_length_release = log(0.1)
parameters$ln_cv_length_recovery = log(0.1)
parameters$ln_age_at_release = log(individual_recovery_df$release_age)

parameters$ln_mu_age_release = log(3)
parameters$ln_sd_age_release = log(1)

obj_mixed_all <- MakeADFun(data, parameters, random = "ln_age_at_release", DLL="LEPgrowth_model")
```


```{r, optimise_TMB_model, echo = T, eval = T, results = 'hide'}
MLE_mixed_all = nlminb(start = obj_mixed_all$par, objective = obj_mixed_all$fn, gradient  = obj_mixed_all$gr)
MLE_mixed_all$convergence
MLE_mixed_all_rep = obj_mixed_all$report(obj_mixed_all$env$last.par.best)
MLE_mixed_all_sd_rep = sdreport(obj_mixed_all)
plot(ages, MLE_mixed_all_rep$mean_length_at_age, type = "l", lwd = 3, col = "red", xlab = "Age", ylab = "Length (cm)", ylim = c(0, 240))
lines(ages, mean_length_at_age, col = "blue", lty = 3, lwd = 3)
legend('bottomright', legend = c("LEP obs error","True"), col = c("red", "blue"), lty = c(1,2), lwd = 3)

```


## Next steps {-}

- Check sensitivity to the model to starting parameters 
- Repeat with different sample sizes
- Repeat with a truncated age-structure for the age-length data using a selectivity
- Look at Sablefish data and see if the LEP approach can be used to it
- Explore alternative growth models i.e., @schnute1981versatile






<!--chapter:end:08-TaggingData.Rmd-->

# Review/summarise reference points {#refpoints}

Most of my experience with reference points are spawning biomass related i.e., \(SSB_y/SSB_0\). However, many of the reference points outside of New Zealand are \(F\) based i.e., \(F_{35\%}\) which I don't really understand. The purpose of this section is to define them mainly to help me understand, but also as a reference for when I forget in the future.


+----------------------------+-----------------------------------------------------------------------------+
| Symbol                     | Description/Calculation                            
+============================+=============================================================================+
| \(SSB^{\%B_0}_{y}\)        | *Percent \(B_0\)* \(= \frac{SSB_y}{B_0}\)
+----------------------------+-----------------------------------------------------------------------------+
| \(SPR\)                    | *Spawner per recruit* a measure/proxy of population fecundity
+----------------------------+-----------------------------------------------------------------------------+
| \(F_{35\%spr}\)            | *\(F\) 35\%* The Fishing mortality that results in a 35\% SPR
+----------------------------+-----------------------------------------------------------------------------+
| \(SPR_{msy}\)              | *SPR at MSY*
+----------------------------+-----------------------------------------------------------------------------+





<!--chapter:end:09-ReferencePoints.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:10-references.Rmd-->


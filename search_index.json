[["index.html", "Alaskan sablefish research Chapter 1 Overview Gitbook outline Future things to consider", " Alaskan sablefish research C.Marsh 2023-01-22 Chapter 1 Overview This Gitbook documents my/our research on Alaskan sablefish (Anoplopoma fimbria). The objective is to develop and explore a spatially explicit stock assessment model for the Alaskan sablefish stock. However, there will be many topics that I will touch on. This book outlines my research and thinking along with some rabbit holes I entered (and hopefully returned) during my post-doctoral research. The following section outlines chapters contained in this document. Gitbook outline Chapter 2 outlines a list of objectives that we have set or accomplished during this research project. Some of our research cannot be presented in this document due to the confidentiality reasons. However, this checklist should include all tasks during the project Chapter 3 documents the current stock assessment model and assumptions (work in progress). This is the first step of the project, with the purpose of helping me understand the data and important process dynamics assumed in the current assessment. Most models used in this research is written in TMB (Kristensen et al. 2015), many of these are available in the SpatialSablefishAssessment R package. Chapter 4 documents a generalized spatial assessment model used as both an OM and EM during simulations. Chapter 5 describes, characterizes and explores the survey longline data available for the the assessment. Chapter 6 describes, characterizes and explores fishery dependent data, which includes reported catch (log-book data) and observer records. Chapter 7 describes the tagging data and how it can be used within a spatial stock assessment model but also used in a panmictic model for informing population dynamics such as growth. Chapter 10 describes different tag likelihoods that I considered in the spatial model and does a simple simulation estimating annual movement rates with the different likelihoods Chapter 13 explores how to include sex disaggregated composition observations that can include sex ratio information. It conducts a simple simulation to investigate two different approaches. Chapter 14 explores how to parameterise fishing mortality. The current approach is to estimate an annual fishing mortality parameter for each gear as a free parameter. I feel slightly uncomfortable about this approach moving towards a spatial model as the number of estimated parameters will explode when a spatial dimension is explored. This chapter looks at two alternative approaches that either derive fishing mortality estimates using a Newton Raphson solver which is heavily borrowed from the Stock Synthesis “hybrid” approach (Methot Jr and Wetzel 2013) and Pope’s discrete approach (Pope 1972) which uses exploitation rates. Both these methods have been applied in the literature for decades. The aim of this chapter is to do a simulation and make sure the considered approaches are efficient and numerically stability for the purposes of our research. Chapter 15 explores how to calculate the plus group in spatially explicit age-structured models that assume markovian movement during initialization. Future things to consider When is the latest year that we can start the model at? Currently the assessment model starts in 1960 because there is early survey and catch info along with some of the largest catches recorded. I want to explore starting the model at a later period i.e., the 1980’s when there is consistent surveys and age data. This is thought to reduce the number of estimable parameters that have low information (early recruitment deviations). However, the downfall is we may loose information on stock production because the 60’s and 70’s have some of the largest recorded catches. library(TMB) #library(stockassessmenthelper) library(ggplot2) library(dplyr) library(reshape2) library(gridExtra) library(knitr) library(RColorBrewer) References "],["objectives.html", "Chapter 2 A list of objectives/milestones that we have set along the project life", " Chapter 2 A list of objectives/milestones that we have set along the project life Translate current stock assessment (Chapter 3) from ADMB to TMB. Planned date of completion is December 1 2022 Conduct self test using TMB stock assessment model. Planned date of completion is December 1 2022 I decided not to do this because the assessment had too many bespoke likelihoods Consider improvements i.e., sex disaggregated composition data or sex ratio observations (look at the rock lobster assessment) including age-length observations or tag-increment observations to estimate growth internally. (Chapter 13) Characterize both fishery and survey data to get an idea of data limitations when considering spatially explicit stock assessment model. Develop a spatially explicit estimation model in TMB that generalizes the current assessment model. This requires a lot of thought, especially how we want to integrate the tagging data (Chapter 7). Self test has been complete without tagging data. Generate observation error values for composition data. either boostrap or use SE methods Calculate mean length at age for each year - perhaps use the growth model, but this may be double using some of the datasets? This is an interesting idea cause if we take the tag data for example it would be used to estimate mean length at age just using increment and time at liberty, where as when it is internally used in the model it would be using age-frequency to estimate ontogenetic movement. I decided to default to the current assessment length at age and mean length assumptions Outline key model decisions based on data exploration (Chapter 8) Display initial model runs Consider descibe data-weighting methods "],["modeldescription.html", "Chapter 3 Current Alaskan sablefish stock assessment model Process equations Observation equations (\\(ll\\left( . \\right)\\)) Symbol Notation", " Chapter 3 Current Alaskan sablefish stock assessment model The latest published stock assessment (D. Goethel et al. 2021) is a single area model sexually disaggregated integrated age-structured model. Let \\(\\boldsymbol{N_{y,s}}\\) denote a vector of ages in year \\(y\\) for sex \\(s\\) (the partition) i.e., \\(\\boldsymbol{N_{y,s}} = (N_{1,y,s}, N_{2,y,s}, \\dots, N_{a_+,y,s})^T\\). The general process model is sequential and follows the general Equation (3.1), \\[\\begin{equation} \\boldsymbol{N_{y,s}} = \\begin{cases} g\\left(\\boldsymbol{\\theta}\\right), &amp; y = 1959 \\text{ Initial model year}\\\\ f\\left(\\boldsymbol{N_{y-1,s}}|\\boldsymbol{\\theta}\\right), &amp; y &gt; 1959 \\\\ \\end{cases} \\tag{3.1} \\end{equation}\\] where, \\(g(.)\\) is the function describing initial conditions for the partition and \\(f(.)\\) is the function that applies populations dynamics each year i.e., birth, death, growth and migration. See later sections for a detailed description of \\(g(.)\\) and \\(f(.)\\) and \\(\\boldsymbol{\\theta}\\) is the set of estimable (not all are estimated) parameters. Maximum Likelihood Estimates (MLE) for estimated parameters \\(\\widehat{\\boldsymbol{\\theta}}_{MLE}\\) are evaluated, \\[\\begin{equation} \\widehat{\\boldsymbol{\\theta}}_{MLE} = \\underset{\\boldsymbol{\\theta}}{\\arg\\max} \\left( L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) \\right) \\tag{3.2} \\end{equation}\\] where, \\(\\boldsymbol{y^{obs}}\\) is a set of observations and \\(L\\left( . \\right)\\) is an objective function that is made up of priors/penalties and densities. All the models in this research estimate \\(\\widehat{\\boldsymbol{\\theta}}_{MLE}\\) by minimising the negative log of \\(ll\\left( . \\right) = -\\log(L\\left( . \\right))\\). See the observation section for descriptions of \\(ll\\left( . \\right)\\). All symbols used in the following equations are defined in the table at the end of this chapter. Process equations Initialisation (\\(g\\left(.\\right)\\)) \\[\\begin{align*} N_{a,1,s} = \\begin{cases} R_1, &amp; a = a_1\\\\ \\exp\\bigg( \\mu_r + \\tau_{a_1 - a + 1}\\bigg) \\exp-\\bigg( a - a_1\\bigg) \\bigg( M + F_{hist} * \\mu_{LL} * S^{LL}_{a,1}\\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp( \\mu_r) \\exp-( a - 1) ( M + F_{hist} * \\mu_{LL} * S^{LL}_{a - 1,1})(1 - \\exp( M + F_{hist} * \\mu_{LL} * S^{LL}_{a - 1,1}))^{-1}, &amp; a = a_+ \\end{cases} \\end{align*}\\] Population dynamics (\\(f\\left(.\\right)\\)) The assessment assumes a closed population that is only effected by mortality (natural and fishing), recruitment and growth. Mortality is applied assuming \\[ Z_{a,y,s} = M + \\sum_g F^g_{y} S^g_{a,y,s} \\] where, \\(S^g_{a,y,s}\\) is the fishery selectivity and \\(F^g_{y}\\) is the annual estimated fishing mortality. The annual cycle follows, \\[\\begin{align*} N_{a,y,s} = \\begin{cases} p^s_{y} R_y, &amp; a = a_1\\\\ N_{a - 1,y - 1,s} \\times \\exp\\bigg( -Z_{a - 1,y - 1,s} \\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp\\bigg( -Z_{a - 1,y - 1,s} \\bigg) + \\exp\\bigg( -Z_{a,y - 1,s} \\bigg), &amp; a = a_+ \\end{cases} \\end{align*}\\] where, \\[ R_y = \\exp\\{\\mu_r + \\tau_y + 0.5\\sigma_R^2\\} \\] and \\(p^s_{y}\\) is the proportion of recruits in year \\(y\\) for sex \\(s\\). Observation equations (\\(ll\\left( . \\right)\\)) Three are three observation types used in the current Sablefish stock assessment - Relative abundance indices - Age composition (aggregated over sex) - Length composition (disaggregated by sex) These three observation types come from both fishery dependent i.e., observer programs and fishery independent i.e., research surveys. Catch at age Fishery dependent catch at age observations for gear type \\(g\\) denoted by \\({C^g}_{a,y,s}\\) are calculated as follows \\[\\begin{equation} {C^g}_{a,y,s} = \\frac{F^g_{a,y,s}}{Z_{a,y,s}} N_{a,y,s} \\left(1 - S_{a,y,s} \\right) \\tag{3.3} \\end{equation}\\] Currently all age observations are sex aggregated which means the model expected values before applying ageing error is \\[ {C^g}_{a,y} = 0.5 \\sum_s \\frac{{C^g}_{a,y,s}}{\\sum_a{C^g}_{a,y,s}} \\] why the 0.5? should be omitted going forward. Ageing error is then incorporated and the values are normalized so that they are proportions, before being passed to the multinomial log-likelihood function. Survey age composition is similar but instead of being a function of \\(F\\) it is calculated at the beginning of the year. For survey \\(k\\) the numbers at age are denoted by \\({C^k}_{a,y}\\) and calculated following \\[\\begin{equation} {C^k}_{a,y} = \\sum_s p^s N_{a,y,s} S^k_{y,a,s} \\tag{3.4} \\end{equation}\\] I am not sure exactly what the timing of these surveys are, but do we need to account for some mid-year mortality? or changes in timing of the survey? if so we could easily replace \\[ N_{a,y,s} \\] with \\[ N_{a,y,s} \\left(1 - \\exp\\{-p^k_y Z_{a,y,s}\\} \\right) \\] where,\\(p^k_y\\) is the proportion of mortality that we want to account for in year \\(y\\) for survey \\(k\\). The survey numbers at age \\({C^k}_{a,y}\\) are then adjusted for ageing error and normalised so they sum to one for each year. Relative abundance indices \\[\\begin{equation} \\widehat{I}^g_{y} = \\sum_s\\sum_a p^s N_{a,y,s} \\exp \\{-0.5 Z_{a,y,s}\\} S^g_{y,a,s} \\bar{w}_{a,y,s} \\tag{3.5} \\end{equation}\\] where, \\(\\bar{w}_{a,y,s}\\) is mean weight at age, this can be omitted if the observation is in numbers i.e., abundance instead of biomass and \\(p^s\\) is the proportion for each sex. This is currently a user input, but should be dealt within the model either as having different sex selectivities or through the sex ratio of recruitment. A list of slight improvements change how sex ratio is handled in age and length composition (Chapter 13) fishery dependent abundance indices i.e., CPUE change \\(N_{a,y,s} \\exp \\{-0.5 Z_{a,y,s}\\}\\) with \\(\\boldsymbol{C^g}_{a,y,s}\\) which is calculated in the catch at age observations. Catch at length For each year that has a length frequency observation, numbers at length denoted by \\(\\boldsymbol{C^l}_{y,s} = (C^l_{1,y,s}, \\dots, C^l_{n_l,y,s})^T\\) (dimension of \\(\\boldsymbol{C^l}_{y,s}\\) is \\(n_l \\ \\times \\ 1\\)) were calculated for each sex. This involved multiplying the catch at age (see above for how it is calculated) through a sex specific age-length transition matrix denoted by \\(\\boldsymbol{A}^l_{y,s}\\) (dimensions of \\(\\boldsymbol{A}^l_{y,s}\\) are \\(n_a \\ \\times \\ n_l\\) and its rows must sum to 1). The calculation follows Equation (3.6), \\[\\begin{equation} \\boldsymbol{C^l}_{y,s} = \\left(\\boldsymbol{A}^l_{y,s} \\right)^T \\ \\times \\ \\boldsymbol{C_{y,s}} \\tag{3.6} \\end{equation}\\] where, \\(\\boldsymbol{C_{y,s}}\\) is a column vector of numbers at age (dimension \\(n_a \\ \\times \\ 1\\)) at the beginning of year \\(y\\) for sex \\(s\\). Symbol Notation Symbol Description \\(y\\) Year, \\(y = 1960, \\dots, T\\) \\(T\\) Terminal year of the model \\(s\\) Sex index \\(s \\in \\{1,2\\}\\) \\(a\\) Model age cohort, i.e., \\(a = a_0, a_0 + 1, \\dots\\) \\(a_{1}\\) Recruitment age to the model = 2 \\(a_+\\) Plus-group age class (oldest age considered plus all older ages) \\(n_a\\) Number of age classes modeled \\(a_+ \\ - a_1\\) \\(l\\) length class \\(n_l\\) Number of length classes \\(g\\) gear type index, i.e. longline survey, fixed gear fishery, trawl fishery \\(x\\) log-likelihoos index \\(\\bar{w}_{a,y, s}\\) Average weight at age \\(a\\), year \\(y\\) and sex \\(s\\) \\(\\phi_{a,y}\\) Proportion of female mature by age and year \\(p^s_{y}\\) Proportion of recruits for sex \\(s\\). Often assumed = 0.5 \\(\\ln \\mu_{r}\\) Average log-recruitment \\(\\ln \\mu_{f}\\) Average log-fishing mortality \\(\\phi_{y,g}\\) annual fishing mortality deviation by gear (log space) \\(\\tau_{y}\\) annual recruitment deviation \\(\\sim LogNormal\\left(0,\\sigma_r\\right)\\) \\(\\sigma_r\\) Recruitment standard deviation \\(N_{a,y,s}\\) Numbers of fish at age \\(a\\) in year \\(y\\) of sex \\(s\\) \\(M\\) Natural mortality \\(F^g_{a,y}\\) Fishing mortality for year \\(y\\), age \\(a\\) and gear \\(g\\) \\(F_{hist}\\) Historical proportion of Fishing mortality \\(Z_{a,y}\\) Total mortality for year \\(y\\), age \\(a\\) \\(=\\sum\\limits_g F^g_{a,y} + M\\) \\(R_{y}\\) Annual recruitment \\(B_{y}\\) Spawning biomass in year \\(y\\) \\(S^g_{a,y,s}\\) Selectivity at age \\(a\\) for gear type \\(g\\) and sex \\(s\\) \\(a_50\\) age at 50% selection for ascending limb \\(d_50\\) age at 50% selection for descending limb \\(\\delta\\) slope/shape parameters for different logistic curves \\(\\boldsymbol{A}\\) ageing-error matrix dimensions \\(n_a \\ \\times \\ n_a\\) \\(\\boldsymbol{A}^l_s\\) age to length conversion matrix by sex. dimensions \\(n_a \\ \\times \\ n_l\\) \\(q_g\\) abundance index catchability coeffecient by gear \\(\\lambda_x\\) Statistical weight (penalty) for component \\(x\\) \\(P^g_{l,y,s}\\) Observed proportions at length for gear \\(g\\) in year \\(y\\) and sex \\(s\\) \\(P^g_{a,y,s}\\) Observed proportions at age for gear \\(g\\) in year \\(y\\) and sex \\(s\\) Inference If random effects are considered the joint probability model follows, \\[\\begin{equation} Pr\\left[ \\boldsymbol{y^{obs}}, \\boldsymbol{u}| \\boldsymbol{\\theta} \\right] = Pr\\left[\\boldsymbol{y^{obs}} |\\boldsymbol{\\theta^f}, \\boldsymbol{u} \\right] Pr\\left[\\boldsymbol{u} |\\boldsymbol{\\theta^h} \\right] \\end{equation}\\] where, \\(\\boldsymbol{\\theta}\\) denotes “fixed-effect” parameters which are furthur seperated by \\(\\boldsymbol{\\theta} = (\\boldsymbol{\\theta^f},\\boldsymbol{\\theta^h})\\), with \\(\\boldsymbol{\\theta^h}\\) denoting fixed effects that are hyperprior parameters for the “random-effect” variables denoted by \\(\\boldsymbol{u}\\) and \\(\\boldsymbol{\\theta^f}\\) are all other fixed-effect parameters. Inference is conducted by maximising the marginal likelihood noting \\(L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}} \\right) \\propto Pr\\left[ \\boldsymbol{y^{obs}} | \\boldsymbol{\\theta} \\right]\\) \\[\\begin{equation}\\label{eq:marginal_ll} L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) = \\int \\left(Pr\\left[\\boldsymbol{y^{obs}} |\\boldsymbol{\\theta^f}, \\boldsymbol{\\theta^g}, \\boldsymbol{u} \\right] Pr\\left[\\boldsymbol{u} |\\boldsymbol{\\theta^h} \\right] \\right) \\boldsymbol{du} \\end{equation}\\] In general this integral is not tractable, and so approximations are necessary. The software used here implement the Laplace approximation, which relies on Gaussian assumptions. Maximum Likelihood Estimates (MLE) for fixed effect parameters \\(\\widehat{\\boldsymbol{\\theta}}_{MLE}\\) are evaluated, \\[\\begin{equation} \\widehat{\\boldsymbol{\\theta}}_{MLE} = \\underset{\\boldsymbol{\\theta}}{\\arg\\max} \\left( L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) \\right) \\end{equation}\\] and Empirical Bayes estimates are evaluated for \\(\\widehat{\\boldsymbol{u}}\\), which are used model diagnostics and other model quantities, \\[\\begin{equation} \\widehat{\\boldsymbol{u}} = \\underset{\\boldsymbol{u}}{\\arg\\max} \\left( Pr\\left[ \\boldsymbol{y^{obs}}, \\boldsymbol{u}| \\widehat{\\boldsymbol{\\theta}}_{MLE} \\right] \\right) \\end{equation}\\] TODO Build a validate function to help catch users setting up parameters or data structures that will cause a crash once supplied to TMB. Self test Change array column casting from vector&lt;Type&gt;(array.col(i)) to array.col(i).vec() References "],["spatialmodeldescription.html", "Chapter 4 Spatial stock assessment model for Alaskan sablefish Process equations Observation equations", " Chapter 4 Spatial stock assessment model for Alaskan sablefish The spatial model used for this research is available as an R package and is best described by the R package documentation found here. I have described the general model, but the package documentation is the best resource for specific equations. Process equations Population dynamics The order of processes in an annual cycle follow Recruitment and release of tagged fish (we apply initial tag induced mortality here) Total mortality and ageing Markovian movement Annual tag shedding (applied as a mortality process) Before applying movement, the partition is updated following \\[\\begin{align*} N_{a,r,y,s} = \\begin{cases} R_{r,y} 0.5, &amp; a = a_1\\\\ N_{a - 1,r,y - 1,s} \\exp\\bigg( -Z_{a - 1,r, y - 1,s} \\bigg), &amp; a_1 &lt; a &lt; a_+\\\\ N_{a - 1,r,y - 1,s} \\exp\\bigg( -Z_{a - 1,r, y - 1,s} \\bigg) + N_{a,r,y - 1,s} \\exp\\bigg( -Z_{a,r, y - 1,s} \\bigg), &amp; a = a_+ \\end{cases} \\end{align*}\\] where, \\(N_{a,r,y,s}\\) is the numbers at age \\(a\\) in region \\(r\\), year \\(y\\) for sex \\(s\\), \\(Z_{a,r,y,s} = M + \\sum_g F_{a,r,y,s}^g\\) is total mortality and \\(R_{r,y}\\) is annual recruitment for region \\(r\\). Once ageing and mortality have taken place movement is then applied as \\[\\begin{equation*} \\boldsymbol{N}&#39;_{a,y,s} = \\boldsymbol{N}_{a,y,s} \\boldsymbol{M} \\ \\ \\forall \\ a \\end{equation*}\\] where, \\(\\boldsymbol{N}&#39;_{a,y,s} = (N&#39;_{a,1,y,s}, \\dots, N&#39;_{a,n_r,y,s})\\) denotes the numbers for age \\(a\\) across all regions after movement and \\(\\boldsymbol{M}\\) is an \\(n_r \\times n_r\\) movement matrix, which will move age cohort \\(a\\) among the regions based on the movement matrix. Initialisation An equilibrium age structure is derived following the method described in Chapter 15, but for completeness we will briefly describe it here. The annual cycle is run \\(n_a - 1\\) times to populate all age cohorts prior to the plus group. Then, iterate the annual cycle one more time and calculate the number of individuals that moved into each regions plus age cohort, denoted by \\(c^r_{a+}\\). This will be the result of ageing, mortality and movement. The equilibrium plus group for region \\(r\\) is then calculated as \\[ N_{a+, r} = N_{a+ - 1, r} \\frac{1}{1 - c^r_{a+}} \\ . \\] After the equilibrium age-structure is calculated, there is an option to estimate age specific deviations to allow the model to start with a non-equilibrium age-structure denoted by \\(e^{\\epsilon_a}\\) \\[ N_{a, r} = N_{a, r} e^{\\epsilon_a} \\ \\ \\forall \\ r \\ a \\in [a_2..(a_+ - 1)] . \\] To help with estimation there is a penalty on \\(\\epsilon_a\\) that assumes a central tendancy of zero with an estimable variance parameter (\\(\\sigma_{\\epsilon}^2\\)). \\[ \\epsilon_a \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}) \\] Future model generalizations should consider making this inital age-deviations regional specific. Growth Empirical age-length matrices are supplied for all years by sex, these are the same matricies used in the current single area sex. We did not consider spatially varying growth because when the data was visually inspected, there did not seem to be obvious differences. The other reason was when spatially varying growth is included in the model, we would need to track length in the partition (add an extra dimension) to avoid fish drastically changing length as they move between areas and different growth curves. Mean weight at age was calculated using an allometric length weight relationship with time and space invariant parameters \\(\\alpha\\) and \\(\\beta\\) \\[ \\bar{w}_{a,y} = \\alpha \\bar{l}_{a,y}^{\\beta} \\] Recruitment There are two options in the model for recruitment, regional mean recruitment with global recruitment deviations and regional mean recruitment with region recruitment deviations. TODO - Add regional stock recruitment relationships as a model option - Add a global stock recruitment relationship Fishing mortality When the hybrid \\(F\\) method is assumed (this is my default), tagged fish were not included when internally solving the fishing mortality nuisance parameters (Chapter 14). The ratio of tagged to untagged numbers of fish in the partition in any year was assumed to be small enough not to effect \\(F\\) estimates. However, tagged fish were included when the model calculates predicted catch-at-age/length and catch for a fleet. This decision was made to reduce the computational overhead this would require to implement. When \\(F\\) parameters are estimated as free parameters, then this is not a problem and \\(F\\) will be applied to both tagged and untagged fish. Tag release events Tags release event denoted by the index \\(k\\) have an implied region \\(r\\) and year \\(y\\) dimension. Each tag release event has known sex and age frequency at release. This is derived using the survey age-length key. This is reasonable given the survey is responsible for releasing most tags. A downside of using the age-length key approach to convert unsexed lengths at release into tag releases by age and sex is a tagged fish that would have an exact age, sex and length will be represented in the model as a fraction of a fish across multiple ages and sexes. For release years where there were no age length keys, we used age-length keys pooled over years 1981, 1985 and 1987 for earlier perios (prior to 1981) and the closest age-length key for later periods. (How can we explore uncertainty in this input? re-run the model with numbers at age and length from bootstrapping age-length keys?) Tagged fish from release event \\(k\\) are denoted in the partition as \\(T^k_{a,r,y,s}\\), and are tracked for \\(n_{T}\\) years before migrating into a pooled tag group, at which point we loose release-year information but do maintain its region of release. At present, tagged fish are assumed to take on the exact same population processes as the untagged elements of the partition (instantaneous mixing). Other considerations for tag-releases Do we want to include the inshore (Chatham Strait and Clarence Strait) tag-releases? there are alot of fish tagged in these regions. Do we care about the amount of tags that leave stock area? See Figure 7.3 Observation equations There are four observation types in the model Relative indices of abundance Age composition disaggregated by sex for the fixed gear fishery and longline survey Length composition disaggregated by sex for the trawl and early period of the fixed gear fishery Tag-recovery observations Catch at age Fishery dependent catch at age observations are available for the fixed gear fishery, but are also needed to calculate catch at length observations for the trawl fishery. Catch at age for fishery \\(g\\) is denoted by \\({C}^g_{a,r,y,s}\\) and model fitted values are calculated following \\[\\begin{equation} {C}^g_{a,r,y,s} = \\frac{F^g_{a,r,y,s}}{Z_{a,r,y,s}} N_{a,r,y,s} \\left(1 - S_{a,r,y,s} \\right) \\end{equation}\\] Observed values were proportions with respect to age and sex, final model fitted proportions were \\[ {P}^g_{a,r,y,s} = \\frac{{C}^g_{a,r,y,s}}{\\sum_a \\sum_s {C}^g_{a,r,y,s}}, \\] and initially the multinomial likelihood was assumed \\[ \\boldsymbol{X}^g_{r,y} \\sim \\text{Multinomial}\\left(\\boldsymbol{\\widehat{P}}^g_{r,y}\\right) \\] where, \\(\\boldsymbol{X}^g_{r,y} = \\boldsymbol{P}^g_{r,y}N^{eff}_{r,y}\\) and \\(\\boldsymbol{P}^g_{r,y}\\) is the observed proportions, \\(N^{eff}_{r,y}\\) is the effective sample size and \\(\\boldsymbol{P}^g_{r,y} = (P^g_{1,r,y,1}, \\dots, P^g_{a_+,r,y,1}, P^g_{1,r,y,2}, \\dots, P^g_{a_+,r,y,2})\\) is the vector of observed proportions across all ages and sexs in year \\(y\\) and region \\(r\\), and \\(\\boldsymbol{\\widehat{P}}^g_{r,y}\\) is the model fitted values which have the same dimension (\\(\\sum_a \\sum_s \\widehat{P}^g_{a,r,y,s} = 1\\)). Catch at length Catch at length observations are available for the trawl fishery. Model fitted values are derived by multiplying the catch at age (see above) by an age-length transition matrix denoted by \\(\\boldsymbol{A}^l_{y,s}\\) (dimensions of \\(\\boldsymbol{A}^l_{y,s}\\) are \\(n_a \\ \\times \\ n_l\\) and its rows must sum to 1), \\[\\begin{equation} \\widehat{\\boldsymbol{Cl}}^g_{r,y,s} = \\left(\\boldsymbol{A}^l_{y,s} \\right)^T \\ \\times \\ \\widehat{\\boldsymbol{C}}^g_{r,y,s} \\end{equation}\\] where, \\(\\widehat{\\boldsymbol{C}}^g_{r,y,s}\\) is a column vector of catch at age (dimension \\(n_a \\ \\times \\ 1\\)) at the beginning of year \\(y\\) in region \\(r\\) for sex \\(s\\), and \\(\\widehat{\\boldsymbol{Cl}}^g_{r,y,s}\\) is a column vector of catch at length (dimension \\(n_l \\ \\times \\ 1\\)). Proportions at age Survey age composition data denoted by \\({N}^s_{a,r,y,s}\\) is available for the longline survey where model fitted numbers are derived as, \\[\\begin{equation} \\widehat{N}^s_{a,r,y,s} = N_{a,r,y,s} \\left(1 - \\exp^{\\delta_y Z_{a,r,y,s}}\\right)S^s_{y,r,a,s} \\end{equation}\\] where, \\(\\delta_y \\in (0,1)\\) is the proportion of time in the year that the observation occurs during year \\(y\\) and \\(S^s_{y,r,a,s}\\) is the survey selectivity. Relative abundance indices \\[\\begin{equation} \\widehat{I}^s_{r,y} = \\sum_s\\sum_a \\widehat{N}^s_{a,r,y,s} \\bar{w}_{a,y,s} \\end{equation}\\] where, \\(\\bar{w}_{a,y,s}\\) is mean weight at age, this can be omitted if the observation is in numbers i.e., abundance instead of biomass. Tag recovery observations When tagged fish are released in to the model partition they are tracked by the tag release event \\(k\\) for \\(n_{T}\\) years. The model expects tag-recovery observations to be known by age and sex. These are derived for each recovery event (also year and region specific) and tag-release event by using the same age-length key that was used to release each recovered fish to obtain an sex specific age-frequency. This age-frequency is then aged by the number of years this tag-recovery event was at liberty to derive observed tag-recoveries by age and sex. This assumes the age-length conversion between releases and recoveries is consistent and allows us to use recovered fish with no length or sex recorded, but has the down side as mentioned earlier in the tag release section of smearing a single recovered fish across multiple age bins and sexes. However, it does mitigate the problem highlighted in chapter 7 (tag release section) of going backwards and forwards through the age-length transition matrix, which appears to be more problematic. All tag recoveries are from the fixed gear (longline and pot gear) fishery, due to the recent trend in recoveries by gear method (Figure 7.2), we only considered tags recovered before 2018. The switch from longline to pot fishing in the fixed gear fishery has not seen anywhere near the same recoveries to be reported from the pot gear compared to the longling gear. To avoid this complication we will only consider recoveries from a period when the longline method was the dominant method of fixed gear catch Model fitted values for tag event \\(k\\) recovered in region \\(r\\) and year \\(y\\) denoted by the set index \\(m = \\{r,y\\}\\) are denoted by \\(\\widehat{N}^k_{m}\\), and are derived as \\[ \\widehat{N}^k_{m} = \\sum_a \\sum_s T^k_{a,r,y,s} \\frac{F^{LL}_{a,r,y,s}}{Z_{a,r,y,s}} (1 - e^{-Z_{a,r,y,s}})\\delta_{r,y}, \\quad m = \\{r,y\\} \\] where, \\(T^k_{a,r,y,s}\\) are the number of tagged fish from tag-release event \\(k\\), and \\(\\delta_{r,y}\\) is the reporting rate in year \\(y\\). Initial model runs used the Poisson \\[ N^k_{m} \\sim \\mathcal{Poisson}(\\widehat{N}^k_{m}) \\] However, the negative binomial and multinomial are in development. See Chapter 10 for simple exploration of different tag-likelihoods for estimating movement parameters. "],["surveydata.html", "Chapter 5 Survey data Survey design Abundance (catch rate) data Age data Length frequencies Age frequencies Age-length data Appendix", " Chapter 5 Survey data This chapter explores and describes survey age, length and catch rate data to inform the following spatial model decisions Is there spatial differences in age or length composition? Is there spatial differences in growth? What estimators will we use for regional abundance and age-frequencies Survey design The longline survey in the Gulf of Alaska and Bering Sea began in 1978-79 and is fixed station systematic design (Sasaki 1985). “Survey stations are distributed as uniformely as possible in each geographic area. One station per day is fished, and normally 160 hachis/skates are fished at each station. The longline is set at right angles to the isobars in a manner to cover the depth range of 101- 1,000 m. However, the distance between 101 and 1,000 m varied at each survey station. Thus, this complete depth range could not be covered at stations where this distance exceeded the 16 km length of the longline gear. The longline was usually set from shallow to deep waters and was retrieved in the same direction. Hauling the longline started 2 hours after the set was completed.” pg 68 Sasaki (1985) Each hachi is assigned to a depth stratum. Hachi belonging to a fishing event and specific depth stratum are used to derive mean catch rates for each stratum and fishing event observation and used in subsequent estimators. Covariation is accounted for in variance estimators between depth strata to account for longline transects crossing multiple depth strata. Abundance (catch rate) data A geostatistical model-based estimator was used to estimate spatial estimates of abundance. sdmTMB (Anderson et al. 2022) was the package used for this exercise. Geostatistical models require spatial locations to be known for all observations. A limitation of using hachi level data is latitude and longitude is only known for the whole longline event (e.g., all hachi on the same line have the same spatial coordinates). For each longline event we summed over all hachi. Survey abundnace pooled over 50km x 50km grid cells is shown in Figure 5.1. Figure 5.1: A time-series of sablefish catch from the long line survey pooled over 50km by 50km grided cells A range of covariates, spatio-temporal and likelihood assumptions were considered in the geostatistical analysis. Two covariates that were forced in the model whether they were statistically significant or not was Year and country. There has been documented difference between Japanese and NMFS sampling relating to hook and ganion construction (Kimura and Zenger Jr 1997). Given the unusual shape of the coast for the region, an boundary was created to avoid spatial regions in the Bearing sea sharing information with CGOA and EGOA. The mesh assumed in models that has spatial random effects but not spatio-temporal random effects is shown in Figure 5.2. Figure 5.2: Mesh for spatial random effects, red dots indicate station location The first model was configured using code the follow code chunk. fit_spatial_tweedie &lt;- sdmTMB( catch ~ 0 + as.factor(Year) + Country, family = tweedie(link = &quot;log&quot;), spatial = &quot;on&quot;, time = &quot;Year&quot;, spatiotemporal = &quot;off&quot;, ) This model structure was repeated assuming the Gamma and Lognormal distribtion because there were only 5 records of 4000 that did not catch sablefish strictly positive distributions were only considered. Residuals shown in Figure 5.2 Figure 5.3: Boxplot comparing overall residuals between distributions Symbol Description \\(\\mathcal{M}_1\\) y ~ year + country + omega \\(\\mathcal{M}_2\\) y ~ year + country + FMP_region + omega \\(\\mathcal{M}_3\\) y ~ year + country + epsilon(iid) \\(\\mathcal{M}_4\\) y ~ year + country + epsilon(ar1) where omega is time-invariant Gaussian Field (GF) and epsilon is time-varying GF Table 5.1: Negative log-likelihoods for index models model Gamma Lognormal Tweedie n_params M1 2865.55 3404.42 2199.97 48 M2 2848.87 3378.63 2183.28 52 M3 2737.73 3229.85 1970.40 49 M4 2581.64 3021.01 1778.05 50 Figure 5.4: Spatial predition M1 with the tweedie distribution. Figure 5.5: Comparison of indicies for the Tweedie distribution and the three model structures. Figure 5.6: Spatial predictions of log abundance from model M3 (spatio-temporal GF) Age data A big challenge of any spatial stock assessment is deriving spatially disaggregated age-frequency observations from small age sample sizes. For both the long-line survey and fixed gear fishery we have both age and length data. This means there are multiple estimators available, including; direct ageing and age-length key (Ailloud and Hoenig 2019; Hoenig, Choudary Hanumara, and Heisey 2002) estimators. The forward age-length key method at face value looks to be the most attractive, as it reduces data sparsity when compared to direct ageing estimators. However, we will generate AF’s for both methods and see if they effect any model outputs. A note on sablefish otolith sampling from the survey. “Otolith collections were length-stratified from 1979-94 and random thereafter” pg 9 of Sigler, Fujioka, and Lowe (2001). Figure 5.7: Number of aged fish by sex, region and year Length frequencies Often, each haul is subsampled for LF measurements. For each haul we calculate the sampling fraction of samples for LF vs the entire haul catch \\[ \\pi_h = \\frac{n_h}{N_h} \\] where, \\(n_h\\) is the number of fish measured for LF and \\(N_h\\) are the total number of fish caught in haul \\(h\\). Each length measurement is then scaled by this sampling fraction to derive the length frequency for the entire haul, \\[ N^h_l = \\frac{\\pi_h}{n^h_l} \\] where, \\(n^h_l\\) is the number of fish in length bin \\(l\\) for haul \\(h\\), and \\(N^h_l\\) is the scaled number of fish. To generate region wide LF’s from the survey data, we used the mean estimator \\[ N^r_l = \\frac{1}{\\sum\\limits_{h \\in r}1} \\sum\\limits_{h \\in r} N^h_l \\] where, \\(h \\in r\\) denotes only hauls within region \\(r\\) and \\(\\sum\\limits_{h \\in r}1\\) indicates the number of hauls in that region. Figure 5.8: Number of fish measured for length by sex, region and year Age frequencies Two estimators were explored for deriving spatially disaggregated age-frequencies from survey data. These were direct ageing estimators and age-length key estimators. 5.0.1 Direct ageing estimators The direct ageing estimator we applied assumed age-samples within a region and year are the result of simple random sampling, with the estimator. \\[ P_{a,r,y} = \\frac{n_{a,r, y}}{\\sum\\limits_a n_{a,r, y}} \\] where, \\(P_{a,r,y}\\) is the proportion in age \\(a\\) and \\(n_{a,r, y}\\) are the number of fish aged in age \\(a\\) region \\(r\\) and year \\(y\\). To aggregate age frequencies across areas we use an abundance weighted approach, where the abundance estimated from the survey in region \\(r\\) and year \\(y\\) denoted by \\(I_{r,y}\\) is used, \\[ \\tilde{P}_{a,r,y} = P_{a,r,y} \\frac{I_{r,y}}{\\sum\\limits_r I_{r,y}} \\ . \\] If we are going to aggregate proportions at age over multiple regions we would use \\(\\tilde{P}_{a,r,y}\\) such as, \\[ {P}_{a,R,y} = \\sum\\limits_{r \\in R} \\tilde{P}_{a,r,y} \\] where, \\(R\\) indicates the set of areas that we are aggregating and this is normalized so that it sums to one, which leads to area aggregated estimates \\[ {P}_{a,R,y} = \\frac{{P}_{a,R,y}}{\\sum\\limits_a{P}_{a,R,y}} \\ . \\] Length bins that did not have age samples were imputed with the global age-length key values. This was to include length samples in the length frequency to avoid odd age-frequencies. 5.0.2 Age length key estimators The Age length key (ALK) estimator uses paired age-lengths to calculate an age-length key which is used to derive age-frequencies by multiplying the ALK by scaled length frequencies. Constructing an age-length key requires paired age and length measurements which calculate the probability of age given a length bin \\[ \\hat{p}(a|l) = \\frac{n_{a,l}}{n_{+,l}} \\] where, \\(n_{+,l}\\) is the number of ages with corresponding lenghts that fall within length bin \\(l\\). The probabilities of age given length using the forward ALK method are then simply multiplied by the marginal probabilities by the scaled length frequencies \\[ P_{a,r} = \\hat{p}(a|l) N^r_l \\] where, \\(N^r_l\\) are regional specific scaled length frequencies (described in the prior section). The ALK can also be regional specific where only paired age-lengths are used from that region. This is not considered in this work because of the lack of samples when building ALKs at this resolution. Continuation ratio logits (CRL) This method was not explored in detail due to the sex dimension for sablefish adding a complexity we didn’t have time to get in to. There is R code that applies the CRL model ignoring sex in the data and wanted to partially document it as it seems quite promising. An alternative to the ALK is to use a continuation ratio model (CRL) to model the distribution of ages \\(\\boldsymbol{p}_a(\\boldsymbol{x}) = (p_J, \\dots, p_A)\\), which has been proposed and explored in recent studies (Berg and Kristensen 2012; Correa et al. 2020). Using a \\(J\\) minus \\(A\\) conditional model for describing the probability of being age \\(a\\) given it as at least \\(a\\), that is \\[\\begin{equation} \\pi_a = P(Y = a| Y \\geq a) = \\frac{p_a}{p_a + p_{a+1} + \\dots + p_A} , \\ \\ a = J, \\dots, A-1 \\end{equation}\\] Given the set of A − J models, the estimated unconditional probabilities \\(p_a\\) from the conditional probabilities \\(\\pi_a\\) follows \\[\\begin{align} \\hat{p}_a =&amp; \\hat{\\pi}_a , \\ a = R\\\\ \\hat{p}_a =&amp; \\hat{\\pi}_a \\bigg( 1 - \\sum\\limits_{k = J}^{a - 1} \\hat{p}_a \\bigg) = \\hat{\\pi}_a \\prod\\limits_{k = J}^{a - 1} (1 - \\hat{\\pi}_k) , \\ a &gt; J \\end{align}\\] Estimating initial input sample sizes for multinomial composition data Bootstrapping is used to estimate standard errors for \\(P_{a,R,y}\\). Data used to calculate age-length keys are re sampled with replacement to calculate a SE and CV. This produces a CV for each age, region and year denoted by \\(CV_{a,r, y}\\). Proportions at age are assumed to be distributed according to the multinomial distribution. To translate the observation error expressed as a CV to an initial effective sample denoted by \\(N^{eff}_y\\) we apply a non-linear least squares solver to estimate \\(N^{eff}_y\\) by minimizing the following expression \\[ \\log CV_{a,r, y} = \\log \\sqrt{\\frac{P_{a,R,y}\\widehat{N}^{eff}_y \\left(1 - P_{a,R,y}\\right)}}{P_{a,R,y}\\widehat{N}^{eff}_y} \\] Age-length data Figure 5.9: Age-length by sex Figure 5.10: Male age-length by region (left panel) and decade (right panel) Figure 5.11: Female age-length by region (left panel) and decade (right panel) Appendix Figure 5.12: CDF of age frequencies for females Figure 5.13: CDF of age frequencies for males Figure 5.14: CDF of length frequencies for females Figure 5.15: CDF of length frequencies for males References "],["observerdata.html", "Chapter 6 Fishery dependent data Catch data Length data Age data Age-length data", " Chapter 6 Fishery dependent data This chapter describes an exploratory analysis using the observer and other fishery reported data. The aim is to highlight trends and signals in the data that would lead to an assessment decision or consideration e.g. spatial and temporal structures. All data analysed in this section has been extracted from the AKFIN database (North Pacific Observer Program). It included extracts from the length, age and catch reports. Some of the data cannot be displayed here due to confidentiality reasons. Locations shown in this work have been generalized to generic center locations of a 20 x 20 sq. km grid if there were 3 or more unique vessels, as per NOAA/NMFS regulations. This data will result in two important assessment inputs: observed catch (which will be assumed known with a high level of precision) and composition by fishery, either age or length. Define what a fishery is? Currently a “fishery” is defined by a gear type i.e., trawl vs fixed-gear (line and pot). is there evidence for changing selectivity? i.e., time-blocks Auxiliary information see Table 3.3 D. Goethel et al. (2021) for management actions which describe spatial closures by gear. Figure 6.1: Catch history by region Catch data Deriving annual estimates of catch by year and region should be fairly straight forward. Fishers generally have a legal requirement to record catches and we will probably just assume that reported catches are accurate. Unfortunately catch by gear type and region is not known prior to 1977 (pers comms Kari Fenske). The following bubble plots display the proportion of catch sampled for lengths and ages by observers relative to the catch by gear and area from 1990 when observer data available. When bubbles and crosses have the same size then the observer samples are proportional to catch for a given year. When crosses are larger then observers sampled more relative to the catch and vice versa. These are meant to give some impression of “representative” sampling i.e., are there regions or gears that are under or over sampled. Figure 6.2: Observer representative figures by method. When the cross and circle are the same size this indicates observers sample proportional to the catch for a year. Figure 6.3: Observer representative figures by method. When the cross and circle are the same size this indicates observers sample proportional to the catch for a year. Figure 6.4: Observer representative figures by method. When the cross and circle are the same size this indicates observers sample proportional to the catch for a year. Figure 6.5: Observer representative figures by method. When the cross and circle are the same size this indicates observers sample proportional to the catch for a year. Length data Catch at length estimator The aim of catch at length is to obtain representative length frequencies (LF) of fish removed by a specific fishery within a specific area and year. These estimates are derived from observer collected data of which only a subsample of fishing trips are observed. Observers are tasked with subsampling observed catch to provide length and age samples. Thus these samples need to be scaled to either the stock wide level for inputs into a single area stock assessment or to some region level for use in a spatially disaggregated stock assessment. This is sampling structure has a natural hierarchy which is illustrated in Figure 6.6. Figure 6.6: Sampling hierachy for fishery dependent catch at age and catch at length estimates Each node in the sampling hierarchy is denoted by the index \\(m\\). When a node is nested within another node, we use \\(m \\in m&#39;\\) to define that \\(m&#39;\\) is nested within \\(m\\). Symbol Description \\(m,l,a,s\\) index for node, length bin, age bin, sex \\(n_{m,l,s},N_{m,l,s}\\) Number of fish in unscaled and scaled LF for sex \\(s\\), at node \\(m\\) \\(n_{m,a,s},N_{m,a,s}\\) Number of fish in unscaled and scaled AF for sex \\(s\\), at node \\(m\\) \\(q_m\\) Number of child nodes for node \\(m\\) \\(n_{m,l,a,s},N_{m,l,a,s}\\) Number of fish in unscaled and scaled LF &amp; AF for sex \\(s\\), at node \\(m\\) \\(\\pi_m\\) Scaling factor at node \\(m\\) \\(W_m,M_m,P_m,A_m\\) scaling variables for each node (weight, numbers, proportion, area) \\(w_{l,s}\\) mean weight for length bin \\(l\\) and sex \\(s\\) \\(w_{a,s}\\) mean weight for age bin \\(a\\) and sex \\(s\\) \\(K_{m,l,a,s}\\) Age-length key for node \\(m\\) by sex We require information the numbers at length for each node ( \\(n_{m,l,s}\\)) which make up the unscaled length frequency. Length weight parameters that describe the allometric relationship of weight from length (\\(w_{l,s} = a_s L_{l,s}^{b_s}\\)). The last piece is how we want to scale the frequencies (\\(W_m,M_m,P_m,A_m\\)). Length frequencies are iteratively calculated up the sampling hierarchy \\[ n_{m,l,s} = \\sum_{m&#39; \\in m} N_{m&#39;,l,s} \\] where \\[ N_{m&#39;,l,s} = \\pi_{m&#39;} n_{m&#39;,l,s} \\] There are multiple approaches for scaling unscaled numbers to scaled numbers such as scaling by area etc, scaling by weight. If an individual haul is subsampled i.e., only 50 fish are measured for length of 1000 caught in a single haul, then we use the sampling fraction denoted by \\(\\pi^{h}\\) to scale the subsample to a haul level LF. Region wide LFs are calculated by summing the LFs over all sampled hauls within that region. Due to each haul having a scaled LF hauls, hauls with larger catches will naturally contribute more samples to a region wide LF, thus making this a catch weighted estimator. If \\(n^h_l\\) fish are measured for lengths from a haul that had \\(N^h_l\\) fish, then the scaler for the subsample follows, \\[ \\pi^{h} = \\frac{N^h_l}{n^h_l} \\] each length sample in haul \\(h\\) is divided by this sampling fraction. The estimator for region wide LFs denoted by \\(\\widehat{N}^r_{l,s}\\) follow, \\[ \\widehat{N}^r_{l,s} = \\sum_{h\\in a} n^h_{l,s} \\pi^{h} \\pi^{r} \\] where \\(\\pi^{r}\\), is the region scalar which weights each observed haul by the catch from hauls that had LFs collected and total catch in the region. \\[ \\pi^{r} = \\frac{C_r}{\\sum_{h \\in h&#39;} C_h} \\] where, \\(C_h\\) is the catch from haul \\(h\\), \\(h&#39;\\) denotes the set of hauls that were observed and had LFs taken, and \\(C_r\\) is the region wide catch, which is a legal requirement from fishers to report. Region wide LFs are aggregated across multiple regions denoted by the set \\(r&#39;\\) using an another catch weighted approach \\[ \\widehat{N}^{r&#39;}_{l,s} = \\sum_{r\\in r&#39;} \\widehat{N}^r_{l,s} \\pi^{r} \\] where, \\[ \\pi^{r} = \\frac{C_r}{\\sum_r C_r} \\] where, \\(A_r\\) is the catch in region \\(C_r\\) and \\(\\sum_r C_r\\) denotes catch over all regions under investigation. Figure 6.7: This figure shows how each of the scaling factors change the raw sampled LFs (\\(n^h_{l,s}\\)) to obtain regional scaled length frequencies (\\(\\widehat{N}^{r&#39;}_{l,s}\\)) for the fixed gear fishery. A gear and region had to have at least 100 fish measured for length in order to generate catch at length estimates. Age data Only the fixed gear fishery has age-samples to estimate age-frequencies. The same direct and age-length key estimators as the survey was used for the fixed gear survey. Age-length data Figure 6.8: Age-length by sex Figure 6.9: Male age-length by region (left panel) and decade (right panel) Figure 6.10: Female age-length by region (left panel) and decade (right panel) References "],["tagdata.html", "Chapter 7 Tagging data exploration Exploratory analysis of the tag data Lincoln-Peterson estimator Integrating tagging observations in spatial age-structured models Tagging things to consider with relevant references Releasing tags", " Chapter 7 Tagging data exploration Since 1972 there have been approximately 400 000 sablefish tagged in Alaska waters, of which over 38 500 have been recovered. Although there is extensive and long term tagging data, this information is not currently directly included in the stock assessment (D. Goethel et al. 2021). Historical publications investigating movement of Alaskan sablefish include Heifetz and Fujioka (1991), Hanselman et al. (2015) Exploratory analysis of the tag data Figure 7.1 shows the spatial distribution of both releases and recaptures, which both have fairly broad spatial distributions which is a good attribute. Figure 7.2 shows the number of recoveries by gear method and year, this highlights a major drop off in recoveries from the Longline gear with no other gear has picked up in. This will have to be discussed with the wider team. In particular, what years to consider this data to be informative. Figure 7.1: Tag releases and recoveries pooled over all years Figure 7.2: Recovered fish by gear type and year One thing of note is the number of tag-recaptures outside of the stock boundaries, shown in Figure 7.3. Figure 7.3: Tag recoveries outside of stock boundaries, with release locations (bottom panel). We can crudely look at the proportion of recoveries across recovery regions that were released in a given region shown in Figure 7.4. Care must be taken when interpreting these numbers because recovery rates among regions will differ which this plot is ignoring. Figure 7.4: Tag recoveries by release and recovery region pooled over all years. Colors are number of tags recovered and text indicates the proportion. Lincoln-Peterson estimator We applied a simple Lincoln-Peterson estimators to view changes in abundance over the area of interest using a subset of the tag recoveries. The Lincoln-Peterson estimator follows \\[ \\widehat{N} = \\frac{n e^{-(\\kappa + M)}K\\tau}{k} \\ . \\] Symbol Description \\(N\\) Number of fish in the population \\(n\\) Number of fish released with a tag \\(K\\) Number of fish scanned for tags (fishery catch over the period of recoveries \\(k\\) Number of tagged fish recovered \\(\\tau\\) Reporting/detection rate = 0.276 from Heifetz and Maloney (2001) \\(\\kappa\\) Annual tag loss or mortality = 0.1 Beamish and McFarlane (1988) \\(M\\) Natural mortality = 0.1 based on D. Goethel et al. (2021) Most of the tags are released during the summer survey (Figure 7.5) but recoveries are more spread out within a year. Figure 7.5: Tag recovery and release distributions by month A Lincoln-Peterson estimator based on long line tag recoveries that were at liberty for a year (300 - 420 days) was explored. This time-at-liberty period was chosen so we could calculate annual estimates of abundance and thus derive annual estimates of exploitation rates to compare with the assessment. Due to the large distance traveled by sablefish over this time-period (Figure 7.6), the spatial extent considered was the entire stock region. Figure 7.6: Distance (km) between release location and recovery location for fish at liberty for a year. A few calculations/approximations are included in the Lincoln-Peterson estimator, these include tag loss and natural mortality for tagged fish after a year at liberaty, reporting rates from the commercial fishery, and changing reported weights to numbers. The period for calculating catch that was scanned during tag recoveries was the 15 of May to 15 of September. This was chosen as it brackets the monthly peak of releases (Figure 7.5). The other adjustment was converting reported weight into numbers. For this I calculated the mean numbers of fish per tonne based on the observer data. I then used this multiplier for the catch reported in tonnes during the period of recoveries to extract the numbers scanned by the fishery each year. Figure 7.7: Recovered fish by gear type and year Once we have annual population abundance estimates we can derive a rough annual exploitation rate (\\(U_y\\)) denoted by \\[ U_y = \\frac{C_y}{\\widehat{N}} \\] where, \\(C_y\\) is the annual catch in numbers for the Longline fishery shown in Figure 7.8. Figure 7.8: Exploitation rate for the Longline fishery based on Lincoln-Peterson estimates Integrating tagging observations in spatial age-structured models This project intends to explore a range of methods for utilizing tag-recovery observations in spatially disaggregated age-structured stock assessments. Tagging things to consider with relevant references Years to retain tagged fish in the partition “After approximately 9 yr the number of recaptures was small and contributed more to the variance associated with the trends in movement than an improved understanding of these trends” Beamish and McFarlane (1988) Reporting rates (Heifetz and Maloney 2001) Scan detection rates. Is this not a factor of reporting rates? Mixing time and how to deal with it? Tag loss “tag loss in the fist year was approximately 10% and after that approximately 2% per year.” Beamish and McFarlane (1988) Release conditioning vs recapture conditioning (Vincent, Brenden, and Bence 2020; McGarvey and Feenstra 2002) likelihood choice? (Hanselman et al. 2015) Releasing tags Tag release events involve releasing a tag-cohort at the beginning of a year within a specific area. A tag cohort is indexed by \\(k\\) and has an implied year \\(y\\) and region \\(r\\) index. \\(\\boldsymbol{N}^k\\) is used to denote a vector of lengths or ages for tag-cohort \\(k\\). In general, only the length frequency is known at time of release for each tag-cohort because ageing is a fatal process. We consider two different approaches for seeding a tag cohort within spatial age-structured models. The two methods are essentially the same but differ in whether the length are converted to age outside of the model (“External”) or done within the model (“Internal”). The internal method requires users to supply length frequency for each tag-cohort and the model will use the assumed growth assumptions and sex ratios to convert the lengths to ages. The external approach will use an age-length key outside of the model to derive an age frequency that can then be supplied to the model. A frequent assumption of age-structured tagging models in the literature (Maunder 1998; Vincent, Brenden, and Bence 2020) is that the age-frequency of each tag-cohort is known. Due to the fact that ageing is a fatal process, we assume they have used the external approach. If the age-length key is representative, then this method is expected to be very similar and have better computational performance. Factors to consider at time of release are; gear method used to select releases, where releases occur, and time of releases. If growth is estimated within the assessment model, then the internal method may be prefered to keep the growth assumptions consistent between LF observations and other model quantities. One down fall of the internal approach is tag releases and recoveries are both length-based inputs. Due to age-structured modelling growth as length conditional on age. Moving individuals back and forwards through the age-length transition matrix (length \\(\\rightarrow\\) age \\(\\rightarrow\\) length) will cause “smearing” of length frequencies. This is demonstrated in Figures @(ref:addagelength) and @(ref:showagelengthtransition_problem), and needs to be considered when considering model fitted values for observations and corresponding likelihood assumptions. Given this phenomenon, we make the argument that the external age-length key approach should be used. The external method means we assume (there actually is error in this) the ages of released fish and time at liberty, thus we know the age at recovery. Figure 7.9: An example of theoretical length at age, with overlapping length bins used to describe the effect of going back and fourth through the age-length transition matrix. ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. Figure 7.10: A visualisation of the effect of going back and forth through an age-length transition matrix. This can happen when tag releases and recaptures are input as length in an age-structured model. The model converts lengths to ages, then reconverts the age to length for observations. This is assuming the same age-length relationship in Figure 7.9 Internal method Age-structured stock assessment models contain growth models, which describe length conditioned on age. This requires assumptions on the distribution and associated parameters. The default is often the normal distribution with mean length at age denoted by \\(\\bar{l}_a\\) with standard deviation parameterised as a coefficient of variation (\\(\\sigma_a = cv*\\mu_a\\)). This information enables the model to derive a growth transition matrix \\(P_{l|a}\\). Given the lower and upper limits for each length bin denoted as \\(\\boldsymbol{b} = (b_1, b_2, \\dots, b_{max})&#39;\\), the probability of being in length bin \\(l\\) given age \\(a\\) \\[\\begin{equation} P_{l|a} = \\begin{cases} \\Phi(b_{l + 1}|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } l = 1\\\\ \\Phi(b_{l + 1}|\\mu_a,\\sigma_a) - \\Phi(b_l|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } 1 &lt; l &lt; n_l\\\\ 1 - \\Phi(b_{l}|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } l = n_l \\end{cases} \\tag{3.6} \\end{equation}\\] where \\(\\Phi(x|\\mu,\\sigma)\\) is the cumulative normal (but could be generalised to any probability distribution). If growth varies by attributes such as sex, stock or region then this will need to be calculated for each growth model. At the point a tag cohort is released, the model can derive the length composition of the vulnerable population using the transition matrix derived in Equation (eq:agelengthtransition). Given the number of estimable parameters that govern the age-stricture at a point in time and growth model, an exploitation rate is calculated so that if there are not enough numbers in a length bin to be tagged, a penalty can be added to the objective function to dissuade the combination of parameters that generated this situation. Tag-release by length is a known quantity and so the model must allow for a minimum vulnerable length composition to that released. To enforce this, an exploitation rate by length \\((u_l)\\) is calculated as follows, \\[\\begin{equation} u_l = \\frac{N^k_{l}}{\\sum_a}N_{y_k,a,r_k} P_{l|a} \\tag{7.1} \\end{equation}\\] During parameter estimation there are no constraints within the model to trial a set of parameters that will allow \\(u_l &gt; 1\\) i.e., more observed tag-releases than in the available population. To stop negative numbers at age, \\(u_l\\) is set at a level less than 1 and a penalty added to the objective function to discourage parameters from allowing this condition. Finally, tag-release at age is calculated as follows, \\[\\begin{equation} N^k_{a} = N_{y_k,a,r_k} P_{l|a} u_l \\tag{7.2} \\end{equation}\\] Once the tag cohort are created in the model it is assumed that tagged fish are exposed to the same dynamics as un-tagged fish. Revisit this we will want to explore mixing behaviour/assumptions. External method (Age-length key method) Once a tag-release event has occurred for tag group \\(k\\), the only known knowledge is the length distribution \\(N^k_l\\). Assuming there is an accessible forward age-length key which describes the proportion of ages for a given length bin \\(\\left(P_{a|l}\\right)\\) that is representative of the vulnerable population to tagging for the same area and time, then the “forward” or “classic” key method can be used Ailloud and Hoenig (2019). If tag-release coincide with a fishing season you could use fishery-dependent derived age length information, assuming the selectivity curves within a length bin are parallel. If only a subset of fish from each haul are released, it would be better to construct an age-length key from a representative sample of fish that were caught but not-tagged. This would be relevant for single vessel survey release events. \\[\\begin{equation} N^k_a = \\sum\\limits_{l = 1}P_{a|l}N^k_l \\end{equation}\\] where, \\(N^k_a\\) is used as an known input into the model with no error. Revist can we account for uncertainty here? Things to consider for tag release we don’t have much information regarding sex of tagged fish (36.5% of recovered tags have sex information) References "],["InitialModelSetup.html", "Chapter 8 Initial model setup Model start time Model spatial resolution of the model Fishery structure Repeat regression analysis on survey LF data", " Chapter 8 Initial model setup Use Punt (2019) to outline the key considerations When did we choose to start the model and why. was it assumed to be in an equilibrium state What spatial regions did we start with and why How many fisheries? What observations were included? how were they initially weighted Model start time The start year for the current stock assessment is 1960. This is the earliest year in which catch is available. There is early sex-aggregated length composition from the Japanese longline fleet along with a CPUE index for that same fleet in the 60’s/70’s. The survey data doesn’t kick in until mid to late 70’s. Unfortunately catch is the most limiting data input, where we can only go back to 1977 before we loose information on regional catch be gear method (pers comms kari Fenske). For this reason 1977 was the start year for the spatial assessment model. Model spatial resolution of the model This section describes the decision making process we took in configuring an initial spatial model. The first consideration was whether to include areas outside of the Gulf of Alaska (GOA) and the Bering sea Aleutian islands region, which is the spatial extent for the current stock assessment (D. Goethel et al. 2021). Sablefish inhabit a broad spatial distribution from the northeastern Pacific Ocean from northern Mexico to the Gulf of Alaska. It is currently assessed by three assessment bodies, the first is the area of focus, being the Bering sea and gulf of Alaska (D. Goethel et al. 2021), one off the west coast of Canada (Cox et al. 2011) and the west coast from California to Oregon (Stewart et al. 2011). Given the complex juvenile life history coupled with long range movement capabilities of adults, the stock structure of sablefish has been a topic of extensive research. A recent genetic study by Jasonowicz et al. (2017), found no significant difference between samples off the west coast of US, GOA and Bering sea (there were no samples off the west coast of Canada in this study), providing evidence for a single panmictic population. A recent morphometric study (Kapur et al. 2020), found significant differences in fish traits such as length at age between samples from the west coast of US and GOA. These results were consistent with the findings from Tripp-Valdez et al. (2012). Tagging is another important information source, with extensive tag releases along the entire North Pacific. Tag recovery data provide evidence for a two stock hypothesis (Kimura and Shavy 1998). With a stock north of Vancouver Island and a stock to the south. For the purposes of this research, we will assume GOA and BS, hereinafter refereed to as the GOABS complex, is isolated (i.e., no movement in or out of this region) from Canada and the west coast of the US. Although there is evidence to include part of Canada (Figure 7.3). Due to practical considerations regarding data sharing and the time-frame of this research Canada was excluded. The focus of this research is to build and explore a spatially explicit model for the GOABS complex. The general approach taken, was to build an initial spatial model that had the finest spatial resolution possible and aggregate regions as data limitations and model convergence issues arose. This finest model spatial resolution was initially based on the input data set with the coarsest reported spatial resolution. Data sets have been reported at different spatial resolutions over time. In general, data are reproted at three levels of spatial resolution: latitude and longitude (high spatial resolution), statistical area (Figure 8.1) and larger fishery management boundaries (Figure 8.2). Input data sets and the spatial resolution available are described in the following table. Figure 8.1: Statistical and reporting areas for GOABS complex Figure 8.2: Fishery management plan boundaries. The Eastern Gulf is often reported at subareas split up be East/West Yakutat and sometimes Southeast. Data source Description and spatial resolution Catch pre 1990 Available at FMP spatial resolution Catch post 1990 Available at FMP spatial resolution Observer data (Age,Length and catch) Latitude and Longitude positions Survey data (Age, Length and catch) Latitude and Longitude positions Tagging data Latitude and Longitude for releases, Latitude and longitude for approximately half the recoveries Reported catch from commercial fishers seems to be the most limiting data set which has the coarsest reported spatial resolution (check this statement). For this reason, the finest spatial resolution we will consider is the fishery management plan boundaries (FMP) being, Bering Sea, Aleutian Islands, Western Gulf, Central Gulf and Eastern Gulf i.e., five area model (Figure 8.3). Although this was determined by a reporting constraint, this is also the spatial resolution that ABC’s are allocated for In addition to the reported spatial resolution of the data, we need to consider if there is any spatial sampling stratification within a data set. Sampling designs that have spatially varying stratification and thus spatially varying sampling intensity, could be inappropriate to use for alternative spatial stratifications. Often post-stratified estimators are not as efficient or accurate as design based estimators that are consistent with the sampling design. Fortunately in this case, the independent survey design is systematic. This results in consistent spatial sampling with respect to space, and removes this concern when considering alternative regional boundaries. Figure 8.3: The finest spatial resolution that we are considering for Sablefish assessment Fishery structure I used the approach from Lennert-Cody et al. (2010) to analysis length frequency samples to identify changes in length frequency that may suggest alternative fleet or stock structures. My understanding of the method described in Lennert-Cody et al. (2010) is that it uses regression trees to identify splits/nodes in the covariates latitude, longitude and season that generate groups/clusters of length frequency distributions that are similar or somewhat homogenous. “Assuming sampling coverage is adequate, comparison of pooled and individual-year tree results can identify spatial structure that is strongly indicated in every year, and that which is only present in select years, perhaps as a result of strong recruitment or changes in catchability, or if sampling coverage is not adequate, sampling variability.” A limitation for this method for our application is latitude and longitude grids contain unequal areas due to the shrinking of longitudes towards the poles. Also with the unusual shape of the coastline binary splits by latitude and longitude may also be a problem. Table 8.1: Longitude splits based on regression tree analysis Variable Split value Cell Variance explained (%) Split1 Lon 180 NA 6 Split2 Year 2015 2 10 Split3 Lon 212 2 13 Split4 Lon 206 4 14 Split5 Qrt 12;34 2 15 Figure 8.4: Longitude splits based on regression tree analysis from Table 8.1 A summary of fishing effort distributions by region and year. This plots the depth latitude and longitude within one of the five regions for observed fishing events. Figure 8.5: Boxplot of depth by observed fishing event Figure 8.6: Boxplot of latitude by observed fishing event Figure 8.7: Boxplot of longitude by observed fishing event Repeat regression analysis on survey LF data I repeated the regression tree analysis for LF data on the survey data to see what spatial and temporal structures are in the Survey LF data. Interestingly it chose to have a longitude split at 206 degrees which was present in the fixed gear LF analsyis and the same break out at the Aleutian islands. Table 8.2: Longitude splits based on regression tree analysis for survey data Variable Split value Cell Variance explained (%) Split1 Year 2015 NA 13 Split2 Lon 206 1 19 Split3 Lon 178 1 23 Split4 Year 1986 3 25 Split5 Lon 206 5 28 Figure 8.8: Longitude splits based on regression tree analysis from Table 8.2 References "],["modelIterations.html", "Chapter 9 Model iterations Single Area model", " Chapter 9 Model iterations Based on our exploratory analysis we have developed the three following spatial models 5 Area Merge EY/WY/SouthEast into EGOA 3 Area Merge Bering Sea, Aleutian Islands, and Western Gulf regions 1 Area merge all regions Single Area model Due to the focus on spatial assessment models for this research, data sets that are in the current assessment were dropped during initial model development. These included, early Japanese fishery CPUE, early Japanese Length frequency observations and the NFMS trawl survey. The early Japanese data was dropped because it could not be disaggregated by sex or space. The trawl survey was initially not included because we believe that we have sufficient information from the longline survey and the trawl survey does not monitor the core sablefish depth range, which was thought to possibly introduce data conflict due to sampling variation which we wanted to minimize. Figure 9.1: Observation frequency assumed in the SpatialSablefishAssessment (SSA) model As a validation step, we compare SpatialSablefishAssessment which was developed for this research with the 2021 stock assessment (D. Goethel et al. 2021) (Not the exact assessment model as I made some changes/fixes). There are a few fundamental differences between these assessment models, which are listed below Start year 1977. Because SpatialSablefishAssessment does not have that early data. The model would not converge if started in 1960 No temporal overlap in age and length composition. The current assessment model provides age composition (aggregated by sex) and length composition (disaggregated by sex) simultaneously in years for the longline survey and fixed gear fishery. Because we use the age-length key method to derive age-frequencies, that treatment thought to be inappropriate due to the double use of the length data. Age and Length composition are sexually disaggregated. As described in Chapter 13 we assume for an observation in a year that composition sum to one over sex and age. Slightly different treatment of initial age deviations for non-equilibrium age-structure Fishing mortality are catch conditioned and not estimated as free parameters An initial fishing mortality parameter was estimated as a free parameter. The current assessment assuems 10% of the estimated average fixed gear fishing mortality Even with the differences stated above, the models produced similar fits and estimated model quantities for overlapping years. Figure 9.2: Estimated SSB (kt) between the current assessment (CA) and SpatialSablefishAssessment (SSA) Figure 9.3: Estimated fishing mortality between the current assessment (CA) and SpatialSablefishAssessment (SSA) Figure 9.4: Estimated recruitment between the current assessment (CA) and SpatialSablefishAssessment (SSA) Figure 9.5: Compare fits to the survey biomass observation between current assessment (CA) and SpatialSablefishAssessment (SSA) Include tagging data An additional iteration was run for the single area model that included tag-recovery observations to see what would happen. References "],["taglike.html", "Chapter 10 Tag likelihoods Likelihoods Simple simulation", " Chapter 10 Tag likelihoods This section explores a range of tag-recovery likelihoods that have been used in the literature. A simple tag recapture model is used in a simulation to explore how well different likelihoods estimate movement parameters under a range of over-dispersion assumptions. The tag-recapture model ignores age and models number of tagged fish from a release event denoted by \\(k\\) over three regions indexed by \\(r\\) for \\(n_t\\) discrete time-steps. \\(T^k_{r,t}\\) denotes the number of tagged fish from release event \\(k\\) in region \\(r\\) and time step \\(t\\). The model applies the following processes between time-steps. \\[\\begin{align*} T^k_{r,t} &amp; = T^k, \\quad t = 0\\\\ T^k_{r,t + 1} &amp; = T^k_{r,t} e^{-Z_t}, \\quad t &gt; 0\\\\ Z_t &amp; = M + F_t \\\\ \\boldsymbol{T}^k_{t + 1} &amp; = \\boldsymbol{T}^k_{t + 1} \\boldsymbol{M} \\end{align*}\\] where, \\(T^k\\) is the initial nunmber of tag releases for release event \\(k\\), \\(\\boldsymbol{T}^k_{t + 1} = (T^k_{1,t + 1},\\dots, T^k_{n_r,t + 1})\\) is a vector of numbers of tagged fish across all regions and \\(\\boldsymbol{M}\\) is a \\(n_r \\times n_r\\) movement matrix. This assumes each region has the same fishing mortality in each time-step. Likelihoods For all possible tag-recovery events indexed by \\(m\\) (where \\(m = \\{r,t\\}\\) i.e., has an implied region and time-step dimension) the tag-recapture model derives expected tag-recoveries. In this case, any time or region that has any fishing mortality rate is considered a possible tag-recovery event. All the likelihoods in the following sections use the same derivation for expected tag-recoveries, which follows \\[ N^k_{m} = T^k_{r,t} \\left(1 - e^{-Z_t}\\right) \\frac{F_t}{Z_t}, \\quad m = \\{r,t\\} \\ . \\] Poisson The Poisson is the simplest likelihood, which was explored by Hilborn (1990). It assumes \\[ N^k_{m} \\sim \\mathcal{Poisson}(\\widehat{N}^k_{m}) \\, \\] with the total log-likelihood contribution evaluating the Poisson log-likelihood over all possible release and recovery events (\\(\\sum\\limits_k\\sum\\limits_m\\)) Negative Binomial A similar likelihood to the Poisson is the Negative Binomial which was explored by Hanselman et al. (2015). This is a more flexible likelihood as it allows for over dispersion, through an additional estimable parameter denoted by \\(\\phi\\) \\[ N^k_{m} \\sim \\mathcal{NB}(\\widehat{N}^k_{m}, \\widehat{\\phi}) \\, \\] with the total log-likelihood contribution evaluating the Negative binomial log-likelihood over all possible release and recovery events (\\(\\sum\\limits_k\\sum\\limits_m\\)) Multinomial:release conditioned The release conditioned multinomial likelihood was explored by Polacheck et al. (2006) and subsequently by Vincent, Brenden, and Bence (2020) &amp; D. R. Goethel, Legault, and Cadrin (2014). This treats all recovery events plus an additional not-recovered event as a multinomial distributed event. \\[ \\boldsymbol{N}^k \\sim \\mathcal{Multinomial}\\left(\\widehat{\\boldsymbol{\\theta}}^k\\right) \\] where, \\(\\boldsymbol{N}^k\\) is the vector of tag-recoveries for all possible recovery events (\\(n_m\\)) plus an additional not-recovered event. \\[ \\boldsymbol{N}^k = (N^k_1, N^k_2, \\dots, N^k_{n_m}, N^k_{NR}) \\] where, \\(N^k_{NR}\\) represents the not recovered category and is \\(N^k_{NR} = T^k - \\sum\\limits_m^{n_m} N^k_m\\), where \\(T^k\\) is the initial number of tags released for event \\(k\\). \\(\\widehat{\\boldsymbol{\\theta}}^k\\) is a vector of proportions that sum to one, with the same dimensions as \\(\\boldsymbol{N}^k\\) and is calculated as, \\[ \\widehat{\\theta}^k_m = \\frac{\\widehat{N}^k_{m}}{T^k}, \\quad \\forall \\ m \\in (1, \\dots,n_m) \\] where, again \\(T^k\\) is the initial number of tags released for event \\(k\\). The proportions for the not recaptured group is calculated as, \\[ \\widehat{\\theta}^k_{NR} = 1 - \\sum_m^{n_m} \\widehat{\\theta}^k_m \\] Recapture conditioned The multinomial which is recapture conditioned follows that described by Vincent, Brenden, and Bence (2020) but based on the original work of McGarvey and Feenstra (2002). This likelihood evaluates the probability of recapturing a tagged fish in a certain region among all possible regions for a given release event and time-period. \\[ \\boldsymbol{N}^k_t \\sim \\mathcal{Multinomial}\\left(\\widehat{\\boldsymbol{\\theta}}_t^k\\right) \\] where, \\(\\boldsymbol{N}^k_t\\) is the vector of tag-recoveries in all regions (\\(n_m\\)) for release event \\(k\\) and time period \\(t\\) \\[ \\boldsymbol{N}^k_t = (N^k_{1,t}, N^k_{2,t}, \\dots, N^k_{n_r,t}) \\] and model predicted proportions \\[ \\widehat{\\boldsymbol{\\theta}}_t^k = (\\widehat{\\theta}^k_{1,t}, \\widehat{\\theta}^k_{2,t}, \\dots, \\widehat{\\theta}^k_{n_r,t}) \\] and, \\[ \\widehat{\\theta}^k_{r,t} = \\frac{\\widehat{N}^k_{r,t}}{\\sum\\limits_r \\widehat{N}^k_{r,t}} \\] The literature (McGarvey and Feenstra 2002; Vincent, Brenden, and Bence 2020) often describes the log likelihood as \\[ ll = \\sum_k\\sum_y\\sum_r log(\\widehat{\\theta}^k_{r,t}) \\times N^k_{r,t} \\] Simple simulation To explore these likelihoods are very simple simulation was setup to see how well each likelihood could estimate elements of \\(\\boldsymbol{M}\\) under different levels of over-dispersion. The simulation assumes all tags encountered where reported (100% reporting rate) and both natural mortality and fishing mortality are known without error. The only estimated parameters were \\(\\boldsymbol{M}\\) and \\(\\phi\\) when the negative binomial likelihood was explored. Tag recovery observations were all simulated using the negative binomial likelihood with varying over-dispersion parameters. The following is some R-code that was used to generate operating model values for set.seed(123) n_y = 5 n_regions = 3 M = 0.13 F_y = rlnorm(n = n_y, log(0.2), 0.6) Z_y = F_y + M S_y = exp(-Z_y) # make up some random movement matrix move_matrix = matrix(0, ncol = n_regions, nrow = n_regions) diag(move_matrix) = c(0.7, 0.5, 0.6) move_matrix = move_matrix + rnorm(n = n_regions * n_regions, 0.1,0.05) move_matrix = sweep(move_matrix, MARGIN = 1, STATS = rowSums(move_matrix), FUN = &quot;/&quot;) ## seed tag releases tag_release_by_region = rep(1000, n_regions) n_release_events = n_regions ## Calculate tag-partition tags_partition_by_release_event = array(0, dim = c(n_regions, n_y + 1, n_release_events)) expected_tag_recoveries = tag_recovery_obs = array(0, dim = c(n_regions, n_y, n_release_events)) for(r in 1:n_release_events) tags_partition_by_release_event[r,1,r] = tag_release_by_region[r] for(y in 1:n_y) { for(rel_event in 1:n_release_events) { ## ageing and F tags_partition_by_release_event[,y + 1, rel_event] = tags_partition_by_release_event[,y,rel_event] * S_y[y] ## Movement tags_partition_by_release_event[,y + 1, rel_event] = tags_partition_by_release_event[,y + 1, rel_event] %*% move_matrix } } ## Create tag-recovery expected values for(rel_event in 1:n_regions) { expected_tag_recoveries[,,rel_event] = sweep(tags_partition_by_release_event[ ,2:(n_y + 1),rel_event], MARGIN = 2, STATS = F_y / Z_y * (1 - S_y), FUN = &quot;*&quot;) } The following code chunk assumes tags_partition_by_release_event is the same among simulations, but uses the negative binomial with a range of over-dispersion parameters to simulate tag-recoveries for n_sim times. We explore Relative error (RE) and mean square error (MSE) for the different likelihood choices. n_sim = 500 ## Populate TMB objects data = list() data$n_y = n_y data$n_regions = n_regions data$M = M data$F_y = F_y data$tag_likelihood = 0 ## Poisson data$tag_recovery_obs = tag_recovery_obs data$number_of_tags_released = tag_release_by_region data$movement_transformation = 0 ## simplex, can use the logistic transformation as well ## starting values est_parameters = list() start_matrix = matrix(0, ncol = n_regions, nrow = n_regions) diag(start_matrix) = c(0.95, 0.95, 0.95) start_matrix = start_matrix + rnorm(n = n_regions * n_regions, 0.02,0.0001) ## force to sum = 1 start_matrix = sweep(start_matrix, MARGIN = 1, STATS = rowSums(start_matrix), FUN = &quot;/&quot;) est_parameters$transformed_movement_pars = matrix(NA, nrow = n_regions - 1, ncol = n_regions) for(i in 1:n_regions) est_parameters$transformed_movement_pars[,i] = simplex(start_matrix[i,]) est_parameters$ln_phi = log(1) ## don&#39;t estimate phi parameter unless Negative binomial na_map = fix_pars(par_list = est_parameters, pars_to_exclude = &quot;ln_phi&quot;) OM_mat = melt(move_matrix) colnames(OM_mat) = c(&quot;From&quot;, &quot;To&quot;,&quot;proportion&quot;) OM_mat$type = &quot;OM&quot; ############################################ ## over_diserpsion_investication ## what happens when we simualte from ## negative binomial with different ## over-dispersion parameters ############################################ over_dispersion_params = c(0.1, 0.2, 0.3, 0.5, 1, 10) n_sim = 500 # use the simplex data$movement_transformation = 0 sim_data_info = NULL complete_df = NULL for(over_ndx in 1:length(over_dispersion_params)) { this_dispersion = over_dispersion_params[over_ndx] full_move_df = NULL; temp_proportion_zeros_sim_data = temp_variance_sim_data = c() for(sim in 1:n_sim) { ## keep expected values the same among simulations for(rel_event in 1:n_release_events) { for(y in 1:n_y) { for(r in 1:n_regions) { tag_recovery_obs[r,y,rel_event] = rnbinom(n = 1, mu = expected_tag_recoveries[ r,y,rel_event], size = this_dispersion) } } } ## summarise number of zeros and variance of observed data temp_proportion_zeros_sim_data = c(temp_proportion_zeros_sim_data, sum(tag_recovery_obs == 0)); temp_variance_sim_data = c(temp_variance_sim_data, var(tag_recovery_obs)); ## save data data$tag_recovery_obs = tag_recovery_obs ## Poisson data$tag_likelihood = 0 est_obj &lt;- MakeADFun(data, est_parameters, map = na_map, DLL=&quot;SimpleTagEstimator&quot;, silent = T) est_obj$env$tracepar = F opt_poisson = nlminb(est_obj$par, est_obj$fn, est_obj$gr, control = list(iter.max = 10000, eval.max = 10000)) poisson_rep = est_obj$report(opt_poisson$par) sd_poisson = sdreport(est_obj) ## Multinomial release conditioned data$tag_likelihood = 1 est_obj &lt;- MakeADFun(data, est_parameters, map = na_map, DLL=&quot;SimpleTagEstimator&quot;, silent =T) opt_multi_release = nlminb(est_obj$par, est_obj$fn, est_obj$gr, control = list(iter.max = 10000, eval.max = 10000)) multi_release_rep = est_obj$report(opt_multi_release$par) sd_multi_release = sdreport(est_obj) ## Multinomial recapture conditioned data$tag_likelihood = 2 est_obj &lt;- MakeADFun(data, est_parameters,map = na_map, DLL=&quot;SimpleTagEstimator&quot;, silent = T) opt_multi_recap = nlminb(est_obj$par, est_obj$fn, est_obj$gr, control = list(iter.max = 10000, eval.max = 10000)) multi_recap_rep = est_obj$report(opt_multi_recap$par) sd_multi_recap = sdreport(est_obj) ## recapture conditioned data$tag_likelihood = 3 est_obj &lt;- MakeADFun(data, est_parameters,map = na_map, DLL=&quot;SimpleTagEstimator&quot;, silent = T) opt_recap = nlminb(est_obj$par, est_obj$fn, est_obj$gr, control = list(iter.max = 10000, eval.max = 10000)) recap_rep = est_obj$report(opt_recap$par) sd_recap = sdreport(est_obj) ## Negative binomial data$tag_likelihood = 4 est_obj &lt;- MakeADFun(data, est_parameters, DLL=&quot;SimpleTagEstimator&quot;, silent = T) opt_nb = nlminb(est_obj$par, est_obj$fn, est_obj$gr, control = list(iter.max = 10000, eval.max = 10000)) nb_rep = est_obj$report(opt_nb$par) sd_nb = sdreport(est_obj) ## reformat movement estimates pois_mat = melt(poisson_rep$movement_matrix) pois_mat$RE = (pois_mat$value - OM_mat$proportion) / OM_mat$proportion * 100 pois_mat$SE = (OM_mat$proportion - pois_mat$value)^2 pois_mat$type = &quot;Poisson&quot; pois_mat$sim = sim recap_mat = melt(recap_rep$movement_matrix) recap_mat$RE = (recap_mat$value - OM_mat$proportion) / OM_mat$proportion * 100 recap_mat$SE = (OM_mat$proportion - recap_mat$value)^2 recap_mat$type = &quot;Recapture&quot; recap_mat$sim = sim multi_release_mat = melt(multi_release_rep$movement_matrix) multi_release_mat$RE = (multi_release_mat$value - OM_mat$proportion) / OM_mat$proportion * 100 multi_release_mat$SE = (OM_mat$proportion - multi_release_mat$value)^2 multi_release_mat$type = &quot;Multinomial Release&quot; multi_release_mat$sim = sim nb_mat = melt(nb_rep$movement_matrix) nb_mat$RE = (nb_mat$value - OM_mat$proportion) / OM_mat$proportion * 100 nb_mat$SE = (OM_mat$proportion - nb_mat$value)^2 nb_mat$type = &quot;Negative Binomial&quot; nb_mat$sim = sim full_move_df = rbind(full_move_df, rbind(pois_mat, recap_mat, multi_release_mat, nb_mat)) } prop_obs_zero = temp_proportion_zeros_sim_data / (dim(data$tag_recovery_obs)[1] * dim(data$tag_recovery_obs)[2] * dim(data$tag_recovery_obs)[3]) tmp_df = data.frame(avg_proportion_zero = mean(prop_obs_zero), avg_var = mean(temp_variance_sim_data), over_dispersion_param = this_dispersion) sim_data_info = rbind(sim_data_info, tmp_df) full_move_df$over_dispersion_param = this_dispersion complete_df = rbind(complete_df, full_move_df) } colnames(complete_df) = c(&quot;From&quot;, &quot;To&quot;,&quot;proportion&quot;, &quot;RE&quot;, &quot;SE&quot;, &quot;type&quot;, &quot;sim&quot;, &quot;over_dispersion_param&quot;) Table 10.1: Average proportion of zeros and variance of simulated data for different overdispersion settings. avg_proportion_zero avg_var over_dispersion_param 0.603 10135.388 0.1 0.417 5552.975 0.2 0.296 4003.506 0.3 0.176 2321.719 0.5 0.068 1505.669 1.0 0.002 561.667 10.0 Figure 10.1: Relative error in movement parameters. Columns are overdispersion values for simulated data. GGplot facets are movement matrix elemen combinatons Figure 10.2: Estimated movement parameters, red line is true value. Columns are overdispersion values for simulated data. GGplot facets are movement matrix elemen combinatons Figure 10.3: Mean squared error (MSE) over all simulations and estimated parameters. References "],["growth.html", "Chapter 11 Growth Growth estimation using the Laslett–Eveson–Polacheck (LEP) method Simulation test the “LEP” method Next steps", " Chapter 11 Growth Growth is an important input in stock assessments. Although we are not considering spatial varying growth in the spatial stock assessments due to computational reasons. We still want to look at the data to see if growth is significantly different between the spatial regions under consideration. Growth estimation using the Laslett–Eveson–Polacheck (LEP) method Another use of tag-recovery data is for estimating growth models which are important inputs for stock assessment models. The section explores the “Laslett–Eveson–Polacheck (LEP)” approach, based on Laslett, Eveson, and Polacheck (2002) &amp; Eveson, Laslett, and Polacheck (2004) and described in Aires-da-Silva et al. (2015). The idea is to use a single growth model that fits to two observational data sets (ideally within the assessment, but for now this analysis is independent of the assessment). The two data sets are are age and length observations and tag-increment observations from tagging experiments. A benefit of this method, other than estimating growth is that estimates of ages of fish at release are a derivative that can then be used as inputs for tag releases in an age-structured stock assessment model (what to do with observations with no sex information?). Age-at-length growth model The Richards growth curve was assumed as was done in Aires-da-Silva et al. (2015) (but this could be extended). The Richards growth formulation follows \\[\\begin{equation} \\bar{l}_{a} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a - a_0)\\}\\right)^{-p} \\tag{11.1} \\end{equation}\\] where, \\(\\bar{l}_{a}\\) is the mean length at age \\(a\\), \\(L_{\\infty}\\) is the asymptotic length, \\(K\\) is the growth coefficient and \\(p\\) is a shape parameter that is related to the ratio \\(\\bar{l}_{a} / L_{\\infty}\\) at the inflexion point. Tag recapture growth data Symbol Description \\(l_{1,i}\\) length of individual \\(i\\) at release \\(l_{2,i}\\) length of individual \\(i\\) at recapture \\(a_{1,i}\\) age of individual \\(i\\) at release. Denoted as \\(A\\) in Aires-da-Silva et al. (2015) \\(a_{2,i}\\) age of individual \\(i\\) at recapture \\(\\Delta_t\\) Time at liberty \\(\\Delta_t = a_{2,i} - a_{1,i}\\) Just one comment on notation!!! in most all the papers that use this method, they ignore the individual notation of \\(A\\). That is not an issue in general however it confuses me when they describe the prior on this. The sub-models for the release and recapture lengths follow, \\[\\begin{equation} l_{1,i} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a_{1,i} - a_0)\\}\\right)^{-p} \\tag{11.2} \\end{equation}\\] and, \\[\\begin{equation} l_{2,i} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a_{1,i} + \\Delta_t - a_0)\\}\\right)^{-p} \\tag{11.3} \\end{equation}\\] The above growth model assumes that we know the age at recovery \\(a_{2,i}\\). The problem we have is, we have 22 569 tag recoveries with length information but only a handful of these have been aged. This is dealt with by modelling \\(a_{1,i}\\) as a random effect i.e., \\(a_{1,i} \\sim LN \\left(\\mu, \\sigma^2\\right)\\). What confuses is me here is how to assign a hyper distribution like the one above for the random effect variables \\(a_{1,i}\\). \\(a_{1,i}\\) is expected to vary quite a bit because tagged fish at release have a broad length frequency and thus is expected to have a broad age at release? (ask someone about this because I may be misunderstanding something). Simulation test the “LEP” method ## going to use parameters from Aires-da-Silva et al. (2015) Table 1 integrated analysis L_inf = 200.8 k = 0.44 t_0 = 1.26 p = -4.27 cv = 0.15 ## cv of length around length at age ## selectivity paraemters sel_a50 = 1.3 sel_ato95 = 0.8 ## sample sizes for simulation n_sample_release = 1000 n_sample_recoveries = 1000 * 0.1 ## about the recovery rate from sablefish data n_sample_age_length = 1000 ## generate a pseudo age structure set.seed(123) R_0 = 200000 M = 0.29 ages = 1:20 n_ages = length(ages) #plot(ages, mean_length_at_age, type = &quot;l&quot;, lwd = 3, xlab = &quot;Age&quot;, ylab = &quot;Length (cm)&quot;) sel_at_age = logis(ages, sel_a50, sel_ato95) ## numbers at age N_age = vector(length = n_ages, &quot;numeric&quot;) for (age_ndx in 1:n_ages) N_age[age_ndx] = R_0 * exp(-ages[age_ndx] * M) * exp(rnorm(1,0,0.7)) N_age = N_age * sel_at_age ## vulnerable numbers at age plot(ages, N_age, ylab = &quot;Numbers&quot;, xlab = &quot;Age&quot;, main = &quot;Population age-structure&quot;, type = &quot;o&quot;) ## plot growth mean_length_at_age = richards_growth(ages, p, k, t_0, L_inf) ## randomly sample 1000 individuals with replacement for otolithing no ageing error!! ## individual_age_length_df = NULL for(i in 1:n_sample_age_length) { age_i = sample(1:n_ages, size = 1, prob = N_age) mean_length_i = richards_growth(age_i, p, k, t_0, L_inf) length_i = rnorm(1, mean_length_i, mean_length_i * cv) temp_df = data.frame(age = age_i, length = length_i) individual_age_length_df = rbind(individual_age_length_df, temp_df) } ## Simulate a tag-recapture experiment # releases release_ages = sample(1:n_ages, size = n_sample_release, prob = N_age, replace = T) release_mean_lengths = richards_growth(release_ages, p, k, t_0, L_inf) release_lengths = rnorm(n_sample_release, release_mean_lengths, release_mean_lengths * cv) individual_release_df = data.frame(release_age = release_ages, release_length = release_lengths, release_mean_length = release_mean_lengths) individual_release_df$fish_id = 1:nrow(individual_release_df) # recaptures sample uniformly without replacement fish_ndx = sample(1:nrow(individual_release_df), size = n_sample_recoveries, replace = F) individual_recovery_df = subset(individual_release_df, subset = individual_release_df$fish_id %in% fish_ndx) ## time-at liberty days randomly recovered on average between 100-600 days individual_recovery_df$time_at_liberty = rpois(n = n_sample_recoveries, lambda = runif(n_sample_recoveries,100,600)) individual_recovery_df$recovery_age = individual_recovery_df$release_age + individual_recovery_df$time_at_liberty/365 ## how to add the length increment between release and recovery? individual_recovery_df$recovery_mean_length = richards_growth(individual_recovery_df$recovery_age, p, k, t_0, L_inf) individual_recovery_df$recovery_mean_length_increment = with(individual_recovery_df, recovery_mean_length - release_mean_length) individual_recovery_df$recovery_length = with(individual_recovery_df, release_length + rlnorm(n_sample_recoveries, log(recovery_mean_length_increment), cv)) individual_recovery_df$growth_change = individual_recovery_df$recovery_length - individual_recovery_df$release_length ## visualise length at age samples ggplot(individual_age_length_df, aes(x = age, y = length)) + geom_point() + geom_line(data= data.frame(length = mean_length_at_age, age = ages), aes(x = age, y = length), col = &quot;red&quot;, linewidth = 1.2, inherit.aes = F) + labs(x = &quot;Age&quot;, y = &quot;Length&quot;) + ylim(0,NA) Assumptions in the above OM follow. \\[ l_{1,i} \\sim \\mathcal{N} \\left(\\bar{l}_{1,a}, \\sigma = \\bar{l}_{1,a} \\times cv\\right) \\] where the mean length at age release (\\(\\bar{l}_{1,a}\\)) follows the Richards growth curve defined in Equation (11.1). The age used to derive the mean length at age was a random sample with replacement from the population in shown in the earlier figure. Time at liberty was drawn from a Poisson distribution with a rate parameter randomly drawn from a uniform distribution between 100-600 days. The age at recovery \\(a_{2,i} = a_{1,i} + \\Delta_t\\). An approximation was made when calculating the length at recovery. The length increment (\\(l_{\\Delta_t}\\)) was simulated using a Log Normal distribution with the median set based on the difference between mean length at release age and mean length at recovery age. This was to ensure all recovered fish positively grew at a rate expected by the growth model (less than ideal but will do for now). \\[ l_{i,\\Delta_t} \\sim \\mathcal{LN} \\left(\\ln (\\bar{l}_{a_{2,i}} - \\bar{l}_{a_{1,i}}), \\sigma = cv\\right) \\] \\[ l_{2,i} = l_{1,i} + l_{i, \\Delta_t} \\] In theory we can now pass this data to our LEP model to back estimate growth parameters. setwd(file.path(&quot;TMB&quot;)) #sink(file = &quot;compile_output.txt&quot;) compile(file = &quot;LEPgrowth_model.cpp&quot;, flags = &quot;-Wignored-attributes -O3&quot;) #sink() dyn.load(dynlib(&quot;LEPgrowth_model&quot;)) #setwd(DIR$book) # data data = list() data$ages_from_age_length = individual_age_length_df$age data$lengths_from_age_length = individual_age_length_df$length data$lengths_at_release = individual_recovery_df$release_length data$lengths_at_recovery = individual_recovery_df$recovery_length data$time_at_liberty = individual_recovery_df$time_at_liberty / 365 data$ages_for_report = ages; data$p_bounds = c(-20, 20) data$t0_bounds = c(-6, 4) # parameters parameters = list() parameters$ln_cv_length_at_age = log(cv) parameters$ln_k = log(k) parameters$ln_L_inf = log(L_inf) parameters$logit_p = logit_general(p, data$p_bounds[1],data$p_bounds[2]) parameters$logit_t0 = logit_general(t_0, data$t0_bounds[1],data$t0_bounds[2]) parameters$ln_cv_length_release = log(0.1) parameters$ln_cv_length_recovery = log(0.1) parameters$ln_age_at_release = log(individual_recovery_df$release_age) parameters$ln_mu_age_release = log(3) parameters$ln_sd_age_release = log(1) obj_mixed_all &lt;- MakeADFun(data, parameters, random = &quot;ln_age_at_release&quot;, DLL=&quot;LEPgrowth_model&quot;) MLE_mixed_all = nlminb(start = obj_mixed_all$par, objective = obj_mixed_all$fn, gradient = obj_mixed_all$gr) MLE_mixed_all$convergence MLE_mixed_all_rep = obj_mixed_all$report(obj_mixed_all$env$last.par.best) MLE_mixed_all_sd_rep = sdreport(obj_mixed_all) plot(ages, MLE_mixed_all_rep$mean_length_at_age, type = &quot;l&quot;, lwd = 3, col = &quot;red&quot;, xlab = &quot;Age&quot;, ylab = &quot;Length (cm)&quot;, ylim = c(0, 240)) lines(ages, mean_length_at_age, col = &quot;blue&quot;, lty = 3, lwd = 3) legend(&#39;bottomright&#39;, legend = c(&quot;LEP obs error&quot;,&quot;True&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = c(1,2), lwd = 3) Next steps Check sensitivity to the model to starting parameters Repeat with different sample sizes Repeat with a truncated age-structure for the age-length data using a selectivity Look at Sablefish data and see if the LEP approach can be used to it Explore alternative growth models i.e., Schnute (1981) References "],["refpoints.html", "Chapter 12 Review/summarise reference points", " Chapter 12 Review/summarise reference points Most of my experience with reference points are spawning biomass related i.e., \\(SSB_y/SSB_0\\). However, many of the reference points outside of New Zealand are \\(F\\) based i.e., \\(F_{35\\%}\\) which I don’t really understand. The purpose of this section is to define them mainly to help me understand, but also as a reference for when I forget in the future. Symbol Description/Calculation \\(SSB^{\\%B_0}_{y}\\) Percent \\(B_0\\) \\(= \\frac{SSB_y}{B_0}\\) \\(SPR\\) Spawner per recruit a measure/proxy of population fecundity \\(F_{35\\%spr}\\) \\(F\\) 35% The Fishing mortality that results in a 35% SPR \\(SPR_{msy}\\) SPR at MSY "],["sexratios.html", "Chapter 13 Sex ratios in age and length composition data A simple simulation", " Chapter 13 Sex ratios in age and length composition data An immediate improvement in the current stock assessment (Chapter 3) relates to how sexually disaggregated compositional data are handled. Currently LF’s are separated by sex (needed for the different growths) and age compositional data are aggregated over both sexes. Although LFs are disaggregated by sex and should (in theory) be sufficient to estimate sex specific selectivities. It is not ideal to use LFs to estimate age-based selectivities because older cohorts “smush” into single modes and age information is lost. Before developing a spatially explicit model stock assessment model, I wanted to tidy some loose ends that may come back and bite me in the proverbial butt once we explore the spatially sex disaggregated stock assessment model in anger. These things are exponentially more easier to deal with in “simpler” models. My general intention is to drop length data when we have well sampled age data, currently they both go into the model together. For age composition data I want to structure the observations so that there is potential information on sex ratio. The current assessment can be given information on sex ratio for generating model predicted values which is similar to the approach in Ward et al. (2019). Howver, I personally think this should be dealt within the model. I am aware of two approaches for supplying observations that in theory should provide information on sex ratio. The first (“Approach 1”) was taken from Casal2 (Doonan et al. 2016). This treats sexed composition data for a year as a single proportion i.e., proportions across all ages and sexes sum to one for each year, \\[ \\boldsymbol{P}^k_{y} = \\frac{(C^k_{a,y,1},C^k_{a,y,2})}{\\sum_a \\sum_s C^k_{a,y,s}}, \\quad \\sum \\boldsymbol{P}^k_{y} = 1 \\] where, \\(C^k_{a,y,1}\\) is the catch at age (numbers) for males in year \\(y\\), age \\(a\\) and survey \\(k\\). \\(\\boldsymbol{P}^k_{y}\\) is a proportion vector that sums to one that covers both sexes and corresponding ages. The likelihood contribution for this approach follows \\[ \\boldsymbol{P}^k_{y} \\sim Multinomial(\\mathbb{E}[\\boldsymbol{P}^k_{y}], N^{eff, k}_{y}) \\ . \\] where, \\(N^{eff, k}_{y}\\) is the effective sample size for this survey and year. The second approach (“Approach 2”) is to treat composition for each sex seperately that is proportions at age or length for a sex will sum to one, but also provide a specific sex ratio observation over all ages or lengths as done in the New Zealand rock lobster stock assessment (Webber, Rudd, and Starr 2021). \\[ R^k_{y,s} = \\frac{\\sum_a C^k_{a,y,s}}{\\sum_a \\sum_s C^k_{a,y,s}}, \\quad \\sum_s R^k_{y,s} = 1 \\] and, \\[ P^k_{a, y,s} = \\frac{C^k_{a,y,s}}{\\sum_a C^k_{a,y,s}}, \\quad \\sum_a P^k_{a, y,s} = 1 \\ . \\] The likelihood assumptions for this model are, \\[ R^k_{y,s} \\sim Binomial(\\mathbb{E}[R^k_{y,s}], \\sum_s N^{eff, k}_{y,s}) \\] and, \\[ \\boldsymbol{P}^k_{y,s} \\sim Multinomial(\\mathbb{E}[\\boldsymbol{P}^k_{a, y,s}], N^{eff, k}_{y,s}) \\ . \\] where, \\(N^{eff, k}_{y,s}\\) is the effective sample size. A simple simulation To explore the utility of these two approaches we conducted a simple simulation using a sexually disaggregated age-structured model (see simulation section below). The Operating Model (OM) used in the simulation assumed a 50:50 sex ratio during the recruitment process however the OM did assume different growth and selectivity among the sexes. Results In summary both approaches resulted in similar estimates in selectivities and SSBs. I prefer Approach 1 as it is a single observation compared with Approach 2 which has two observation types (need to consider how to avoid double counting of samples), but this simulation showed at least within the very small assumptions explored here they resulted in similar performance. This was all I was after in order to move forward to the spatial model. Another consideration about “Approach 2” is if the selectivity shape differs between sexes i.e., lower age at 50% retention. Then due to the sex ratio being derived by summing numbers over all ages, and the natural exponential decay in successive age-cohorts, selectivities that capture more younger fish will result in higher sex ratios. “Approach 1” Future research that was not considered in this simple simulation LF observations with sexual dimorphism in growth. A possible reason LF’s could be influencing assessment output is due to mis-specified growth à la Minte-Vera et al. (2017) Sample size between the two approaches Actual sex ratio skewed in the recruitment process, rather than just a selectivity effect which was of focus in the following simulation Look at the effect on \\(F\\)’s I only summarised SSB and selectivities Look at some residuals to see if that is a way to discredit some of these models ### Operating Model (OM) Parameters {-} set.seed(123) n_sims = 5 bio_params = list( ages = 1:20, L_inf_m = 58, K_m = 0.133, t0_m = 0, L_inf_f = 62, K_f = 0.143, t0_f = 0, M = 0.15, a_m = 2.18e-9, ## tonnes b_m = 3.2, a_f = 2.08e-9, ## tonnes b_f = 3.3, m_a50 = 2.3, m_ato95 = 1.2, sigma = 0.6, h = 0.85, sigma_r = 0.6, R0 = 8234132, plus_group = 1 # 0 = No, 1 = Yes ) other_params = list( s_a50_m = 3.6, s_ato95_m = 2, s_a50_f = 4.6, s_ato95_f = 1.4, s_q = 0.2, s_alpha = 1, f_a50_m = 4.2, f_ato95_m = 1.17, f_a50_f = 4.7, f_ato95_f = 1.76, f_alpha = 1, ssb_prop_Z = 0.5, survey_prop_Z = 0.5, survey_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) fishery_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) survey_bio_cv = c(0.1) ) ages = bio_params$ages max_age = max(bio_params$ages) n_years = 30 years = (2020 - n_years + 1):2020 n_ages = length(ages) ## annual fishing mortality start_F = c(rlnorm(10, log(seq(from = 0.02, to = 0.1, length = 10)), 0.1), rlnorm(10, log(0.1), 0.1), rlnorm(10, log(0.07), 0.1)) recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r)) Figure 13.1: Examples of the two approaches for the survey (top row) and fishery (bottom row). The black and red line in approach 1 will sum to one, where as the black line and red line in approach will each sum to one. Approach 2 has an extra observation which is the proportion male (not shown). Scenario 1 The first simulation assumed the OM had 50:50 males and female sex ratio at recruitment, and selectivities were as described in the above OM section. We simulated 100 data sets for each of the two approach’s for sexually disaggregated compositional data outlined in the introduction. These were then fitted to in two EM’s, where the EM’s differed in the approach they used. Both EM’s estimated a scalar on the female selectivity that allowed females to be more or less selected compared to males for both the fishery and survey. This was done be introducing an estimable \\(\\alpha\\) parameter into the selectivity. Males selectivities were constrained to have a max value = 1 using, \\[\\begin{equation} S^{male}_a = 1/(1+19^{(a_{50}-a)/a_{to95})}) \\tag{13.1} \\end{equation}\\] where as the female was \\[\\begin{equation} S^{female}_a = \\alpha/(1+19^{(a_{50}-a)/a_{to95})}) \\tag{13.2} \\end{equation}\\] Although this scenario assumed both male and female had the same max selectivity I wanted to see the effect of estimating this additional parameter. A third EM (EM3) was also explored, this structured compositional data using Approach 1 but fixed the female \\(\\alpha\\) = 1 in Equation (13.2). This is often the default approach. For scenario 1 this should be the best performing EM as it has the \\(\\alpha\\) set at the values of the OM. EM 1 (using approach 1) ## max gradient from 100 simualtions = 1.858256e-06 Figure 13.2: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 13.3: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 2 (using approach 2) ## max gradient from 100 simualtions = 5.591513e-11 Figure 13.4: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 13.5: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 3 (using approach 1 with female fixed at \\(\\alpha = 1\\)) ## max gradient from 100 simualtions = 6.455864e-07 Figure 13.6: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 13.7: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs Scenario 2 The second scenario assumed sex ratio was 50:50 at recruitment and females were more selective than males to the fishery. This was done by setting \\(\\alpha\\) = 1.2 in Equation (13.2). true_pars$logit_f_alpha_f = logit_general(1.2, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2]) EM 1 (using approach 1) ## max gradient from 100 simualtions = 6.54662e-07 Figure 13.8: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 13.9: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 2 (using approach 2) ## max gradient from 100 simualtions = 3.796794e-07 Figure 13.10: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 13.11: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 3 (using approach 1 with female fixed at \\(\\alpha = 1\\)) ## max gradient from 100 simualtions = 2.748698e-07 Figure 13.12: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 13.13: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs References "],["Fexplore.html", "Chapter 14 Fishing mortality approaches Set up a simulation Appendix - Hybrid approach", " Chapter 14 Fishing mortality approaches The current Alaskan sablefish stock assessment (Chapter 3) estimates annual fishing mortality values for each gear \\(g\\) denoted by \\(F^g_{y}\\). This parametersation poses to potential problems when considering future assessment models and spatial models. The first is, the number of parameters will increase as the number of gears increase. The fishery is currently going through a transformation whereby there is a switch from longline to pots. The second consideration is how to set this up in a spatially explicit model where catch have an added spatial dimension. There are two alternative approaches to the current approach which treat \\(F\\) as a derived quantity rather than an estimable parameter. The first is to use Newton Raphson method to solve for \\(F^g_{y}\\). This is the recommended approach in Stock Synthesis (Methot Jr and Wetzel 2013), termed the “hybrid” approach. The previous two methods assume the Baranov catch equation for mortality (Baranov 1918). An alternative is to assume Popes discrete formulation (Pope 1972) which uses exploitation proportions (sometimes called harvest rates or fishing pressure) and has a closed form solution. A good general overview on these methods can be found in Branch (2009). They describe and compared the continuous Baranov catch equation (Baranov 1918) with Pope’s discrete formulation (Pope 1972). Arguments for using the continuous case is that \\(M\\) and \\(F\\) occur simultaneously, also with the continuous case, \\(F\\) allows for multiple event encounters, this is assuming a fleet has the same selectivity and availability, that a fish that escapes one net can be caught in another. In contrast, the discrete formulation only allows a fish to be caught or escape from an instantaneous event. I have tried to summarize the benefits of the continuous equation in the following list, Allows the entire population to be caught (not sure this is that relevant) Allows simultaneous \\(M\\) and \\(F\\), no need to worry about order of operations. From a coding/practical perspective this is quite attractive. Once you have an F and M you can easily derive all mid-mortality quantities. Where as using a \\(U\\) approach you need save the population before and after to interpolate to derive mid-mortality quantities. The magnitude of \\(F\\) effects composition data, where as in the discrete case, composition is independent of the magniture of \\(U\\). Allows for multiple catch events of an individual Can fit to catch observations thus allows for uncertainty in catches. In practice the uncertainty/variance on catch is very small i.e., coeffecient of variations ranging from 0.01 to 0.1. This essentially states catch is observed with high confidence and in my opinion isn’t that much different to saying catch is known exactly. Note often this high precision on observed catch is needed in order to make the \\(F\\)’s identifiable. This high precision also muddies the “degrees of freedom” for the model. Although the \\(F\\)’s look like independent and free parameters they are heavily constrained by the assumptiosn on observed catch variance. The arguments for the discrete approximation is that there is an analytical solution for \\(U\\) and so is fast to calculate expected catch, where as \\(F\\) has to be either solved numerically or estimated as a free parameter (as mentioned earlier). Chris Francis’s wrote a response to this paper (Francis 2010) where he argues the discrete formulation does not preclude the multiple encounters and that only the data can truly tell us which catch equation is the best one to use. Need to make a point about how there may be Automatic differentiation issues with the \\(U\\) approach. Because there is an if(U &gt; 0.99) which can cause a fork in the chain rule which can equal a coding nightmare. The relationship between \\(F\\) (Instantaneous fishing mortality) and \\(U\\) exploitation rate for a simple scenario (single fishery) is illustrated in the following R code. exploitation_rates = seq(0,0.8,by = 0.02) ## calculate F given a U fishing_mortalites = -log(1 - exploitation_rates) ## back calculate U given a F # 1 - exp(-fishing_mortalites) The objective of this simulation Is the method efficient i.e., no loss of speed. Is the method numerically stable (No NaNs during optimization), particularly under high fishing pressure Figure 14.1: Illustration of how mortality is applied to an age cohort continuously over time (y). Set up a simulation To explore the above described methods a simple simulation was conducted using a simple age-structured stock assessment operating model. The model assumed 15 seperate fisheries all with a common selectivity. The purpose was to check that the derived methods were reliable (provided unbiased stock quantities) and that they are computationally efficient. bio_params = list( ages = 1:20, L_inf = 58, K = 0.133, t0 = 0, M = 0.15, a = 2.08e-9, ## tonnes b = 3.5, m_a50 = 6.3, m_ato95 = 1.2, sigma = 0.6, h = 0.85, sigma_r = 0.6, R0 = 8234132, plus_group = 1 # 0 = No, 1 = Yes ) other_params = list( s_a50 = 3.6, s_ato95 = 2, s_q = 0.2, f_a50 = 5, f_ato95 = 2, ssb_prop_Z = 0.5, survey_prop_Z = 0.5, survey_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) fishery_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) survey_bio_cv = c(0.1) ) ages = bio_params$ages max_age = max(bio_params$ages) n_years = 30 years = (2020 - n_years + 1):2020 n_ages = length(ages) ## annual fishing mortality start_F = c(rlnorm(10, log(seq(from = 0.05, to = 0.2, length = 10)), 0.1), rlnorm(10, log(0.13), 0.1), rlnorm(10, log(0.07), 0.1)) recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r)) length_at_age = vonbert(bio_params$ages, bio_params$K, bio_params$L_inf, bio_params$t0) fishery_ogive = logis(bio_params$ages, other_params$f_a50, other_params$f_ato95) survey_ogive = logis(bio_params$ages, other_params$s_a50, other_params$s_ato95) mat_age = logis(bio_params$ages, bio_params$m_a50, bio_params$m_ato95) weight_at_age = bio_params$a * length_at_age^bio_params$b ## observation temporal frequency survey_year_obs = years survey_ages = 1:20 fishery_year_obs = years fishery_ages = 1:20 ## simulate data set.seed(123) sim_data = ASM_obj$simulate(complete = T) ## Build AD TMB functions start_pars = ran_start_vals() est_model_est_F = MakeADFun(sim_data, true_pars, DLL= &quot;SimpleAgestructuredModelMultiFs&quot;, map = na_map, silent = T) sim_data$F_method = 1 sim_data$F_iterations = 4 est_model_hybrid_F = MakeADFun(sim_data, true_pars, DLL= &quot;SimpleAgestructuredModelMultiFs&quot;, map = na_map_hybrid, silent = T) ## optimise opt_model_est_F = nlminb(est_model_est_F$par, est_model_est_F$fn, est_model_est_F$gr, control = list(iter.max = 10000, eval.max = 10000)) opt_model_hybrid_F = nlminb(est_model_hybrid_F$par, est_model_hybrid_F$fn, est_model_hybrid_F$gr, control = list(iter.max = 10000, eval.max = 10000)) ## look at the number of iterations used to solve opt_model_hybrid_F$iterations ## [1] 187 opt_model_est_F$iterations ## [1] 697 ## get reports = rep_est_hybrid = est_model_hybrid_F$report(est_model_hybrid_F$env$last.par.best) rep_est_F = est_model_est_F$report(est_model_est_F$env$last.par.best) plot(TMB_data$years, rep_est_hybrid$ssb[-1], type = &quot;l&quot;, lwd = 3, xlab = &quot;Year&quot;, ylab = &quot;SSB&quot;, ylim = c(0,46000)) lines(TMB_data$years, rep_est_F$ssb[-1], type = &quot;l&quot;, lwd = 3, lty = 2, col = &quot;purple&quot;) lines(TMB_data$years, sim_data$ssb[-1], type = &quot;l&quot;, lwd = 4, lty = 3, col = &quot;red&quot;) legend(&quot;topright&quot;, col = c(&quot;black&quot;, &quot;purple&quot;, &quot;red&quot;), legend = c(&quot;Hybrid&quot;, &quot;Est F&quot;, &quot;OM&quot;), lwd = 3) est_F_bench = benchmark(obj = est_model_est_F, n = 1000) hybrid_F_bench = benchmark(obj = est_model_hybrid_F, n = 1000) est_F_bench ## elapsed ## template.likelihood 1.008 ## template.gradient 1.550 hybrid_F_bench ## elapsed ## template.likelihood 2.053 ## template.gradient 4.230 ben_est_F &lt;- benchmark(obj = est_model_est_F, n=20,expr=expression(do.call(&quot;optim&quot;,obj))) ben_hybrid_F &lt;- benchmark(obj = est_model_hybrid_F, n=20,expr=expression(do.call(&quot;optim&quot;,obj))) ben_est_F ## elapsed ## do.call(&quot;optim&quot;, obj) 14.709 ben_hybrid_F ## elapsed ## do.call(&quot;optim&quot;, obj) 11.897 These results have highlighted the following Both the Free \\(F\\) and hybrid estimate very similar model quantities i.e., SSB’s and F’s The Free \\(F\\) method is much faster on average for a single gradient calculation and function call compared to the hybrid method However, the hybrid method requires less iterations due to there being less estimated parameters. For this simulation where we assumed 15 fisheries both optimised in similar amounts of time Appendix - Hybrid approach The hybrid fishing mortality process uses the methods and algorithms applied in Stock Synthesis (Methot Jr and Wetzel 2013). The descriptions below are heavily based on the text describing this approach in the Appendix of (Methot Jr and Wetzel 2013). This process begins by calculating popes discrete approximation, and then converts this to Baranov fishing mortality coefficients. A tuning algorithm is then done to tune these coefficients to match input catch nearly exactly, rather than the full Baranov approach. Total mortality, denoted by \\(Z_{a,y,s,r}\\) for sex \\(s\\), region \\(r\\), age \\(a\\) and year \\(y\\) will hereby be denoted by \\(Z_{a,y,s}\\) i.e., drop the region index. This is because mortality rates are calculated independently (in isolation) among regions (NOTE consider parallelising this in the model). \\[\\begin{equation*} Z_{a,y,s} = M_{a,y,s} + \\sum\\limits_{f} S^g_{y,s} F^g_y \\end{equation*}\\] where, \\(M_{a,s}\\) is the natural mortality rate, \\(F^g_y\\) is fishing mortality and \\(S^g_{a,s}\\) is the selectivity. The hybrid fishing mortality method allows the \\(F\\) values to be “tuned” to match input catch nearly exactly, rather than estimating them as free model parameters. The process begins by calculating mid year exploitation rate using Pope’s approximation. This exploitation rate is then converted to an approximation of the Baranov continuous \\(F\\). The \\(F\\) values for all fisheries operating in that year and region are then tuned over a set number of iterations (f_iterations) to match the observed catch for each fishery with its corresponding \\(F\\). Differentiability is achieved by the use of Pope’s approximation to obtain the starting value for each \\(F\\) and then the use of a fixed number of tuning iterations, typically 4. Tests from Stock Synthesis have shown that modelling \\(F\\) as hybrid versus \\(F\\) as a parameter has trivial impact on the estimates of the variances of other model derived quantities. The hybrid method calculates the harvest rate using the Pope’s approximation then converts to an approximation of the corresponding F as: \\[\\begin{align} V^g_{y} &amp;= \\sum\\limits_s\\sum\\limits_a N_{a,y,s} \\exp\\left(-\\delta_t M_{a,s}\\right) \\nonumber \\\\ \\tilde{U}^g_{y} &amp;= \\frac{C^g_{y}}{V^g_{y} + 0.1 C^g_{y}}\\\\ j^g_{y} &amp;= \\left(1 + \\exp \\left(30 (\\tilde{U}^g_{y} - 0.95) \\right)\\right)^{-1}\\\\ U^g_{y} &amp;= j^g_{y} \\tilde{U}^g_{y} + 0.95 (1 - j^g_{y} )\\\\ \\tilde{F}^g_{y} &amp;= \\frac{-\\log\\left(1 - U^g_{y}\\right)}{\\delta_t} \\end{align}\\] where, \\(C^{g}_y\\) is the observed catch, \\(\\delta_t\\) is the duration of the period of observation within the year. In most situations where the entire catch has been observed in a time-step. This should be one. \\(V^g_{y}\\) is partway vulnerable biomass and \\(\\tilde{F}^g_{y}\\) is the initial \\(F\\). The formulation above is designed so that high exploitation rates (above 0.95) are converted into an F that corresponds to a harvest rate of close to 0.95, thus providing a more robust starting point for subsequent iterative adjustment of this F. The logistic joiner, \\(j\\), is used at other places in Stock Synthesis to link across discontinuities. The tuning algorithm begins by setting \\(F^g_{y} = \\tilde{F}^g_{y}\\) and repeating the following algorithm f_iteration times. \\[ \\widehat{C}_{a,y,s} = \\sum\\limits_g {F}^g_{y}S^g_{a,s} N_{a,y,s}\\bar{w}_{a,y,s} \\lambda^*_{a,y,s} \\] where, \\(\\lambda^*_{a,y,s}\\) denotes the survivorship and is calculated as: \\[\\begin{equation} \\lambda^*_{a,y,s} = \\frac{1 - \\exp\\left(-\\delta_t Z_{a,y,s} \\right) }{Z_{a,y,s}} \\tag{14.1} \\end{equation}\\] Total fishing mortality is then adjusted over several fixed number of iterations (typically four, but more in high F and multiple fishery situations). The first step is to calculate the ratio of the total observed catch over all fleets to the predicted total catch according to the current F estimates. This ratio provides an overall adjustment factor to bring the total mortality closer to what it will be after adjusting the individual \\(F\\) values. \\[ \\widehat{C}_{y} = \\sum\\limits_g \\sum\\limits_s\\sum\\limits_a {F}^g_{y}\\left(S^g_{a,s} N_{a,y,s}\\right) \\lambda^*_{a,y,s} \\] This is different from Equation A.1.25 in the Appendix of (Methot Jr and Wetzel 2013). They include \\(Z_{a,y,s}\\) in the denominator when describing \\({F}^g_{y}\\), I think this is a typo error because \\(Z_{a,y,s}\\) is already included in the denominator when calculating \\(\\lambda^*_{a,y,s}\\) (see Equation (14.1)). \\[ Z^{adj}_y = \\frac{\\sum\\limits_g C^g_{y}}{\\widehat{C}_{y}} \\] The total mortality if this adjuster was applied to all the Fs is then calculated: \\[ Z^*_{a,y,s} = M_{a,s} + Z^{adj}_y \\left(Z_{a,y,s} -M_{a,s} \\right) \\] \\[ \\lambda^*_{a,y,s} = \\frac{1 - \\exp\\left(-\\delta_t Z^*_{a,y,s} \\right) }{Z^*_{a,y,s}} \\] The adjusted mortality rate is used to calculate the total removals for each fishery, and then the new \\(F\\) estimate is calculated by the ratio of observed catch to total removals, with a constraint to prevent unreasonably high \\(F\\) calculations (max_f): \\[\\begin{align*} \\tilde{V}^g_{y} &amp;= \\sum\\limits_s\\sum\\limits_a \\left(N_{a,y,s} \\bar{w}_{a,y,s}S^g_{a,s} \\right)\\lambda^*_{a,y,s} \\\\ F^{g*}_{y} &amp;= \\frac{C^g_{y}}{\\tilde{V}^g_{y} + 0.0001}\\\\ j^{g*}_{y} &amp;= \\left(1 + \\exp \\left(30 (F^{g*}_{y} - 0.95 F_{max}) \\right)\\right)^{-1}\\\\ \\end{align*}\\] where, \\(F_{max}\\) is a user defined maximum fishing mortality f_max. The \\(F\\) at the end of each tuning iteration follows: \\[ F^g_{y} = j^{g*}_{y} F^{g*}_{y} + \\left(1 - j^{g*}_{y}\\right)F_{max} \\] After the tuning algorithm removals at age, and other derived quantities are recorded. The final total mortality is updated \\[ Z_{a,y,s} = M_{a,s} + \\sum\\limits_{g} S^g_{a,s} F^g_{y} \\] This process generates catch at age and sex for each year (and region) (\\(\\widehat{C}^g_{a,y,s}\\)) which can be accessed by process_removals observations. Numbers at age are calculated as \\[ \\widehat{C}^g_{a,y,s} = \\frac{F^g_{a,s,y}}{Z_{a,y,s}} N_{a,y,s} \\exp\\left(-Z_{a,y,s}\\right) \\] Total catch is the summed over all sexes and age \\[ \\widehat{C}^g_{y} = \\sum\\limits_s\\sum\\limits_a \\widehat{C}^g_{a,y,s} \\bar{w}_{a,y,s} \\] where \\(\\bar{w}_{a,y,s}\\) is the mean weight References "],["spatialInit.html", "Chapter 15 Initialising the plus group in spatial models", " Chapter 15 Initialising the plus group in spatial models In single area age-structured models, the plus age group is calculated using a solution to an infinite geometric series. This solution for an age-structured model is used to derive initial (equilibrium) state of the partition. The partition consists of a vector of numbers at age for each category denoted by \\(\\textbf{N}\\); \\[ \\textbf{N} = (N_1, N_2, ... , N_{a_+})^T \\] where \\(N_{a_+}\\) denotes the numbers in the plus group. The numbers at age for a single area population with no density-dependent processes is derived as, \\[ N_a = \\left\\{ \\begin{array}{lcl} R_0 &amp; \\mbox{for} &amp; a = 1 \\\\ R_0e^{-aM} &amp; \\mbox{for} &amp; 1 &lt; a &lt; a_+ \\\\ R_0e^{\\sum_{i = a_+}^\\infty-iM} &amp; \\mbox{for} &amp; a = a_+ \\end{array}\\right. \\] Initialization for ages \\(1 \\leq a &lt; a_+\\) is easy, all you need to do is iterate the model \\(a_+ - 1\\) times and the age classes will be populated with there respected initial numbers at age. However, for the plus group (\\(N_{a_+}\\)) the solution is needed. Although the plus group may start at let say 30 years old, it actually represents 30 and 31 and 32 up to some biological plausible value lets say 130, but mathematically can be thought of as \\(\\infty\\). The plus group is modeled for practical reasons and care should be given when choosing the cut-off maximum age. The plus group is an infinite geometric series that is defined by the common ratio \\(r_{a_+} = M\\). \\[\\begin{align} N_{a_+} &amp;= R_0e^{\\sum_{a = a_+}^\\infty-aM}\\\\ &amp;= R_0 \\frac{e^{M - a_+M}}{1 - e^{-M}} \\end{align}\\] M = 0.1 R0 = 4e6 plus_group_age = 30 N_age = R0 * exp(-M * 1:plus_group_age) ## numerically calculate it N_plus_group = tail(N_age, n = 1) for(i in 1:10000) { N_plus_group = N_plus_group * exp(-M) + tail(N_age, n = 1) * exp(-M) } N_plus_group ## [1] 1893568 ## using the geometric series calculation R0 * exp(-M - plus_group_age*M) / (1 - exp(-M)) ## [1] 1893568 The question becomes, how do we calculate this plus group when there is markovian movement? This code shows how the same infinite geometric series solution works for the plus group with movement. Instead of the common ratio being just it also need to account for the movement process. Let \\(c^r_{a+}\\) denote the accumulation of individuals into the plus group in region \\(r\\). This will be the result of ageing, natural mortality and movement. Then the plus group for that region can be \\[ N_{a+, r} = N_{a+ - 1, r} \\frac{1}{1 - c^r_{a+}} \\] where, \\(N_{a+ - 1, r}\\) is the numbers at age for the second to last age cohort in the plus group. The following R code shows how this is equivalent to running the annual cycle for 1000 years. M = 0.1 R0 = 4e6 n_regions = 3 movement_matrix = matrix(0, nrow = n_regions, ncol = n_regions); movement_matrix[1,] = c(0.7, 0.2, 0.1) movement_matrix[2,] = c(0.1, 0.6, 0.3) movement_matrix[3,] = c(0.15, 0.05, 0.8) ## rows are &quot;from&quot; cols are &quot;to&quot; plus_group_age = 30 ## partition N_age = matrix(0, nrow = n_regions, ncol = plus_group_age) ## initialise with no movement initially N_age[1,] = R0 * exp(-M * 1:plus_group_age) ## N_age[2,] = R0 * exp(-M * 1:plus_group_age) ## N_age[3,] = R0 * exp(-M * 1:plus_group_age) ## ## apply an annual cycle 10000 times to see what the &quot;initial conditions should be&quot; N_next_year_age = N_age for(i in 1:1000) { ## recruitment N_next_year_age[,1] = R0 * exp(-M) ## ageing and mortality N_next_year_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) ## plus group N_next_year_age[,plus_group_age] = N_next_year_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) ## movement N_age = t(movement_matrix) %*% N_next_year_age } iterative_N_age = N_age plot(1:plus_group_age, N_age[3,], xlab = &quot;Age&quot;, ylab= &quot;Initial numbers&quot;, ylim = c(0,R0* 1.4), type = &quot;l&quot;, lwd = 3) lines(1:plus_group_age, N_age[2,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, N_age[1,], lwd = 3, col = &quot;blue&quot;, lty = 2) legend(&#39;topright&#39;, col = c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;), legend = c(&quot;Region 3&quot;, &quot;Region 2&quot;, &quot;Region 1&quot;), lwd = 3) N_age = matrix(0, nrow = n_regions, ncol = plus_group_age) update_N_age = N_age for(i in 1:(plus_group_age)) { # recruitment update_N_age[,1] = R0 * exp(-M) # ageing and mortality update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) # plus group update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) # movement N_age = t(movement_matrix) %*% update_N_age } ## calculate one more annual cycle # recruitment update_N_age[,1] = R0 * exp(-M) # ageing and mortality update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) # plus group update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) # movement update_N_age = t(movement_matrix) %*% update_N_age ## approximate! c = update_N_age[,plus_group_age] / N_age[,plus_group_age] - 1 update_N_age[,plus_group_age] = N_age[,plus_group_age] * 1 / (1 - c) iterative_N_age[,plus_group_age] ## [1] 1758313 1217294 2705097 update_N_age[,plus_group_age] ## [1] 1758313 1217294 2705097 plot(1:plus_group_age, iterative_N_age[3,], xlab = &quot;Age&quot;, ylab= &quot;Initial numbers&quot;, ylim = c(0,R0* 1.4), type = &quot;l&quot;, lwd = 3) lines(1:plus_group_age, update_N_age[3,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, iterative_N_age[2,], lwd = 3, col = &quot;black&quot;, lty = 1) lines(1:plus_group_age, update_N_age[2,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, iterative_N_age[1,], lwd = 3, col = &quot;black&quot;, lty = 1) lines(1:plus_group_age, update_N_age[1,], lwd = 3, col = &quot;red&quot;, lty = 2) legend(&#39;topright&#39;, col = c(&quot;black&quot;,&quot;red&quot;), legend = c(&quot;Numerical&quot;, &quot;Analytical&quot;), lwd = 3, lty = c(1,2)) "],["glossary.html", "Chapter 16 Glossary of terms", " Chapter 16 Glossary of terms Term Description ALK Age length key OM Operating model EM Estimation model AF Age frequency LF Length frequency "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

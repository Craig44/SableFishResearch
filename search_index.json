[["index.html", "Alaskan sablefish research Chapter 1 Overview Gitbook outline Future things to consider", " Alaskan sablefish research C.Marsh 2022-12-02 Chapter 1 Overview This Gitbook documents my/our research for the Alaska sablefish (Anoplopoma fimbria). The objective is to develop and explore a spatially explicit stock assessment for Alaskan sablefish. However, there will be many topics that I will likely only scratch the surface on. The following section outlines chapters in this document. Gitbook outline Chapter 2 outlines a list of objectives that we have set or accomplished during this research project. Some of our research cannot be presented in this document due to the confidentiality reasons. However, this checklist should include all tasks during the project Chapter 3 documents the current stock assessment model and assumptions (work in progress). This is the first step of the project, with the purpose of helping me understand the assessment, data and important dynamics Chapter 4 documents a generalised spatial stock assessment model used as both an OM and EM during simulations Chapter 5 describes data (other than tagging data see Chapter 6) that was explored for use in the spatial stock assessment model. Chapter 6 describes the tagging data and how it can be used within a spatial stock assessment model but also used in a panmictic model for informing population dynamics such as growth. Chapter 8 explores how to include sex disaggregated composition observations that can include sex ratio information. It conducts a simple simulation to investigate two different approaches Chapter 9 explores how to parameterise fishing mortality. The current approach is to estimate an annual fishing mortality parameter for each gear as a free parameter. I feel slightly uncomfortable about this approach moving towards a spatial model as the number of estimated parameters will explode with spatial areas. This chapter looks at two alternative approaches that either derive fishing mortality estimates using a Newton Raphson solver which is heavily borrowed from the Stock Synthesis “hybrid” approach (Methot Jr and Wetzel 2013) and Pope’s discrete approach (Pope 1972) which uses exploitation rates. Both these methods have been applied in the literature for decades. The aim of this chapter is to do a simulation and make sure the considered approaches are efficient and numerically stability for the purposes of our study Chapter 10 explores how to calculate the plus group in spatially explicit age-structured models that assume markovian movement during initialization Future things to consider How to reduce partition dimension when adding tag-release events When is the latest you can start the model? Currently the assessment model starts in 1960 because there is early survey and catch info along with some of the largest catches observed over the fishery. I want to explore starting the model at later period i.e., the 1980’s when there is consistent surveys and age data. This is thought to reduce the number of estimable parameters that have low information (early recruitment). However, the downfall is we may loose information on stock productivity because the 60’s and 70’s have some of the largest recorded catches. library(TMB) #library(stockassessmenthelper) library(ggplot2) library(dplyr) library(reshape2) library(gridExtra) library(knitr) library(RColorBrewer) References "],["objectives.html", "Chapter 2 A list of objectives/milestones that we have set along the project life", " Chapter 2 A list of objectives/milestones that we have set along the project life Translate current stock assessment (Chapter 3) from ADMB to TMB. Planned date of completion is December 1 2022 Conduct self test using TMB stock assessment model. Planned date of completion is December 1 2022 I decided not to do this because the assessment had too many bespoke likelihoods Consider improvements i.e., sex disaggregated composition data or sex ratio observations (look at the rock lobster assessment) including age-length observations or tag-increment observations to estimate growth internally. (Chapter 8) Characterize both fishery and survey data to get an idea of data limitations when considering spatially explicit stock assessment model. Develop a spatially explicit estimation model in TMB that generalizes the current assessment model. This requires a lot of thought, especially how we want to integrate the tagging data (Chapter 6) "],["modeldescription.html", "Chapter 3 Current Alaskan sablefish stock assessment model 3.1 Process equations 3.2 Observation equations 3.3 Symbol Notation", " Chapter 3 Current Alaskan sablefish stock assessment model The latest published stock assessment (Goethel et al. 2021) is a single area model (Chapter 3). This chapter intends to extend this model by allowing it to be spatially disaggregated. disaggregated integrated age-structured model. Let \\(\\boldsymbol{N_{y,s}}\\) denote a vector of ages in year \\(y\\) for sex \\(s\\) (the partition) i.e., \\(\\boldsymbol{N_{y,s}} = (N_{1,y,s}, N_{2,y,s}, \\dots, N_{a_+,y,s})^T\\). The general process model is sequential and follows the general Equation (3.1), \\[\\begin{equation} \\boldsymbol{N_{y,s}} = \\begin{cases} g\\left(\\boldsymbol{\\theta}\\right), &amp; y = 1959 \\text{ Initial model year}\\\\ f\\left(\\boldsymbol{N_{y-1,s}}|\\boldsymbol{\\theta}\\right), &amp; y &gt; 1959 \\\\ \\end{cases} \\tag{3.1} \\end{equation}\\] where, \\(g(.)\\) is the function describing initial conditions for the partition and \\(f(.)\\) is the function that applies populations dyanmics each year i.e., birth, death, growth and migration. See Section 3.3 &amp; 3.1 for a detailed description of \\(g(.)\\) and \\(f(.)\\) and \\(\\boldsymbol{\\theta}\\) is the set of estimable (not all are estimated) parameters. Maximum Likelihood Estimates (MLE) for estimated parameters \\(\\widehat{\\boldsymbol{\\theta}}_{MLE}\\) are evaluated, \\[\\begin{equation} \\widehat{\\boldsymbol{\\theta}}_{MLE} = \\underset{\\boldsymbol{\\theta}}{\\arg\\max} \\left( L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) \\right) \\tag{3.2} \\end{equation}\\] where, \\(\\boldsymbol{y^{obs}}\\) is a set of observations and \\(L\\left( . \\right)\\) is an objective function that is made up of priors/penalties and log-likelihood. See Section 3.2 3.1 Process equations Initialisation (\\(g\\left(.\\right)\\)) \\[\\begin{align*} N_{a,1,s} = \\begin{cases} R_1, &amp; a = a_1\\\\ \\exp\\bigg( \\mu_r + \\tau_{a_1 - a + 1}\\bigg) \\exp-\\bigg( a - a_1\\bigg) \\bigg( M + F_{hist} * \\mu_{LL} * S^{LL}_{a,1}\\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp( \\mu_r) \\exp-( a - 1) ( M + F_{hist} * \\mu_{LL} * S^{LL}_{a - 1,1})(1 - \\exp( M + F_{hist} * \\mu_{LL} * S^{LL}_{a - 1,1}))^{-1}, &amp; a = a_+ \\end{cases} \\end{align*}\\] Population dynamics (\\(f\\left(.\\right)\\)) The assessment assumes a closed population that is only effected by mortality (natural and fishing), recruitment and growth. Mortality is applied assuming \\[ Z_{a,y,s} = M + \\sum_g F^g_{y} S^g_{a,y,s} \\] where, \\(S^g_{a,y,s}\\) is the fishery selectivity and \\(F^g_{y}\\) is the annual estimated fishing mortality. The annual cycle follows, \\[\\begin{align*} N_{a,y,s} = \\begin{cases} p^s_{y} R_y, &amp; a = a_1\\\\ N_{a - 1,y - 1,s} \\times \\exp\\bigg( -Z_{a - 1,y - 1,s} \\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp\\bigg( -Z_{a - 1,y - 1,s} \\bigg) + \\exp\\bigg( -Z_{a,y - 1,s} \\bigg), &amp; a = a_+ \\end{cases} \\end{align*}\\] where, \\[ R_y = \\exp\\{\\mu_r + \\tau_y + 0.5\\sigma_R^2\\} \\] 3.2 Observation equations Three are three observational types in the current Sablefish stock assessment - Relative abundance indices - Age composition (aggregated over sex) - Length composition (disaggregated by sex) These three observation types come from both fishery dependent i.e., observer programs and CPUE and fishery independent i.e., research surveys. Catch at age Fishery dependent catch at age observations for gear type \\(g\\) denoted by \\(\\boldsymbol{C^g}_{a,y,s}\\) are calculated as follows \\[\\begin{equation} \\boldsymbol{C^g}_{a,y,s} = \\frac{F^g_{a,y,s}}{Z_{a,y,s}} N_{a,y,s} \\left(1 - S_{a,y,s} \\right) \\tag{3.3} \\end{equation}\\] Currently all age observations are sex aggregated which means the model expected values before applying ageing error is \\[ \\boldsymbol{C^g}_{a,y} = 0.5 \\sum_s \\frac{\\boldsymbol{C^g}_{a,y,s}}{\\sum_a\\boldsymbol{C^g}_{a,y,s}} \\] why the 0.5? should be omitted going forward. Ageing error is then incorporated and the values are normalized so that they are proportions, before being passed to the multinomial log-likelihood function. Survey age composition is similar but instead of being a function of \\(F\\) it is calculated at the beginning of the year. For survey \\(k\\) the numbers at age are denoted by \\(\\boldsymbol{C^k}_{a,y}\\) and calculated following \\[\\begin{equation} \\boldsymbol{C^k}_{a,y} = p^s N_{a,y,s} S^k_{y,a,s} \\tag{3.4} \\end{equation}\\] I am not sure exactly what the timing of these surveys are, but do we need to account for som mid-year mortality? or changes in timing of the survey? if so we could easily replace \\[ N_{a,y,s} \\] with \\[ N_{a,y,s} \\exp\\{-p^k_y Z_{a,y,s}\\} \\] where,\\(p^k_y\\) is the proportion of mortality that we want to account for in year \\(y\\) for survey \\(k\\). The survey numbers at age are then adjusted for ageing error and normalised so they sum to one for each year. Relative abundance indices \\[\\begin{equation} \\widehat{I}^g_{y} = \\sum_s\\sum_a p^s N_{a,y,s} \\exp \\{-0.5 Z_{a,y,s}\\} S^g_{y,a,s} \\bar{w}_{a,y,s} \\tag{3.5} \\end{equation}\\] where, \\(\\bar{w}_{a,y,s}\\) is mean weight at age, this can be omitted if the observation is in numbers i.e., abundance instead of biomass and \\(p^s\\) is the proportion for each sex. This is currently a user input, but should be dealt within the model either as having different sex selectivities or through the sex ratio of recruitment. A list of slight improvements change how sex ratio is handled fishery dependent abundance indices i.e., CPUE change \\(N_{a,y,s} \\exp \\{-0.5 Z_{a,y,s}\\}\\) with \\(\\boldsymbol{C^g}_{a,y,s}\\) which is calculated in the catch at age observations. Catch at length For each year that has a length frequency observation, numbers at length denoted by \\(\\boldsymbol{C^l}_{y,s} = (C^l_{1,y,s}, \\dots, C^l_{n_l,y,s})^T\\) (dimension of \\(\\boldsymbol{C^l}_{y,s}\\) is \\(n_l \\ \\times \\ 1\\)) were calculated for each sex. This involved multiplying the catch at age (see above for how it is calculated) through an age-length transition matrix denoted by \\(\\boldsymbol{A}^l_{y,s}\\) (dimensions of \\(\\boldsymbol{A}^l_{y,s}\\) are \\(n_a \\ \\times \\ n_l\\) and its rows must sum to 1). The calculation follows Equation (3.6), \\[\\begin{equation} \\boldsymbol{C^l}_{y,s} = \\left(\\boldsymbol{A}^l_{y,s} \\right)^T \\ \\times \\ \\boldsymbol{C_{y,s}} \\tag{3.6} \\end{equation}\\] where, \\(\\boldsymbol{C_{y,s}}\\) is a column vector of numbers at age (dimension \\(n_a \\ \\times \\ 1\\)) at the beginning of year \\(y\\) for sex \\(s\\). 3.3 Symbol Notation Symbol Description \\(y\\) Year, \\(y = 1960, \\dots, T\\) \\(T\\) Terminal year of the model \\(s\\) Sex index \\(s \\in \\{1,2\\}\\) \\(r\\) Region index \\(r \\in \\{1, \\dots, n_r\\}\\) \\(n_r\\) number of modeled regions \\(a\\) Model age cohort, i.e., \\(a = a_0, a_0 + 1, \\dots\\) \\(a_{1}\\) Recruitment age to the model = 2 \\(a_+\\) Plus-group age class (oldest age considered plus all older ages) \\(n_a\\) Number of age classes modeled \\(a_+ \\ - a_1\\) \\(l\\) length class \\(n_l\\) Number of length classes \\(g\\) gear type index, i.e. longline survey, longline fishery, trawl fishery \\(x\\) log-likelihoos index \\(\\bar{w}_{a,y, s}\\) Average weight at age \\(a\\), year \\(y\\) and sex \\(s\\) \\(\\phi_{a,y}\\) Proportion of female mature by age and year \\(p^s_{y}\\) Proportion of recruits for sex \\(s\\). Often assumed = 0.5 \\(\\ln \\mu_{r}\\) Average log-recruitment \\(\\ln \\mu_{f}\\) Average log-fishing mortality \\(\\phi_{y,g}\\) annual fishing mortality deviation by gear (log space) \\(\\tau_{y}\\) annual recruitment deviation \\(\\sim LogNormal\\left(0,\\sigma_r\\right)\\) \\(\\sigma_r\\) Recruitment standard deviation \\(N_{a,y,s}\\) Numbers of fish at age \\(a\\) in year \\(y\\) of sex \\(s\\) \\(M\\) Natural mortality \\(F^g_{a,y}\\) Fishing mortality for year \\(y\\), age \\(a\\) and gear \\(g\\) \\(F_{hist}\\) Historical proportion of Fishing mortality \\(Z_{a,y}\\) Total mortality for year \\(y\\), age \\(a\\) \\(=\\sum\\limits_g F^g_{a,y} + M\\) \\(R_{y}\\) Annual recruitment \\(B_{y}\\) Spawning biomass in year \\(y\\) \\(S^g_{a,y,s}\\) Selectivity at age \\(a\\) for gear type \\(g\\) and sex \\(s\\) \\(a_50\\) age at 50% selection for ascending limb \\(d_50\\) age at 50% selection for descending limb \\(\\delta\\) slope/shape parameters for different logistic curves \\(\\boldsymbol{A}\\) ageing-error matrix dimensions \\(n_a \\ \\times \\ n_a\\) \\(\\boldsymbol{A}^l_s\\) age to length conversion matrix by sex. dimensions \\(n_a \\ \\times \\ n_l\\) \\(q_g\\) abundance index catchability coeffecient by gear \\(\\lambda_x\\) Statistical weight (penalty) for component \\(x\\) \\(P^g_{l,y,s}\\) Observed proportions at length for gear \\(g\\) in year \\(y\\) and sex \\(s\\) \\(P^g_{a,y,s}\\) Observed proportions at age for gear \\(g\\) in year \\(y\\) and sex \\(s\\) \\(\\psi^g_{y}\\) assumed sample size for gear \\(g\\) in year \\(y\\) (for multinomial likelihood \\(n_g\\) Number of years that age (or length) composition is available for gear \\(g\\) Inference If random effects are considered the joint probability model follows, \\[\\begin{equation} Pr\\left[ \\boldsymbol{y^{obs}}, \\boldsymbol{u}| \\boldsymbol{\\theta} \\right] = Pr\\left[\\boldsymbol{y^{obs}} |\\boldsymbol{\\theta^f}, \\boldsymbol{u} \\right] Pr\\left[\\boldsymbol{u} |\\boldsymbol{\\theta^h} \\right] \\end{equation}\\] Inference is conducted by maximising the marginal likelihood noting \\(L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}} \\right) \\propto Pr\\left[ \\boldsymbol{y^{obs}} | \\boldsymbol{\\theta} \\right]\\) \\[\\begin{equation}\\label{eq:marginal_ll} L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) = \\int \\left(Pr\\left[\\boldsymbol{y^{obs}} |\\boldsymbol{\\theta^f}, \\boldsymbol{\\theta^g}, \\boldsymbol{u} \\right] Pr\\left[\\boldsymbol{u} |\\boldsymbol{\\theta^h} \\right] \\right) \\boldsymbol{du} \\end{equation}\\] In general this integral is not tractable, and so approximations are necessary. The software used here implement the Laplace approximation, which relies on Gaussian assumptions. Maximum Likelihood Estimates (MLE) for fixed effect parameters \\(\\widehat{\\boldsymbol{\\theta}}_{MLE}\\) are evaluated, \\[\\begin{equation} \\widehat{\\boldsymbol{\\theta}}_{MLE} = \\underset{\\boldsymbol{\\theta}}{\\arg\\max} \\left( L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) \\right) \\end{equation}\\] and Empirical Bayes estimates are evaluated for \\(\\widehat{\\boldsymbol{u}}\\), which are used model diagnostics and other model quantities, \\[\\begin{equation} \\widehat{\\boldsymbol{u}} = \\underset{\\boldsymbol{u}}{\\arg\\max} \\left( Pr\\left[ \\boldsymbol{y^{obs}}, \\boldsymbol{u}| \\widehat{\\boldsymbol{\\theta}}_{MLE} \\right] \\right) \\end{equation}\\] TODO Build a validate function to help catch users setting up parameters or data structures that will cause a crash once supplied to TMB. Self test change some parameter containers. In the ADMB model the often share parameters between male and females. Particularly for selectivity parameters. However TMB will not allow us to fix/map parameters across different arrays or vectors. This means we will want to join the male and female selectivity parameter objects into a single object so that we can share parameters between the sexes. Change array column casting from vector&lt;Type&gt;(array.col(i)) to array.col(i).vec() References "],["spatialmodeldescription.html", "Chapter 4 Spatial stock assessment model for Alaskan sablefish 4.1 Process equations", " Chapter 4 Spatial stock assessment model for Alaskan sablefish The latest published stock assessment (Goethel et al. 2021) is a sexually disaggregated integrated age-structured model. Let \\(\\boldsymbol{N_{r,y,s}}\\) denote a vector of ages in year \\(y\\) sex \\(s\\) in region \\(r\\) (the partition) i.e., \\(\\boldsymbol{N_{r,y,s}} = (N_{1,r,y,s}, N_{2,r,y,s}, \\dots, N_{a_+,r,y,s})^T\\). 4.1 Process equations Initialisation (\\(g\\left(.\\right)\\)) \\[\\begin{align*} N_{a,r,1,s} = \\begin{cases} R_r 0.5, &amp; a = a_1\\\\ N_{a - 1,r,1,s} \\exp\\bigg( - (M + F_{hist} * S^{LL}_{a,1})\\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp( \\mu_r) \\exp-( a - 1) ( M + F_{hist} * S^{LL}_{a - 1,1})(1 - \\exp( M + F_{hist}* S^{LL}_{a - 1,1}))^{-1}, &amp; a = a_+ \\end{cases} \\end{align*}\\] The plus group Population dynamics (\\(f\\left(.\\right)\\)) To DO simulation test a spatial model with three areas no tagging data and equilibrium initial conditions Appendix References "],["spatialmodelInputs.html", "Chapter 5 Spatial model inputs 5.1 Survey Abundance data 5.2 Age-frequency 5.3 Observer data 5.4 Growth data 5.5 Catch data Appendix", " Chapter 5 Spatial model inputs This chapter describes how age,length, survey and catch data were used to derive assessment inputs for a myriad of spatially structured assessments. The chapter aims to standardize methods so that we can easily re-work the data to be fit in a 1,2 or \\(n_r\\) area assessment model. Figure 5.1: The finest spatial resolution that we are considering for Sablefish assessment 5.1 Survey Abundance data I am thinking, when it comes to the real data application that we apply a geostatistical model-based estimator. The survey is a systematic/fixed design (do they visit the same locations each year? obviously ignoring the AI BS switching), but use a stratified survey estimator for the population total and variance. This is often done because there are no known design based estimators for systematic surveys that have a single primary sampling unit i.e., the only random event would be for the first station then the rest are systematically placed based on the first sampling unit. I am wondering if a stratified random variance estimator will over state or under state the precision? A useful reference for changes in survey operators for the Alaskan sablefish is Kimura and Zenger Jr (1997). “The Japanese long-line gear used in the joint surveys and the NMFS long-line gear are similar in many respects…Differences between Japanese sampling gear and NMFS sampling gear were mostly due to hook and gangion construction”. When analysing the survey CPUE data it would be ideal to have a single time-series. So a desirable population total estimator would account for different catchabilities by country or vessel. Figure 5.2: A time-series of sablefish catch from the long line survey pooled over 50km by 50km grided cells 5.2 Age-frequency A big challenge of any spatial stock assessment is deriving spatially disaggregated age-frequency observations from low age sample sizes. For both the long-line survey and fishery we have both age and length data sets. This means there are multiple estimators available, including direct ageing, length frequency analysis (Andrade and Kinas 2004) (Length frequency analysis decomposes length frequency histograms into age classes) and age-length key (Ailloud and Hoenig 2019; Hoenig, Choudary Hanumara, and Heisey 2002). The forward age-length key method at face value looks to be the most attractive, as it reduces data sparsity when compared to direct ageing estimators. A note on sablefish otolith sampling from the survey. “Otolith collections were length-stratified from 1979-94 and random thereafter” pg 9 of Sigler, Fujioka, and Lowe (2001). Figure 5.3: Number of aged fish by sex, region and year Length-frequency Figure 5.4: Number of fish measured for length by sex, region and year 5.3 Observer data 5.4 Growth data Figure 5.5: Age-length by sex Figure 5.6: Male age-length by region (left panel) and decade (right panel) Figure 5.7: Female age-length by region (left panel) and decade (right panel) 5.5 Catch data Appendix Sampling notation Symbol Description \\(h\\) haul index \\(i\\) an individual fish index \\(a_i\\) age of individual \\(i\\) \\(l_i\\) length of individual \\(i\\) \\(C^h\\) Catch for haul \\(h\\) can be numbers or biomass \\(n^h_l\\) number of fish measured for length from haul \\(h\\) \\(n^h_a\\) number age samples in haul \\(h\\). Assumed to be a subsample of \\(n^h_l\\) Figure 5.8: CDF of age frequencies for females Figure 5.9: CDF of age frequencies for males Figure 5.10: CDF of length frequencies for females Figure 5.11: CDF of length frequencies for males References "],["tagdata.html", "Chapter 6 Tagging data and studies 6.1 Integrating tagging observations in spatial age-structured models Tagging things to consider with relevant references Releasing tags Tag recovery observations 6.2 Growth estimation using the Laslett–Eveson–Polacheck (LEP) method Simulation test the “LEP” method Next steps", " Chapter 6 Tagging data and studies Since 1972 there have been approximately 400 000 sablefish tagged in Alaska waters, of which over 38 500 have been recovered. Although there is extensive and long term tagging data, this information is not currently directly included in the stock assessment (Goethel et al. 2021). Historical publications investigating movement of Alaskan sablefish include Heifetz and Fujioka (1991), Hanselman et al. (2015) 6.1 Integrating tagging observations in spatial age-structured models This project intends to explore a range of methods for utilising tag-recovery observations in spatially disaggregated age-structured stock assessments. Tagging things to consider with relevant references Years to retain tagged fish in the partition “After approximately 9 yr the number of recaptures was small and contributed more to the variance associated with the trends in movement than an improved understanding of these trends” Beamish and McFarlane (1988) Reporting rates (Heifetz and Maloney 2001) Scan detection rates. Is this not a factor of reporting rates? Mixing time and how to deal with it? Tag loss “tag loss in the fist year was approximately 10% and after that approximately 2% per year.” Beamish and McFarlane (1988) Release conditioning vs recapture conditioning (Vincent, Brenden, and Bence 2020; McGarvey and Feenstra 2002) likelihood choice? (Hanselman et al. 2015) Releasing tags Tag release events involve releasing a tag-cohort at the beginning of a year within a specific area. A tag cohort is indexed by \\(k\\) and has an implied year \\(y\\) and region \\(r\\) index. \\(\\boldsymbol{N}^k\\) is used to denote a vector of lengths or ages for tag-cohort \\(k\\). In general, only the length frequency is known at time of release for each tag-cohort becasue ageing is a fatal process. We consider two different approaches for seeding a tag cohort within spatial age-structured models. The two methods are essentially the same but differ in whether the length are converted to age outside of the model (“External”) or done within the model (“Internal”). The internal method requires users to supply length frequency for each tag-cohort and the model will use the assumed growth assumptions and sex ratios to convert the lengths to ages. The external approach will use an age-length key outside of the model to derive an age frequency that can then be supplied to the model. A frequent assumption of age-structured tagging models in the literature (Maunder 1998; Vincent, Brenden, and Bence 2020) is that the age-frequency of each tag-cohort is known. Due to the fact that ageing is a fatal process, we assume they have used the external approach. If the age-length key is representative, then this method is expected to be very similar and have better computational performance. Factors to consider at time of release are; gear method used to select releases, where releases occur, and time of releases. If growth is estimated within the assessment model, then the internal method may be prefered to keep the growth assumptions consistent between LF observations and other model quantities. One down fall of the internal approach is tag releases and recoveries are both length-based inputs. Due to age-structured modelling growth as length conditional on age. Moving individuals back and forwards through the age-length transition matrix (length \\(\\rightarrow\\) age \\(\\rightarrow\\) length) will cause “smearing” of length frequencies. This is demonstrated in Figures @(ref:addagelength) and @(ref:showagelengthtransition_problem), and needs to be considered when considering model fitted values for observations and corresponding likelihood assumptions. Given this phenomenon, we make the argument that the external age-length key approach should be used. The external method means we assume (there actually is error in this) the ages of released fish and time at liberty, thus we know the age at recovery. Figure 6.1: An example of theoretical length at age, with overlapping length bins used to describe the effect of going back and fourth through the age-length transition matrix. ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. Figure 6.2: A visualisation of the effect of going back and forth through an age-length transition matrix. This can happen when tag releases and recaptures are input as length in an age-structured model. The model converts lengths to ages, then reconverts the age to length for observations. This is assuming the same age-length relationship in Figure 6.1 Internal method Age-structured stock assessment models contain growth models, which describe length conditioned on age. This requires assumptions on the distribution and associated parameters. The default is often the normal distribution with mean length at age denoted by \\(\\bar{l}_a\\) with standard deviation parameterised as a coefficient of variation (\\(\\sigma_a = cv*\\mu_a\\)). This information enables the model to derive a growth transition matrix \\(P_{l|a}\\). Given the lower and upper limits for each length bin denoted as \\(\\boldsymbol{b} = (b_1, b_2, \\dots, b_{max})&#39;\\), the probability of being in length bin \\(l\\) given age \\(a\\) \\[\\begin{equation} P_{l|a} = \\begin{cases} \\Phi(b_{l + 1}|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } l = 1\\\\ \\Phi(b_{l + 1}|\\mu_a,\\sigma_a) - \\Phi(b_l|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } 1 &lt; l &lt; n_l\\\\ 1 - \\Phi(b_{l}|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } l = n_l \\end{cases} \\tag{3.6} \\end{equation}\\] where \\(\\Phi(x|\\mu,\\sigma)\\) is the cumulative normal (but could be generalised to any probability distribution). If growth varies by attributes such as sex, stock or region then this will need to be calculated for each growth model. At the point a tag cohort is released, the model can derive the length composition of the vulnerable population using the transition matrix derived in Equation (eq:agelengthtransition). Given the number of estimable parameters that govern the age-stricture at a point in time and growth model, an exploitation rate is calculated so that if there are not enough numbers in a length bin to be tagged, a penalty can be added to the objective function to dissuade the combination of parameters that generated this situation. Tag-release by length is a known quantity and so the model must allow for a minimum vulnerable length composition to that released. To enforce this, an exploitation rate by length \\((u_l)\\) is calculated as follows, \\[\\begin{equation} u_l = \\frac{N^k_{l}}{\\sum_a}N_{y_k,a,r_k} P_{l|a} \\tag{6.1} \\end{equation}\\] During parameter estimation there are no constraints within the model to trial a set of parameters that will allow \\(u_l &gt; 1\\) i.e., more observed tag-releases than in the available population. To stop negative numbers at age, \\(u_l\\) is set at a level less than 1 and a penalty added to the objective function to discourage parameters from allowing this condition. Finally, tag-release at age is calculated as follows, \\[\\begin{equation} N^k_{a} = N_{y_k,a,r_k} P_{l|a} u_l \\tag{6.2} \\end{equation}\\] Once the tag cohort are created in the model it is assumed that tagged fish are exposed to the same dynamics as un-tagged fish. Revisit this we will want to explore mixing behaviour/assumptions. External method (Age-length key method) Once a tag-release event has occurred for tag group \\(k\\), the only known knowledge is the length distribution \\(N^k_l\\). Assuming there is an accessible forward age-length key which describes the proportion of ages for a given length bin \\(\\left(P_{a|l}\\right)\\) that is representative of the vulnerable population to tagging for the same area and time, then the “forward” or “classic” key method can be used Ailloud and Hoenig (2019). If tag-release coincide with a fishing season you could use fishery-dependent derived age length information, assuming the selectivity curves within a length bin are parallel. If only a subset of fish from each haul are released, it would be better to construct an age-length key from a representative sample of fish that were caught but not-tagged. This would be relevant for single vessel survey release events. \\[\\begin{equation} N^k_a = \\sum\\limits_{l = 1}P_{a|l}N^k_l \\end{equation}\\] where, \\(N^k_a\\) is used as an known input into the model with no error. Revist can we account for uncertainty here? Things to consider for tag release we don’t have much information regarding sex of tagged fish (36.5% of recovered tags have sex information). Does this lean towards the internal method? can allocate sex ratio based on vulnerable population which may be important, if there is quite a difference in sex disaggregated selectivities. Tag recovery observations There are two types of tag-recovery observations that we will consider in this work, tag-release conditioned and tag-recapture conditioned. This conditioning relates to whether we relate recoveries to the release event or whether we only look at the recoveries relative to other recoveries within a year (Vincent, Brenden, and Bence 2020; McGarvey and Feenstra 2002). This conditioning relates more to the log-likelihood formulation rather than the model expected values. We should also explore two different approaches regarding the scanned fish of which tag-recoveries are a subset. The first is recoveries were entirely from a fishery which requires some understanding or assumptions on reporting rates. The other method assumes scanned fish are known, which is the approach used in the Casal2 (Doonan et al. 2016) stock assessment program. This information can be recorded if the scanning is done either by observers who are recording LF’s for the catch or scientific/trained staff when shed sampling landed catch. Both these scanning approaches will require an assuming or information on detection rates. 6.2 Growth estimation using the Laslett–Eveson–Polacheck (LEP) method Another use of tag-recovery data is for estimating growth models which are important inputs for stock assessment models. The section explores the “Laslett–Eveson–Polacheck (LEP)” approach, based on Laslett, Eveson, and Polacheck (2002) &amp; Eveson, Laslett, and Polacheck (2004) and described in Aires-da-Silva et al. (2015). The idea is to use a single growth model that fits to two observational data sets (ideally within the assessment, but for now this analysis is independent of the assessment). The two data sets are are age and length observations and tag-increment observations from tagging experiments. A benefit of this method, other than estimating growth is that estimates of ages of fish at release are a derivative that can then be used as inputs for tag releases in an age-structured stock assessment model (what to do with observations with no sex information?). Age-at-length growth model The Richards growth curve was assumed as was done in Aires-da-Silva et al. (2015) (but this could be extended). The Richards growth formulation follows \\[\\begin{equation} \\bar{l}_{a} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a - a_0)\\}\\right)^{-p} \\tag{6.3} \\end{equation}\\] where, \\(\\bar{l}_{a}\\) is the mean length at age \\(a\\), \\(L_{\\infty}\\) is the asymptotic length, \\(K\\) is the growth coefficient and \\(p\\) is a shape parameter that is related to the ratio \\(\\bar{l}_{a} / L_{\\infty}\\) at the inflexion point. Tag recapture growth data Symbol Description \\(l_{1,i}\\) length of individual \\(i\\) at release \\(l_{2,i}\\) length of individual \\(i\\) at recapture \\(a_{1,i}\\) age of individual \\(i\\) at release. Denoted as \\(A\\) in Aires-da-Silva et al. (2015) \\(a_{2,i}\\) age of individual \\(i\\) at recapture \\(\\Delta_t\\) Time at liberty \\(\\Delta_t = a_{2,i} - a_{1,i}\\) Just one comment on notation!!! in most all the papers that use this method, they ignore the individual notation of \\(A\\). That is not an issue in general however it confuses me when they describe the prior on this. The sub-models for the release and recapture lengths follow, \\[\\begin{equation} l_{1,i} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a_{1,i} - a_0)\\}\\right)^{-p} \\tag{6.4} \\end{equation}\\] and, \\[\\begin{equation} l_{2,i} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a_{1,i} + \\Delta_t - a_0)\\}\\right)^{-p} \\tag{6.5} \\end{equation}\\] The above growth model assumes that we know the age at recovery \\(a_{2,i}\\). The problem we have is, we have 22 569 tag recoveries with length information but only a handful of these have been aged. This is dealt with by modelling \\(a_{1,i}\\) as a random effect i.e., \\(a_{1,i} \\sim LN \\left(\\mu, \\sigma^2\\right)\\). What confuses is me here is how to assign a hyper distribution like the one above for the random effect variables \\(a_{1,i}\\). \\(a_{1,i}\\) is expected to vary quite a bit because tagged fish at release have a broad length frequency and thus is expected to have a broad age at release? (ask someone about this because I may be misunderstanding something). Simulation test the “LEP” method ## going to use parameters from Aires-da-Silva et al. (2015) Table 1 integrated analysis L_inf = 200.8 k = 0.44 t_0 = 1.26 p = -4.27 cv = 0.15 ## cv of length around length at age ## selectivity paraemters sel_a50 = 1.3 sel_ato95 = 0.8 ## sample sizes for simulation n_sample_release = 1000 n_sample_recoveries = 1000 * 0.1 ## about the recovery rate from sablefish data n_sample_age_length = 1000 ## generate a pseudo age structure set.seed(123) R_0 = 200000 M = 0.29 ages = 1:20 n_ages = length(ages) #plot(ages, mean_length_at_age, type = &quot;l&quot;, lwd = 3, xlab = &quot;Age&quot;, ylab = &quot;Length (cm)&quot;) sel_at_age = logis(ages, sel_a50, sel_ato95) ## numbers at age N_age = vector(length = n_ages, &quot;numeric&quot;) for (age_ndx in 1:n_ages) N_age[age_ndx] = R_0 * exp(-ages[age_ndx] * M) * exp(rnorm(1,0,0.7)) N_age = N_age * sel_at_age ## vulnerable numbers at age plot(ages, N_age, ylab = &quot;Numbers&quot;, xlab = &quot;Age&quot;, main = &quot;Population age-structure&quot;, type = &quot;o&quot;) ## plot growth mean_length_at_age = richards_growth(ages, p, k, t_0, L_inf) ## randomly sample 1000 individuals with replacement for otolithing no ageing error!! ## individual_age_length_df = NULL for(i in 1:n_sample_age_length) { age_i = sample(1:n_ages, size = 1, prob = N_age) mean_length_i = richards_growth(age_i, p, k, t_0, L_inf) length_i = rnorm(1, mean_length_i, mean_length_i * cv) temp_df = data.frame(age = age_i, length = length_i) individual_age_length_df = rbind(individual_age_length_df, temp_df) } ## Simulate a tag-recapture experiment # releases release_ages = sample(1:n_ages, size = n_sample_release, prob = N_age, replace = T) release_mean_lengths = richards_growth(release_ages, p, k, t_0, L_inf) release_lengths = rnorm(n_sample_release, release_mean_lengths, release_mean_lengths * cv) individual_release_df = data.frame(release_age = release_ages, release_length = release_lengths, release_mean_length = release_mean_lengths) individual_release_df$fish_id = 1:nrow(individual_release_df) # recaptures sample uniformly without replacement fish_ndx = sample(1:nrow(individual_release_df), size = n_sample_recoveries, replace = F) individual_recovery_df = subset(individual_release_df, subset = individual_release_df$fish_id %in% fish_ndx) ## time-at liberty days randomly recovered on average between 100-600 days individual_recovery_df$time_at_liberty = rpois(n = n_sample_recoveries, lambda = runif(n_sample_recoveries,100,600)) individual_recovery_df$recovery_age = individual_recovery_df$release_age + individual_recovery_df$time_at_liberty/365 ## how to add the length increment between release and recovery? individual_recovery_df$recovery_mean_length = richards_growth(individual_recovery_df$recovery_age, p, k, t_0, L_inf) individual_recovery_df$recovery_mean_length_increment = with(individual_recovery_df, recovery_mean_length - release_mean_length) individual_recovery_df$recovery_length = with(individual_recovery_df, release_length + rlnorm(n_sample_recoveries, log(recovery_mean_length_increment), cv)) individual_recovery_df$growth_change = individual_recovery_df$recovery_length - individual_recovery_df$release_length ## visualise length at age samples ggplot(individual_age_length_df, aes(x = age, y = length)) + geom_point() + geom_line(data= data.frame(length = mean_length_at_age, age = ages), aes(x = age, y = length), col = &quot;red&quot;, linewidth = 1.2, inherit.aes = F) + labs(x = &quot;Age&quot;, y = &quot;Length&quot;) + ylim(0,NA) Assumptions in the above OM follow. \\[ l_{1,i} \\sim \\mathcal{N} \\left(\\bar{l}_{1,a}, \\sigma = \\bar{l}_{1,a} \\times cv\\right) \\] where the mean length at age release (\\(\\bar{l}_{1,a}\\)) follows the Richards growth curve defined in Equation (6.3). The age used to derive the mean length at age was a random sample with replacement from the population in shown in the earlier figure. Time at liberty was drawn from a Poisson distribution with a rate parameter randomly drawn from a uniform distribution between 100-600 days. The age at recovery \\(a_{2,i} = a_{1,i} + \\Delta_t\\). An approximation was made when calculating the length at recovery. The length increment (\\(l_{\\Delta_t}\\)) was simulated using a Log Normal distribution with the median set based on the difference between mean length at release age and mean length at recovery age. This was to ensure all recovered fish positively grew at a rate expected by the growth model (less than ideal but will do for now). \\[ l_{i,\\Delta_t} \\sim \\mathcal{LN} \\left(\\ln (\\bar{l}_{a_{2,i}} - \\bar{l}_{a_{1,i}}), \\sigma = cv\\right) \\] \\[ l_{2,i} = l_{1,i} + l_{i, \\Delta_t} \\] In theory we can now pass this data to our LEP model to back estimate growth parameters. setwd(file.path(&quot;TMB&quot;)) #sink(file = &quot;compile_output.txt&quot;) compile(file = &quot;LEPgrowth_model.cpp&quot;, flags = &quot;-Wignored-attributes -O3&quot;) #sink() dyn.load(dynlib(&quot;LEPgrowth_model&quot;)) #setwd(DIR$book) # data data = list() data$ages_from_age_length = individual_age_length_df$age data$lengths_from_age_length = individual_age_length_df$length data$lengths_at_release = individual_recovery_df$release_length data$lengths_at_recovery = individual_recovery_df$recovery_length data$time_at_liberty = individual_recovery_df$time_at_liberty / 365 data$ages_for_report = ages; data$p_bounds = c(-20, 20) data$t0_bounds = c(-6, 4) # parameters parameters = list() parameters$ln_cv_length_at_age = log(cv) parameters$ln_k = log(k) parameters$ln_L_inf = log(L_inf) parameters$logit_p = logit_general(p, data$p_bounds[1],data$p_bounds[2]) parameters$logit_t0 = logit_general(t_0, data$t0_bounds[1],data$t0_bounds[2]) parameters$ln_cv_length_release = log(0.1) parameters$ln_cv_length_recovery = log(0.1) parameters$ln_age_at_release = log(individual_recovery_df$release_age) parameters$ln_mu_age_release = log(3) parameters$ln_sd_age_release = log(1) obj_mixed_all &lt;- MakeADFun(data, parameters, random = &quot;ln_age_at_release&quot;, DLL=&quot;LEPgrowth_model&quot;) MLE_mixed_all = nlminb(start = obj_mixed_all$par, objective = obj_mixed_all$fn, gradient = obj_mixed_all$gr) MLE_mixed_all$convergence MLE_mixed_all_rep = obj_mixed_all$report(obj_mixed_all$env$last.par.best) MLE_mixed_all_sd_rep = sdreport(obj_mixed_all) plot(ages, MLE_mixed_all_rep$mean_length_at_age, type = &quot;l&quot;, lwd = 3, col = &quot;red&quot;, xlab = &quot;Age&quot;, ylab = &quot;Length (cm)&quot;, ylim = c(0, 240)) lines(ages, mean_length_at_age, col = &quot;blue&quot;, lty = 3, lwd = 3) legend(&#39;bottomright&#39;, legend = c(&quot;LEP obs error&quot;,&quot;True&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = c(1,2), lwd = 3) Next steps Check sensitivity to the model to starting parameters Repeat with different sample sizes Repeat with a truncated age-structure for the age-length data using a selectivity Look at Sablefish data and see if the LEP approach can be used to it Explore alternative growth models i.e., Schnute (1981) References "],["refpoints.html", "Chapter 7 Review/summarise reference points", " Chapter 7 Review/summarise reference points Most of my experience with reference points are spawning biomass related i.e., \\(SSB_y/SSB_0\\). However, many of the reference points outside of New Zealand are \\(F\\) based i.e., \\(F_{35\\%}\\) which I don’t really understand. The purpose of this section is to define them mainly to help me understand, but also as a reference for when I forget in the future. Symbol Description/Calculation \\(SSB^{\\%B_0}_{y}\\) Percent \\(B_0\\) \\(= \\frac{SSB_y}{B_0}\\) \\(SPR\\) Spawner per recruit a measure/proxy of population fecundity \\(F_{35\\%spr}\\) \\(F\\) 35% The Fishing mortality that results in a 35% SPR \\(SPR_{msy}\\) SPR at MSY "],["sexratios.html", "Chapter 8 Sex ratios in age and length composition data 8.1 A simple simulation", " Chapter 8 Sex ratios in age and length composition data An immediate improvement in the current stock assessment (Chapter 3) relates to how sexually disaggregated compositional data are handled. Currently LF’s are separated by sex (needed for the different growths) and age compositional data are aggregated over both sexes. Although LFs are disaggregated by sex and should (in theory) be sufficient to estimate sex specific selectivities. It is not ideal to use LFs to estimate age-based selectivities because older cohorts “smush” into single modes and age information is lost. Before developing a spatially explicit model stock assessment model, I wanted to tidy some loose ends that may come back and bite me in the proverbial butt once we explore the spatially sex disaggregated stock assessment model in anger. These things are exponentially more easier to deal with in “simpler” models. My general intention is to drop length data when we have well sampled age data, currently they both go into the model together. For age composition data I want to structure the observations so that there is potential information on sex ratio. The current assessment can be given information on sex ratio for generating model predicted values which is similar to the approach in Ward et al. (2019). Howver, I personally think this should be dealt within the model. I am aware of two approaches for supplying observations that in theory should provide information on sex ratio. The first (“Approach 1”) was taken from Casal2 (Doonan et al. 2016). This treats sexed composition data for a year as a single proportion i.e., proportions across all ages and sexes sum to one for each year, \\[ \\boldsymbol{P}^k_{y} = \\frac{(C^k_{a,y,1},C^k_{a,y,2})}{\\sum_a \\sum_s C^k_{a,y,s}}, \\quad \\sum \\boldsymbol{P}^k_{y} = 1 \\] where, \\(C^k_{a,y,1}\\) is the catch at age (numbers) for males in year \\(y\\), age \\(a\\) and survey \\(k\\). \\(\\boldsymbol{P}^k_{y}\\) is a proportion vector that sums to one that covers both sexes and corresponding ages. The likelihood contribution for this approach follows \\[ \\boldsymbol{P}^k_{y} \\sim Multinomial(\\mathbb{E}[\\boldsymbol{P}^k_{y}], N^{eff, k}_{y}) \\ . \\] where, \\(N^{eff, k}_{y}\\) is the effective sample size for this survey and year. The second approach (“Approach 2”) is to treat composition for each sex seperately that is proportions at age or length for a sex will sum to one, but also provide a specific sex ratio observation over all ages or lengths as done in the New Zealand rock lobster stock assessment (Webber, Rudd, and Starr 2021). \\[ R^k_{y,s} = \\frac{\\sum_a C^k_{a,y,s}}{\\sum_a \\sum_s C^k_{a,y,s}}, \\quad \\sum_s R^k_{y,s} = 1 \\] and, \\[ P^k_{a, y,s} = \\frac{C^k_{a,y,s}}{\\sum_a C^k_{a,y,s}}, \\quad \\sum_a P^k_{a, y,s} = 1 \\ . \\] The likelihood assumptions for this model are, \\[ R^k_{y,s} \\sim Binomial(\\mathbb{E}[R^k_{y,s}], \\sum_s N^{eff, k}_{y,s}) \\] and, \\[ \\boldsymbol{P}^k_{y,s} \\sim Multinomial(\\mathbb{E}[\\boldsymbol{P}^k_{a, y,s}], N^{eff, k}_{y,s}) \\ . \\] where, \\(N^{eff, k}_{y,s}\\) is the effective sample size. 8.1 A simple simulation To explore the utility of these two approaches we conducted a simple simulation using a sexually disaggregated age-structured model (see Section 8.1). The Operating Model (OM) used in the simulation assumed a 50:50 sex ratio during the recruitment process however the OM did assume different growth and selectivity among the sexes. 8.1.1 Results In summary both approaches resulted in similar estimates in selectivities and SSBs. I prefer Approach 1 as it is a single observation compared with Approach 2 which has two observation types (need to consider how to avoid double counting of samples), but this simulation showed at least within the very small assumptions explored here they resulted in similar performance. This was all I was after in order to move forward to the spatial model. Another consideration about “Approach 2” is if the selectivity shape differs between sexes i.e., lower age at 50% retention. Then due to the sex ratio being derived by summing numbers over all ages, and the natural exponential decay in successive age-cohorts, selectivities that capture more younger fish will result in higher sex ratios. “Approach 1” Future research that was not considered in this simple simulation LF observations with sexual dimorphism in growth. A possible reason LF’s could be influencing assessment output is due to mis-specified growth à la Minte-Vera et al. (2017) Sample size between the two approaches Actual sex ratio skewed in the recruitment process, rather than just a selectivity effect which was of focus in the following simulation Look at the effect on \\(F\\)’s I only summarised SSB and selectivities Look at some residuals to see if that is a way to discredit some of these models ### Operating Model (OM) Parameters set.seed(123) n_sims = 5 bio_params = list( ages = 1:20, L_inf_m = 58, K_m = 0.133, t0_m = 0, L_inf_f = 62, K_f = 0.143, t0_f = 0, M = 0.15, a_m = 2.18e-9, ## tonnes b_m = 3.2, a_f = 2.08e-9, ## tonnes b_f = 3.3, m_a50 = 2.3, m_ato95 = 1.2, sigma = 0.6, h = 0.85, sigma_r = 0.6, R0 = 8234132, plus_group = 1 # 0 = No, 1 = Yes ) other_params = list( s_a50_m = 3.6, s_ato95_m = 2, s_a50_f = 4.6, s_ato95_f = 1.4, s_q = 0.2, s_alpha = 1, f_a50_m = 4.2, f_ato95_m = 1.17, f_a50_f = 4.7, f_ato95_f = 1.76, f_alpha = 1, ssb_prop_Z = 0.5, survey_prop_Z = 0.5, survey_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) fishery_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) survey_bio_cv = c(0.1) ) ages = bio_params$ages max_age = max(bio_params$ages) n_years = 30 years = (2020 - n_years + 1):2020 n_ages = length(ages) ## annual fishing mortality start_F = c(rlnorm(10, log(seq(from = 0.02, to = 0.1, length = 10)), 0.1), rlnorm(10, log(0.1), 0.1), rlnorm(10, log(0.07), 0.1)) recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r)) Figure 8.1: Examples of the two approaches for the survey (top row) and fishery (bottom row). The black and red line in approach 1 will sum to one, where as the black line and red line in approach will each sum to one. Approach 2 has an extra observation which is the proportion male (not shown). 8.1.2 Scenario 1 The first simulation assumed the OM had 50:50 males and female sex ratio at recruitment, and selectivities were as described in the above OM section. We simulated 100 data sets for each of the two approach’s for sexually disaggregated compositional data outlined in the introduction. These were then fitted to in two EM’s, where the EM’s differed in the approach they used. Both EM’s estimated a scalar on the female selectivity that allowed females to be more or less selected compared to males for both the fishery and survey. This was done be introducing an estimable \\(\\alpha\\) parameter into the selectivity. Males selectivities were constrained to have a max value = 1 using, \\[\\begin{equation} S^{male}_a = 1/(1+19^{(a_{50}-a)/a_{to95})}) \\tag{8.1} \\end{equation}\\] where as the female was \\[\\begin{equation} S^{female}_a = \\alpha/(1+19^{(a_{50}-a)/a_{to95})}) \\tag{8.2} \\end{equation}\\] Although this scenario assumed both male and female had the same max selectivity I wanted to see the effect of estimating this additional parameter. A third EM (EM3) was also explored, this structured compositional data using Approach 1 but fixed the female \\(\\alpha\\) = 1 in Equation (8.2). This is often the default approach. For scenario 1 this should be the best performing EM as it has the \\(\\alpha\\) set at the values of the OM. EM 1 (using approach 1) ## max gradient from 100 simualtions = 1.858256e-06 Figure 8.2: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 8.3: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 2 (using approach 2) ## max gradient from 100 simualtions = 5.591513e-11 Figure 8.4: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 8.5: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 3 (using approach 1 with female fixed at \\(\\alpha = 1\\)) ## max gradient from 100 simualtions = 6.455864e-07 Figure 8.6: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 8.7: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs 8.1.3 Scenario 2 The second scenario assumed sex ratio was 50:50 at recruitment and females were more selective than males to the fishery. This was done by setting \\(\\alpha\\) = 1.2 in Equation (8.2). true_pars$logit_f_alpha_f = logit_general(1.2, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2]) EM 1 (using approach 1) ## max gradient from 100 simualtions = 6.54662e-07 Figure 8.8: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 8.9: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 2 (using approach 2) ## max gradient from 100 simualtions = 3.796794e-07 Figure 8.10: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 8.11: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 3 (using approach 1 with female fixed at \\(\\alpha = 1\\)) ## max gradient from 100 simualtions = 2.748698e-07 Figure 8.12: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 8.13: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs References "],["Fexplore.html", "Chapter 9 Fishing mortality approaches Set up a simulation Appendix - Hybrid approach", " Chapter 9 Fishing mortality approaches The current Alaskan sablefish stock assessment (Chapter 3) estimates annual fishing mortality values for each gear \\(g\\) denoted by \\(F^g_{y}\\). This parametersation poses to potential problems when considering future assessment models and spatial models. The first is, the number of parameters will increase as the number of gears increase. The fishery is currently going through a transformation whereby there is a switch from longline to pots. The second consideration is how to set this up in a spatially explicit model where catch have an added spatial dimension. There are two alternative approaches to the current approach which treat \\(F\\) as a derived quantity rather than an estimable parameter. The first is to use Newton Raphson method to solve for \\(F^g_{y}\\). This is the recommended approach in Stock Synthesis (Methot Jr and Wetzel 2013), termed the “hybrid” approach. The previous two methods assume the Baranov catch equation for mortality (Baranov 1918). An alternative is to assume Popes discrete formulation (Pope 1972) which uses exploitation proportions (sometimes called harvest rates or fishing pressure) and has a closed form solution. A good general overview on these methods can be found in Branch (2009). They describe and compared the continuous Baranov catch equation (Baranov 1918) with Pope’s discrete formulation (Pope 1972). Arguments for using the continuous case is that \\(M\\) and \\(F\\) occur simultaneously, also with the continuous case, \\(F\\) allows for multiple event encounters, this is assuming a fleet has the same selectivity and availability, that a fish that escapes one net can be caught in another. In contrast, the discrete formulation only allows a fish to be caught or escape from an instantaneous event. I have tried to summarize the benefits of the continuous equation in the following list, Allows the entire population to be caught (not sure this is that relevant) Allows simultaneous \\(M\\) and \\(F\\), no need to worry about order of operations. From a coding/practical perspective this is quite attractive. Once you have an F and M you can easily derive all mid-mortality quantities. Where as using a \\(U\\) approach you need save the population before and after to interpolate to derive mid-mortality quantities. The magnitude of \\(F\\) effects composition data, where as in the discrete case, composition is independent of the magniture of \\(U\\). Allows for multiple catch events of an individual Can fit to catch observations thus allows for uncertainty in catches. In practice the uncertainty/variance on catch is very small i.e., coeffecient of variations ranging from 0.01 to 0.1. This essentially states catch is observed with high confidence and in my opinion isn’t that much different to saying catch is known exactly. Note often this high precision on observed catch is needed in order to make the \\(F\\)’s identifiable. This high precision also muddies the “degrees of freedom” for the model. Although the \\(F\\)’s look like independent and free parameters they are heavily constrained by the assumptiosn on observed catch variance. The arguments for the discrete approximation is that there is an analytical solution for \\(U\\) and so is fast to calculate expected catch, where as \\(F\\) has to be either solved numerically or estimated as a free parameter (as mentioned earlier). Chris Francis’s wrote a response to this paper (Francis 2010) where he argues the discrete formulation does not preclude the multiple encounters and that only the data can truly tell us which catch equation is the best one to use. Need to make a point about how there may be Automatic differentiation issues with the \\(U\\) approach. Because there is an if(U &gt; 0.99) which can cause a fork in the chain rule which can equal a coding nightmare. The relationship between \\(F\\) (Instantaneous fishing mortality) and \\(U\\) exploitation rate for a simple scenario (single fishery) is illustrated in the following R code. exploitation_rates = seq(0,0.8,by = 0.02) ## calculate F given a U fishing_mortalites = -log(1 - exploitation_rates) ## back calculate U given a F # 1 - exp(-fishing_mortalites) The objective of this simulation Is the method efficient i.e., no loss of speed. Is the method numerically stable (No NaNs during optimization), particularly under high fishing pressure Figure 9.1: Illustration of how mortality is applied to an age cohort continuously over time (y). Set up a simulation To explore the above described methods a simple simulation was conducted using a simple age-structured stock assessment operating model. The model assumed 15 seperate fisheries all with a common selectivity. The purpose was to check that the derived methods were reliable (provided unbiased stock quantities) and that they are computationally efficient. bio_params = list( ages = 1:20, L_inf = 58, K = 0.133, t0 = 0, M = 0.15, a = 2.08e-9, ## tonnes b = 3.5, m_a50 = 6.3, m_ato95 = 1.2, sigma = 0.6, h = 0.85, sigma_r = 0.6, R0 = 8234132, plus_group = 1 # 0 = No, 1 = Yes ) other_params = list( s_a50 = 3.6, s_ato95 = 2, s_q = 0.2, f_a50 = 5, f_ato95 = 2, ssb_prop_Z = 0.5, survey_prop_Z = 0.5, survey_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) fishery_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) survey_bio_cv = c(0.1) ) ages = bio_params$ages max_age = max(bio_params$ages) n_years = 30 years = (2020 - n_years + 1):2020 n_ages = length(ages) ## annual fishing mortality start_F = c(rlnorm(10, log(seq(from = 0.05, to = 0.2, length = 10)), 0.1), rlnorm(10, log(0.13), 0.1), rlnorm(10, log(0.07), 0.1)) recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r)) length_at_age = vonbert(bio_params$ages, bio_params$K, bio_params$L_inf, bio_params$t0) fishery_ogive = logis(bio_params$ages, other_params$f_a50, other_params$f_ato95) survey_ogive = logis(bio_params$ages, other_params$s_a50, other_params$s_ato95) mat_age = logis(bio_params$ages, bio_params$m_a50, bio_params$m_ato95) weight_at_age = bio_params$a * length_at_age^bio_params$b ## observation temporal frequency survey_year_obs = years survey_ages = 1:20 fishery_year_obs = years fishery_ages = 1:20 ## simulate data set.seed(123) sim_data = ASM_obj$simulate(complete = T) ## Build AD TMB functions start_pars = ran_start_vals() est_model_est_F = MakeADFun(sim_data, true_pars, DLL= &quot;SimpleAgestructuredModelMultiFs&quot;, map = na_map, silent = T) sim_data$F_method = 1 sim_data$F_iterations = 4 est_model_hybrid_F = MakeADFun(sim_data, true_pars, DLL= &quot;SimpleAgestructuredModelMultiFs&quot;, map = na_map_hybrid, silent = T) ## optimise opt_model_est_F = nlminb(est_model_est_F$par, est_model_est_F$fn, est_model_est_F$gr, control = list(iter.max = 10000, eval.max = 10000)) opt_model_hybrid_F = nlminb(est_model_hybrid_F$par, est_model_hybrid_F$fn, est_model_hybrid_F$gr, control = list(iter.max = 10000, eval.max = 10000)) ## look at the number of iterations used to solve opt_model_hybrid_F$iterations ## [1] 187 opt_model_est_F$iterations ## [1] 697 ## get reports = rep_est_hybrid = est_model_hybrid_F$report(est_model_hybrid_F$env$last.par.best) rep_est_F = est_model_est_F$report(est_model_est_F$env$last.par.best) plot(TMB_data$years, rep_est_hybrid$ssb[-1], type = &quot;l&quot;, lwd = 3, xlab = &quot;Year&quot;, ylab = &quot;SSB&quot;, ylim = c(0,46000)) lines(TMB_data$years, rep_est_F$ssb[-1], type = &quot;l&quot;, lwd = 3, lty = 2, col = &quot;purple&quot;) lines(TMB_data$years, sim_data$ssb[-1], type = &quot;l&quot;, lwd = 4, lty = 3, col = &quot;red&quot;) legend(&quot;topright&quot;, col = c(&quot;black&quot;, &quot;purple&quot;, &quot;red&quot;), legend = c(&quot;Hybrid&quot;, &quot;Est F&quot;, &quot;OM&quot;), lwd = 3) est_F_bench = benchmark(obj = est_model_est_F, n = 1000) hybrid_F_bench = benchmark(obj = est_model_hybrid_F, n = 1000) est_F_bench ## elapsed ## template.likelihood 0.769 ## template.gradient 1.502 hybrid_F_bench ## elapsed ## template.likelihood 2.025 ## template.gradient 4.258 ben_est_F &lt;- benchmark(obj = est_model_est_F, n=20,expr=expression(do.call(&quot;optim&quot;,obj))) ben_hybrid_F &lt;- benchmark(obj = est_model_hybrid_F, n=20,expr=expression(do.call(&quot;optim&quot;,obj))) ben_est_F ## elapsed ## do.call(&quot;optim&quot;, obj) 13.68 ben_hybrid_F ## elapsed ## do.call(&quot;optim&quot;, obj) 11.703 These results have highlighted the following Both the Free \\(F\\) and hybrid estimate very similar model quantities i.e., SSB’s and F’s The Free \\(F\\) method is much faster on average for a single gradient calculation and function call compared to the hybrid method However, the hybrid method requires less iterations due to there being less estimated parameters. For this simulation where we assumed 15 fisheries both optimised in similar amounts of time Appendix - Hybrid approach The hybrid fishing mortality process uses the methods and algorithms applied in Stock Synthesis (Methot Jr and Wetzel 2013). The descriptions below are heavily based on the text describing this approach in the Appendix of (Methot Jr and Wetzel 2013). This process begins by calculating popes discrete approximation, and then converts this to Baranov fishing mortality coefficients. A tuning algorithm is then done to tune these coefficients to match input catch nearly exactly, rather than the full Baranov approach. Total mortality, denoted by \\(Z_{a,y,s,r}\\) for sex \\(s\\), region \\(r\\), age \\(a\\) and year \\(y\\) will hereby be denoted by \\(Z_{a,y,s}\\) i.e., drop the region index. This is because mortality rates are calculated independently (in isolation) among regions (NOTE consider parallelising this in the model). \\[\\begin{equation*} Z_{a,y,s} = M_{a,y,s} + \\sum\\limits_{f} S^g_{y,s} F^g_y \\end{equation*}\\] where, \\(M_{a,s}\\) is the natural mortality rate, \\(F^g_y\\) is fishing mortality and \\(S^g_{a,s}\\) is the selectivity. The hybrid fishing mortality method allows the \\(F\\) values to be “tuned” to match input catch nearly exactly, rather than estimating them as free model parameters. The process begins by calculating mid year exploitation rate using Pope’s approximation. This exploitation rate is then converted to an approximation of the Baranov continuous \\(F\\). The \\(F\\) values for all fisheries operating in that year and region are then tuned over a set number of iterations (f_iterations) to match the observed catch for each fishery with its corresponding \\(F\\). Differentiability is achieved by the use of Pope’s approximation to obtain the starting value for each \\(F\\) and then the use of a fixed number of tuning iterations, typically 4. Tests from Stock Synthesis have shown that modelling \\(F\\) as hybrid versus \\(F\\) as a parameter has trivial impact on the estimates of the variances of other model derived quantities. The hybrid method calculates the harvest rate using the Pope’s approximation then converts to an approximation of the corresponding F as: \\[\\begin{align} V^g_{y} &amp;= \\sum\\limits_s\\sum\\limits_a N_{a,y,s} \\exp\\left(-\\delta_t M_{a,s}\\right) \\nonumber \\\\ \\tilde{U}^g_{y} &amp;= \\frac{C^g_{y}}{V^g_{y} + 0.1 C^g_{y}}\\\\ j^g_{y} &amp;= \\left(1 + \\exp \\left(30 (\\tilde{U}^g_{y} - 0.95) \\right)\\right)^{-1}\\\\ U^g_{y} &amp;= j^g_{y} \\tilde{U}^g_{y} + 0.95 (1 - j^g_{y} )\\\\ \\tilde{F}^g_{y} &amp;= \\frac{-\\log\\left(1 - U^g_{y}\\right)}{\\delta_t} \\end{align}\\] where, \\(C^{g}_y\\) is the observed catch, \\(\\delta_t\\) is the duration of the period of observation within the year. In most situations where the entire catch has been observed in a time-step. This should be one. \\(V^g_{y}\\) is partway vulnerable biomass and \\(\\tilde{F}^g_{y}\\) is the initial \\(F\\). The formulation above is designed so that high exploitation rates (above 0.95) are converted into an F that corresponds to a harvest rate of close to 0.95, thus providing a more robust starting point for subsequent iterative adjustment of this F. The logistic joiner, \\(j\\), is used at other places in Stock Synthesis to link across discontinuities. The tuning algorithm begins by setting \\(F^g_{y} = \\tilde{F}^g_{y}\\) and repeating the following algorithm f_iteration times. \\[ \\widehat{C}_{a,y,s} = \\sum\\limits_g {F}^g_{y}S^g_{a,s} N_{a,y,s}\\bar{w}_{a,y,s} \\lambda^*_{a,y,s} \\] where, \\(\\lambda^*_{a,y,s}\\) denotes the survivorship and is calculated as: \\[\\begin{equation} \\lambda^*_{a,y,s} = \\frac{1 - \\exp\\left(-\\delta_t Z_{a,y,s} \\right) }{Z_{a,y,s}} \\tag{9.1} \\end{equation}\\] Total fishing mortality is then adjusted over several fixed number of iterations (typically four, but more in high F and multiple fishery situations). The first step is to calculate the ratio of the total observed catch over all fleets to the predicted total catch according to the current F estimates. This ratio provides an overall adjustment factor to bring the total mortality closer to what it will be after adjusting the individual \\(F\\) values. \\[ \\widehat{C}_{y} = \\sum\\limits_g \\sum\\limits_s\\sum\\limits_a {F}^g_{y}\\left(S^g_{a,s} N_{a,y,s}\\right) \\lambda^*_{a,y,s} \\] This is different from Equation A.1.25 in the Appendix of (Methot Jr and Wetzel 2013). They include \\(Z_{a,y,s}\\) in the denominator when describing \\({F}^g_{y}\\), I think this is a typo error because \\(Z_{a,y,s}\\) is already included in the denominator when calculating \\(\\lambda^*_{a,y,s}\\) (see Equation (9.1)). \\[ Z^{adj}_y = \\frac{\\sum\\limits_g C^g_{y}}{\\widehat{C}_{y}} \\] The total mortality if this adjuster was applied to all the Fs is then calculated: \\[ Z^*_{a,y,s} = M_{a,s} + Z^{adj}_y \\left(Z_{a,y,s} -M_{a,s} \\right) \\] \\[ \\lambda^*_{a,y,s} = \\frac{1 - \\exp\\left(-\\delta_t Z^*_{a,y,s} \\right) }{Z^*_{a,y,s}} \\] The adjusted mortality rate is used to calculate the total removals for each fishery, and then the new \\(F\\) estimate is calculated by the ratio of observed catch to total removals, with a constraint to prevent unreasonably high \\(F\\) calculations (max_f): \\[\\begin{align*} \\tilde{V}^g_{y} &amp;= \\sum\\limits_s\\sum\\limits_a \\left(N_{a,y,s} \\bar{w}_{a,y,s}S^g_{a,s} \\right)\\lambda^*_{a,y,s} \\\\ F^{g*}_{y} &amp;= \\frac{C^g_{y}}{\\tilde{V}^g_{y} + 0.0001}\\\\ j^{g*}_{y} &amp;= \\left(1 + \\exp \\left(30 (F^{g*}_{y} - 0.95 F_{max}) \\right)\\right)^{-1}\\\\ \\end{align*}\\] where, \\(F_{max}\\) is a user defined maximum fishing mortality f_max. The \\(F\\) at the end of each tuning iteration follows: \\[ F^g_{y} = j^{g*}_{y} F^{g*}_{y} + \\left(1 - j^{g*}_{y}\\right)F_{max} \\] After the tuning algorithm removals at age, and other derived quantities are recorded. The final total mortality is updated \\[ Z_{a,y,s} = M_{a,s} + \\sum\\limits_{g} S^g_{a,s} F^g_{y} \\] This process generates catch at age and sex for each year (and region) (\\(\\widehat{C}^g_{a,y,s}\\)) which can be accessed by process_removals observations. Numbers at age are calculated as \\[ \\widehat{C}^g_{a,y,s} = \\frac{F^g_{a,s,y}}{Z_{a,y,s}} N_{a,y,s} \\exp\\left(-Z_{a,y,s}\\right) \\] Total catch is the summed over all sexes and age \\[ \\widehat{C}^g_{y} = \\sum\\limits_s\\sum\\limits_a \\widehat{C}^g_{a,y,s} \\bar{w}_{a,y,s} \\] where \\(\\bar{w}_{a,y,s}\\) is the mean weight References "],["spatialInit.html", "Chapter 10 Initialising the plus group in spatial models", " Chapter 10 Initialising the plus group in spatial models In single area age-structured models, the plus age group is calculated using a solution to an infinite geometric series. This solution for an age-structured model is used to derive initial (equilibrium) state of the partition. The partition consists of a vector of numbers at age for each category denoted by \\(\\textbf{N}\\); \\[ \\textbf{N} = (N_1, N_2, ... , N_{a_+})^T \\] where \\(N_{a_+}\\) denotes the numbers in the plus group. The numbers at age for a single area population with no density-dependent processes is derived as, \\[ N_a = \\left\\{ \\begin{array}{lcl} R_0 &amp; \\mbox{for} &amp; a = 1 \\\\ R_0e^{-aM} &amp; \\mbox{for} &amp; 1 &lt; a &lt; a_+ \\\\ R_0e^{\\sum_{i = a_+}^\\infty-iM} &amp; \\mbox{for} &amp; a = a_+ \\end{array}\\right. \\] Initialization for ages \\(1 \\leq a &lt; a_+\\) is easy, all you need to do is iterate the model \\(a_+ - 1\\) times and the age classes will be populated with there respected initial numbers at age. However, for the plus group (\\(N_{a_+}\\)) the solution is needed. Although the plus group may start at let say 30 years old, it actually represents 30 and 31 and 32 up to some biological plausible value lets say 130, but mathematically can be thought of as \\(\\infty\\). The plus group is modeled for practical reasons and care should be given when choosing the cut-off maximum age. The plus group is an infinite geometric series that is defined by the common ratio \\(r_{a_+} = M\\). \\[\\begin{align} N_{a_+} &amp;= R_0e^{\\sum_{a = a_+}^\\infty-aM}\\\\ &amp;= R_0 \\frac{e^{M - a_+M}}{1 - e^{-M}} \\end{align}\\] M = 0.1 R0 = 4e6 plus_group_age = 30 N_age = R0 * exp(-M * 1:plus_group_age) ## numerically calculate it N_plus_group = tail(N_age, n = 1) for(i in 1:10000) { N_plus_group = N_plus_group * exp(-M) + tail(N_age, n = 1) * exp(-M) } N_plus_group ## [1] 1893568 ## using the geometric series calculation R0 * exp(-M - plus_group_age*M) / (1 - exp(-M)) ## [1] 1893568 The question becomes, how do we calculate this plus group when there is markovian movement? This code shows how the same infinite geometric series solution works for the plus group with movement. Instead of the common ratio being just it also need to account for the movement process. Let \\(c^r_{a+}\\) denote the accumulation of individuals into the plus group in region \\(r\\). This will be the result of ageing, natural mortality and movement. Then the plus group for that region can be \\[ N_{a+, r} = N_{a+ - 1, r} \\frac{1}{1 - c^r_{a+}} \\] where, \\(N_{a+ - 1, r}\\) is the numbers at age for the second to last age cohort in the plus group. The following R code shows how this is equivalent to running the annual cycle for 1000 years. M = 0.1 R0 = 4e6 n_regions = 3 movement_matrix = matrix(0, nrow = n_regions, ncol = n_regions); movement_matrix[1,] = c(0.7, 0.2, 0.1) movement_matrix[2,] = c(0.1, 0.6, 0.3) movement_matrix[3,] = c(0.15, 0.05, 0.8) ## rows are &quot;from&quot; cols are &quot;to&quot; plus_group_age = 30 ## partition N_age = matrix(0, nrow = n_regions, ncol = plus_group_age) ## initialise with no movement initially N_age[1,] = R0 * exp(-M * 1:plus_group_age) ## N_age[2,] = R0 * exp(-M * 1:plus_group_age) ## N_age[3,] = R0 * exp(-M * 1:plus_group_age) ## ## apply an annual cycle 10000 times to see what the &quot;initial conditions should be&quot; N_next_year_age = N_age for(i in 1:1000) { ## recruitment N_next_year_age[,1] = R0 * exp(-M) ## ageing and mortality N_next_year_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) ## plus group N_next_year_age[,plus_group_age] = N_next_year_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) ## movement N_age = t(movement_matrix) %*% N_next_year_age } iterative_N_age = N_age plot(1:plus_group_age, N_age[3,], xlab = &quot;Age&quot;, ylab= &quot;Initial numbers&quot;, ylim = c(0,R0* 1.4), type = &quot;l&quot;, lwd = 3) lines(1:plus_group_age, N_age[2,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, N_age[1,], lwd = 3, col = &quot;blue&quot;, lty = 2) legend(&#39;topright&#39;, col = c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;), legend = c(&quot;Region 3&quot;, &quot;Region 2&quot;, &quot;Region 1&quot;), lwd = 3) N_age = matrix(0, nrow = n_regions, ncol = plus_group_age) update_N_age = N_age for(i in 1:(plus_group_age)) { # recruitment update_N_age[,1] = R0 * exp(-M) # ageing and mortality update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) # plus group update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) # movement N_age = t(movement_matrix) %*% update_N_age } ## calculate one more annual cycle # recruitment update_N_age[,1] = R0 * exp(-M) # ageing and mortality update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) # plus group update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) # movement update_N_age = t(movement_matrix) %*% update_N_age ## approximate! c = update_N_age[,plus_group_age] / N_age[,plus_group_age] - 1 update_N_age[,plus_group_age] = N_age[,plus_group_age] * 1 / (1 - c) iterative_N_age[,plus_group_age] ## [1] 1758313 1217294 2705097 update_N_age[,plus_group_age] ## [1] 1758313 1217294 2705097 plot(1:plus_group_age, iterative_N_age[3,], xlab = &quot;Age&quot;, ylab= &quot;Initial numbers&quot;, ylim = c(0,R0* 1.4), type = &quot;l&quot;, lwd = 3) lines(1:plus_group_age, update_N_age[3,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, iterative_N_age[2,], lwd = 3, col = &quot;black&quot;, lty = 1) lines(1:plus_group_age, update_N_age[2,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, iterative_N_age[1,], lwd = 3, col = &quot;black&quot;, lty = 1) lines(1:plus_group_age, update_N_age[1,], lwd = 3, col = &quot;red&quot;, lty = 2) legend(&#39;topright&#39;, col = c(&quot;black&quot;,&quot;red&quot;), legend = c(&quot;Numerical&quot;, &quot;Analytical&quot;), lwd = 3, lty = c(1,2)) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

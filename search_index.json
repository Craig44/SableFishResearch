[["index.html", "Alaskan sablefish research Chapter 1 Overview Future things to consider chapter overview", " Alaskan sablefish research C.Marsh 2022-11-29 Chapter 1 Overview This Gitbook documents my/our research for the Alaska sablefish (Anoplopoma fimbria). The objective is to develop and explore a spatially explicit stock assessment for Alaskan sablefish. However, there will be many other topics that I will likely only scratch the surface on. The following outlines the chapters in this document Future things to consider How to reduce partition dimension when adding tag-release events When is the latest you can start the model? Currently the assessment model starts in 1960 because there is early survey and catch info along with some of the largest catches observed over the fishery. I want to explore starting the model at later period i.e., 1990’s when start getting consistent survey data. This is a possible way to reduce the number of estimated parameters that have low information, however you may loose some information on production if you miss some of the periods with the largest catches. chapter overview Chapter 2 is a list of objectives that we have set or accomplished during this research project. Some of our research cannot be in this book/repo due to the confidential nature of the data. This checklist should include tasks for the wider research Chapter 3 documents the current stock assessment model and assumptions (work in progress). This first is the first step of the project and helps me get a grasp of data and dynamics that are important Chapter 4 documents the spatial stock assessment model used to explore spatially explicit models. Chapter 5 explores how to include sex disaggregated composition observations that can include sex ratio information. It conducts a simple simulation to investigate two different approaches than what is currently done in the assessment Chapter 6 explores how to parameterise fishing mortality. The current approach is to estimate an annual fishing mortality parameter for each gear. I feel slightly uncomfortable about this approach moving towards a spatial model as the number of estimated parameters will explode. This chapter looks at two alternative approaches that either derive fishing mortality estimates using a Newton Raphson solver which is borrowed from the Stock Synthesis “hybrid” approach (Methot Jr and Wetzel 2013) and Pope’s discrete approach (Pope 1972) which uses exploitation rates. All of these methods have been applied in the literature for decades. The aim of this chapter is to do a simulation and make sure the considered approaches are efficient and numerically stability under a range of fishing patterns Chapter 7 explores how to calculate the plus group in spatially explicit age-structured models that assume markovian movement. Chapter 9 describes the tagging data and how it can be used within a spatial model but also used in a panmictic model for informing population dynamics such as growth. library(TMB) #library(stockassessmenthelper) library(ggplot2) library(dplyr) library(reshape2) library(gridExtra) library(knitr) library(RColorBrewer) References "],["objectives.html", "Chapter 2 A list of objectives/milestones that we have set along the project life", " Chapter 2 A list of objectives/milestones that we have set along the project life Translate current stock assessment (Chapter 3) from ADMB to TMB. Planned date of completion is December 1 2022 Conduct self test using TMB model. Planned date of completion is December 1 2022 Consider improvements i.e., sex disaggregated composition data or sex ratio observations (look at the rock lobster assessment) including age-length observations or tag-increment observations to estimate growth internally. Characterize both fishery and survey data to get an idea of data limitations when considering spatially explicit stock assessment model. Develop a spatially explicit estimation model in TMB that generalizes the current assessment model. This requires a lot of thought, especially how we want to integrate the tagging data (Chapter 9) "],["modeldescription.html", "Chapter 3 Current Alaskan sablefish stock assessment model 3.1 Process equations 3.2 Observation equations 3.3 Symbol Notation", " Chapter 3 Current Alaskan sablefish stock assessment model The latest published stock assessment (Goethel et al. 2021) is a single area model (Chapter 3). This chapter intends to extend this model by allowing it to be spatially disaggregated. disaggregated integrated age-structured model. Let \\(\\boldsymbol{N_{y,s}}\\) denote a vector of ages in year \\(y\\) for sex \\(s\\) (the partition) i.e., \\(\\boldsymbol{N_{y,s}} = (N_{1,y,s}, N_{2,y,s}, \\dots, N_{a_+,y,s})^T\\). The general process model is sequential and follows the general Equation (3.1), \\[\\begin{equation} \\boldsymbol{N_{y,s}} = \\begin{cases} g\\left(\\boldsymbol{\\theta}\\right), &amp; y = 1959 \\text{ Initial model year}\\\\ f\\left(\\boldsymbol{N_{y-1,s}}|\\boldsymbol{\\theta}\\right), &amp; y &gt; 1959 \\\\ \\end{cases} \\tag{3.1} \\end{equation}\\] where, \\(g(.)\\) is the function describing initial conditions for the partition and \\(f(.)\\) is the function that applies populations dyanmics each year i.e., birth, death, growth and migration. See Section 3.3 &amp; 3.1 for a detailed description of \\(g(.)\\) and \\(f(.)\\) and \\(\\boldsymbol{\\theta}\\) is the set of estimable (not all are estimated) parameters. Maximum Likelihood Estimates (MLE) for estimated parameters \\(\\widehat{\\boldsymbol{\\theta}}_{MLE}\\) are evaluated, \\[\\begin{equation} \\widehat{\\boldsymbol{\\theta}}_{MLE} = \\underset{\\boldsymbol{\\theta}}{\\arg\\max} \\left( L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) \\right) \\tag{3.2} \\end{equation}\\] where, \\(\\boldsymbol{y^{obs}}\\) is a set of observations and \\(L\\left( . \\right)\\) is an objective function that is made up of priors/penalties and log-likelihood. See Section 3.2 3.1 Process equations Initialisation (\\(g\\left(.\\right)\\)) \\[\\begin{align*} N_{a,1,s} = \\begin{cases} R_1, &amp; a = a_1\\\\ \\exp\\bigg( \\mu_r + \\tau_{a_1 - a + 1}\\bigg) \\exp-\\bigg( a - a_1\\bigg) \\bigg( M + F_{hist} * \\mu_{LL} * S^{LL}_{a,1}\\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp( \\mu_r) \\exp-( a - 1) ( M + F_{hist} * \\mu_{LL} * S^{LL}_{a - 1,1})(1 - \\exp( M + F_{hist} * \\mu_{LL} * S^{LL}_{a - 1,1}))^{-1}, &amp; a = a_+ \\end{cases} \\end{align*}\\] Population dynamics (\\(f\\left(.\\right)\\)) The assessment assumes a closed population that is only effected by mortality (natural and fishing), recruitment and growth. Mortality is applied assuming \\[ Z_{a,y,s} = M + \\sum_g F^g_{y} S^g_{a,y,s} \\] where, \\(S^g_{a,y,s}\\) is the fishery selectivity and \\(F^g_{y}\\) is the annual estimated fishing mortality. The annual cycle follows, \\[\\begin{align*} N_{a,y,s} = \\begin{cases} p^s_{y} R_y, &amp; a = a_1\\\\ N_{a - 1,y - 1,s} \\times \\exp\\bigg( -Z_{a - 1,y - 1,s} \\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp\\bigg( -Z_{a - 1,y - 1,s} \\bigg) + \\exp\\bigg( -Z_{a,y - 1,s} \\bigg), &amp; a = a_+ \\end{cases} \\end{align*}\\] where, \\[ R_y = \\exp\\{\\mu_r + \\tau_y + 0.5\\sigma_R^2\\} \\] Determining selectivities for fisheries and surveys The ADMB model has a hard coded number of selectivities. Some of them relate to changes in the fishery and so represent time-varying blocks. We want to spell these out and simplify for the TMB model. There are nine selectivities labelled fish1, fish2, fish3, fish4, fish5, srv1, srv2 and srv10. label Selectivity description fish1 Longline selectivity from 1960-1994 fish2 Not sure if this is used, maybe this is used for srv6? fish3 Trawl selectivity from 1960 - \\(T\\) fish4 Longline selectivity from 1995 -\\(\\ IFQ_y\\) (\\(IFQ_y\\) can = \\(T\\) fish5 Longline selectivity from \\(IFQ_y \\ - \\ T\\) if there is post IFQ block srv1 Domestic Longline survey selectivity srv2 Japanese Longline survey selectivity 3.2 Observation equations Three are three observational types in the current Sablefish stock assessment - Relative abundance indices - Age composition (aggregated over sex) - Length composition (disaggregated by sex) These three observation types come from both fishery dependent i.e., observer programs and CPUE and fishery independent i.e., research surveys. Catch at age Fishery dependent catch at age observations for gear type \\(g\\) denoted by \\(\\boldsymbol{C^g}_{a,y,s}\\) are calculated as follows \\[\\begin{equation} \\boldsymbol{C^g}_{a,y,s} = \\frac{F^g_{a,y,s}}{Z_{a,y,s}} N_{a,y,s} \\left(1 - S_{a,y,s} \\right) \\tag{3.3} \\end{equation}\\] Currently all age observations are sex aggregated which means the model expected values before applying ageing error is \\[ \\boldsymbol{C^g}_{a,y} = 0.5 \\sum_s \\frac{\\boldsymbol{C^g}_{a,y,s}}{\\sum_a\\boldsymbol{C^g}_{a,y,s}} \\] why the 0.5? should be omitted going forward. Ageing error is then incorporated and the values are normalized so that they are proportions, before being passed to the multinomial log-likelihood function. Survey age composition is similar but instead of being a function of \\(F\\) it is calculated at the beginning of the year. For survey \\(k\\) the numbers at age are denoted by \\(\\boldsymbol{C^k}_{a,y}\\) and calculated following \\[\\begin{equation} \\boldsymbol{C^k}_{a,y} = p^s N_{a,y,s} S^k_{y,a,s} \\tag{3.4} \\end{equation}\\] I am not sure exactly what the timing of these surveys are, but do we need to account for som mid-year mortality? or changes in timing of the survey? if so we could easily replace \\[ N_{a,y,s} \\] with \\[ N_{a,y,s} \\exp\\{-p^k_y Z_{a,y,s}\\} \\] where,\\(p^k_y\\) is the proportion of mortality that we want to account for in year \\(y\\) for survey \\(k\\). The survey numbers at age are then adjusted for ageing error and normalised so they sum to one for each year. Relative abundance indices \\[\\begin{equation} \\widehat{I}^g_{y} = \\sum_s\\sum_a p^s N_{a,y,s} \\exp \\{-0.5 Z_{a,y,s}\\} S^g_{y,a,s} \\bar{w}_{a,y,s} \\tag{3.5} \\end{equation}\\] where, \\(\\bar{w}_{a,y,s}\\) is mean weight at age, this can be omitted if the observation is in numbers i.e., abundance instead of biomass and \\(p^s\\) is the proportion for each sex. This is currently a user input, but should be dealt within the model either as having different sex selectivities or through the sex ratio of recruitment. A list of slight improvements change how sex ratio is handled fishery dependent abundance indices i.e., CPUE change \\(N_{a,y,s} \\exp \\{-0.5 Z_{a,y,s}\\}\\) with \\(\\boldsymbol{C^g}_{a,y,s}\\) which is calculated in the catch at age observations. Catch at length For each year that has a length frequency observation, numbers at length denoted by \\(\\boldsymbol{C^l}_{y,s} = (C^l_{1,y,s}, \\dots, C^l_{n_l,y,s})^T\\) (dimension of \\(\\boldsymbol{C^l}_{y,s}\\) is \\(n_l \\ \\times \\ 1\\)) were calculated for each sex. This involved multiplying the catch at age (see above for how it is calculated) through an age-length transition matrix denoted by \\(\\boldsymbol{A}^l_{y,s}\\) (dimensions of \\(\\boldsymbol{A}^l_{y,s}\\) are \\(n_a \\ \\times \\ n_l\\) and its rows must sum to 1). The calculation follows Equation (3.6), \\[\\begin{equation} \\boldsymbol{C^l}_{y,s} = \\left(\\boldsymbol{A}^l_{y,s} \\right)^T \\ \\times \\ \\boldsymbol{C_{y,s}} \\tag{3.6} \\end{equation}\\] where, \\(\\boldsymbol{C_{y,s}}\\) is a column vector of numbers at age (dimension \\(n_a \\ \\times \\ 1\\)) at the beginning of year \\(y\\) for sex \\(s\\). Observations for fisheries and surveys label Relative Abundance description srv1 Biomass domestic longline survey uses both srv1_sel and srv10_sel srv3 Abundance domestic longline survey uses both srv1_sel and srv10_sel srv2 Biomass survey uses both srv2_sel and srv9_sel srv4 Abundance survey uses both srv2_sel and srv9_sel srv5 Longline fishery CPUE fish1_sel, fish4_sel, fish5_sel srv6 Japanese LL fishery CPUE srv7 NMFS bottom trawl survey (currently GOA only; fit in model) label Composition description ac_fish1 Longline Fishery Age Comp (sex aggregated) sc_fish1 Longline Fishery LF (sex dis-aggregrated) sc_fish3 Trawl Fishery LF (sex disaggregrated) sc_fish2 LF for japaneses Longline fishery (sex aggregrated) (basically a survey now) sc_fish4 LF for japaneses Longline fishery (sex aggregrated) (basically a survey now) fish_size LF From japaneses trawl survey? (sex aggregrated) ac_srv1 Domestic Longline Survey AF (sex aggregated) sc_srv1 Domestic Longline Survey LF (sex disaggregrated) ac_srv2 Japanese Longline Survey AF (sex aggregated) sc_srv2 Japanese Longline Survey LF (sex disaggregrated) ac_srv7 NMFS bottom trawl survey AF (sex aggregated) sc_srv7 NMFS bottom trawl survey LF (sex disaggregrated) 3.3 Symbol Notation Symbol Description \\(y\\) Year, \\(y = 1960, \\dots, T\\) \\(T\\) Terminal year of the model \\(s\\) Sex index \\(s \\in \\{1,2\\}\\) \\(r\\) Region index \\(r \\in \\{1, \\dots, n_r\\}\\) \\(n_r\\) number of modeled regions \\(a\\) Model age cohort, i.e., \\(a = a_0, a_0 + 1, \\dots\\) \\(a_{1}\\) Recruitment age to the model = 2 \\(a_+\\) Plus-group age class (oldest age considered plus all older ages) \\(n_a\\) Number of age classes modeled \\(a_+ \\ - a_1\\) \\(l\\) length class \\(n_l\\) Number of length classes \\(g\\) gear type index, i.e. longline survey, longline fishery, trawl fishery \\(x\\) log-likelihoos index \\(\\bar{w}_{a,y, s}\\) Average weight at age \\(a\\), year \\(y\\) and sex \\(s\\) \\(\\phi_{a,y}\\) Proportion of female mature by age and year \\(p^s_{y}\\) Proportion of recruits for sex \\(s\\). Often assumed = 0.5 \\(\\ln \\mu_{r}\\) Average log-recruitment \\(\\ln \\mu_{f}\\) Average log-fishing mortality \\(\\phi_{y,g}\\) annual fishing mortality deviation by gear (log space) \\(\\tau_{y}\\) annual recruitment deviation \\(\\sim LogNormal\\left(0,\\sigma_r\\right)\\) \\(\\sigma_r\\) Recruitment standard deviation \\(N_{a,y,s}\\) Numbers of fish at age \\(a\\) in year \\(y\\) of sex \\(s\\) \\(M\\) Natural mortality \\(F^g_{a,y}\\) Fishing mortality for year \\(y\\), age \\(a\\) and gear \\(g\\) \\(F_{hist}\\) Historical proportion of Fishing mortality \\(Z_{a,y}\\) Total mortality for year \\(y\\), age \\(a\\) \\(=\\sum\\limits_g F^g_{a,y} + M\\) \\(R_{y}\\) Annual recruitment \\(B_{y}\\) Spawning biomass in year \\(y\\) \\(S^g_{a,y,s}\\) Selectivity at age \\(a\\) for gear type \\(g\\) and sex \\(s\\) \\(a_50\\) age at 50% selection for ascending limb \\(d_50\\) age at 50% selection for descending limb \\(\\delta\\) slope/shape parameters for different logistic curves \\(\\boldsymbol{A}\\) ageing-error matrix dimensions \\(n_a \\ \\times \\ n_a\\) \\(\\boldsymbol{A}^l_s\\) age to length conversion matrix by sex. dimensions \\(n_a \\ \\times \\ n_l\\) \\(q_g\\) abundance index catchability coeffecient by gear \\(\\lambda_x\\) Statistical weight (penalty) for component \\(x\\) \\(P^g_{l,y,s}\\) Observed proportions at length for gear \\(g\\) in year \\(y\\) and sex \\(s\\) \\(P^g_{a,y,s}\\) Observed proportions at age for gear \\(g\\) in year \\(y\\) and sex \\(s\\) \\(\\psi^g_{y}\\) assumed sample size for gear \\(g\\) in year \\(y\\) (for multinomial likelihood \\(n_g\\) Number of years that age (or length) composition is available for gear \\(g\\) Inference If random effects are considered the joint probability model follows, \\[\\begin{equation} Pr\\left[ \\boldsymbol{y^{obs}}, \\boldsymbol{u}| \\boldsymbol{\\theta} \\right] = Pr\\left[\\boldsymbol{y^{obs}} |\\boldsymbol{\\theta^f}, \\boldsymbol{u} \\right] Pr\\left[\\boldsymbol{u} |\\boldsymbol{\\theta^h} \\right] \\end{equation}\\] Inference is conducted by maximising the marginal likelihood noting \\(L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}} \\right) \\propto Pr\\left[ \\boldsymbol{y^{obs}} | \\boldsymbol{\\theta} \\right]\\) \\[\\begin{equation}\\label{eq:marginal_ll} L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) = \\int \\left(Pr\\left[\\boldsymbol{y^{obs}} |\\boldsymbol{\\theta^f}, \\boldsymbol{\\theta^g}, \\boldsymbol{u} \\right] Pr\\left[\\boldsymbol{u} |\\boldsymbol{\\theta^h} \\right] \\right) \\boldsymbol{du} \\end{equation}\\] In general this integral is not tractable, and so approximations are necessary. The software used here implement the Laplace approximation, which relies on Gaussian assumptions. Maximum Likelihood Estimates (MLE) for fixed effect parameters \\(\\widehat{\\boldsymbol{\\theta}}_{MLE}\\) are evaluated, \\[\\begin{equation} \\widehat{\\boldsymbol{\\theta}}_{MLE} = \\underset{\\boldsymbol{\\theta}}{\\arg\\max} \\left( L\\left(\\boldsymbol{\\theta} | \\boldsymbol{y^{obs}}\\right) \\right) \\end{equation}\\] and Empirical Bayes estimates are evaluated for \\(\\widehat{\\boldsymbol{u}}\\), which are used model diagnostics and other model quantities, \\[\\begin{equation} \\widehat{\\boldsymbol{u}} = \\underset{\\boldsymbol{u}}{\\arg\\max} \\left( Pr\\left[ \\boldsymbol{y^{obs}}, \\boldsymbol{u}| \\widehat{\\boldsymbol{\\theta}}_{MLE} \\right] \\right) \\end{equation}\\] TODO Build a validate function to help catch users setting up parameters or data structures that will cause a crash once supplied to TMB. Self test change some parameter containers. In the ADMB model the often share parameters between male and females. Particularly for selectivity parameters. However TMB will not allow us to fix/map parameters across different arrays or vectors. This means we will want to join the male and female selectivity parameter objects into a single object so that we can share parameters between the sexes. Change array column casting from vector&lt;Type&gt;(array.col(i)) to array.col(i).vec() References "],["spatialmodeldescription.html", "Chapter 4 Spatial stock assessment model for Alaskan sablefish 4.1 Process equations 4.2 Data considerations", " Chapter 4 Spatial stock assessment model for Alaskan sablefish The latest published stock assessment (Goethel et al. 2021) is a sexually disaggregated integrated age-structured model. Let \\(\\boldsymbol{N_{r,y,s}}\\) denote a vector of ages in year \\(y\\) sex \\(s\\) in region \\(r\\) (the partition) i.e., \\(\\boldsymbol{N_{r,y,s}} = (N_{1,r,y,s}, N_{2,r,y,s}, \\dots, N_{a_+,r,y,s})^T\\). 4.1 Process equations Initialisation (\\(g\\left(.\\right)\\)) \\[\\begin{align*} N_{a,r,1,s} = \\begin{cases} R_r 0.5, &amp; a = a_1\\\\ N_{a - 1,r,1,s} \\exp\\bigg( - (M + F_{hist} * S^{LL}_{a,1})\\bigg), &amp; a_0 &lt; a &lt; a_+\\\\ \\exp( \\mu_r) \\exp-( a - 1) ( M + F_{hist} * S^{LL}_{a - 1,1})(1 - \\exp( M + F_{hist}* S^{LL}_{a - 1,1}))^{-1}, &amp; a = a_+ \\end{cases} \\end{align*}\\] The plus group Population dynamics (\\(f\\left(.\\right)\\)) 4.2 Data considerations Spatial resolution to explore. Figure 4.1: The finest spatial resolution that we are considering for Sablefish assessment Figure 4.2: Number of aged fish by sex, region and year. To consider collapse sex and age into a single dimension. See how I coded the sex ratio model (Chapter 5) To DO simulation test a spatial model with three areas no tagging data and equilibrium initial conditions References "],["sexratios.html", "Chapter 5 Sex ratios in age and length composition data 5.1 A simple simulation", " Chapter 5 Sex ratios in age and length composition data An immediate improvement in the current stock assessment (Chapter 3) relates to how sexually disaggregated compositional data are handled. Currently LF’s are separated by sex (needed for the different growths) and age compositional data are aggregated over both sexes. Although LFs are disaggregated by sex and should (in theory) be sufficient to estimate sex specific selectivities. It is not ideal to use LFs to estimate age-based selectivities because older cohorts “smush” into single modes and age information is lost. Before developing a spatially explicit model stock assessment model, I wanted to tidy some loose ends that may come back and bite me in the proverbial butt once we explore the spatially sex disaggregated stock assessment model in anger. These things are exponentially more easier to deal with in “simpler” models. My general intention is to drop length data when we have well sampled age data, currently they both go into the model together. For age composition data I want to structure the observations so that there is potential information on sex ratio. The current assessment can be given information on sex ratio for generating model predicted values which is similar to the approach in Ward et al. (2019). Howver, I personally think this should be dealt within the model. I am aware of two approaches for supplying observations that in theory should provide information on sex ratio. The first (“Approach 1”) was taken from Casal2 (Doonan et al. 2016). This treats sexed composition data for a year as a single proportion i.e., proportions across all ages and sexes sum to one for each year, \\[ \\boldsymbol{P}^k_{y} = \\frac{(C^k_{a,y,1},C^k_{a,y,2})}{\\sum_a \\sum_s C^k_{a,y,s}}, \\quad \\sum \\boldsymbol{P}^k_{y} = 1 \\] where, \\(C^k_{a,y,1}\\) is the catch at age (numbers) for males in year \\(y\\), age \\(a\\) and survey \\(k\\). \\(\\boldsymbol{P}^k_{y}\\) is a proportion vector that sums to one that covers both sexes and corresponding ages. The likelihood contribution for this approach follows \\[ \\boldsymbol{P}^k_{y} \\sim Multinomial(\\mathbb{E}[\\boldsymbol{P}^k_{y}], N^{eff, k}_{y}) \\ . \\] where, \\(N^{eff, k}_{y}\\) is the effective sample size for this survey and year. The second approach (“Approach 2”) is to treat composition for each sex seperately that is proportions at age or length for a sex will sum to one, but also provide a specific sex ratio observation over all ages or lengths as done in the New Zealand rock lobster stock assessment (Webber, Rudd, and Starr 2021). \\[ R^k_{y,s} = \\frac{\\sum_a C^k_{a,y,s}}{\\sum_a \\sum_s C^k_{a,y,s}}, \\quad \\sum_s R^k_{y,s} = 1 \\] and, \\[ P^k_{a, y,s} = \\frac{C^k_{a,y,s}}{\\sum_a C^k_{a,y,s}}, \\quad \\sum_a P^k_{a, y,s} = 1 \\ . \\] The likelihood assumptions for this model are, \\[ R^k_{y,s} \\sim Binomial(\\mathbb{E}[R^k_{y,s}], \\sum_s N^{eff, k}_{y,s}) \\] and, \\[ \\boldsymbol{P}^k_{y,s} \\sim Multinomial(\\mathbb{E}[\\boldsymbol{P}^k_{a, y,s}], N^{eff, k}_{y,s}) \\ . \\] where, \\(N^{eff, k}_{y,s}\\) is the effective sample size. 5.1 A simple simulation To explore the utility of these two approaches we conducted a simple simulation using a sexually disaggregated age-structured model (see Section 5.1). The Operating Model (OM) used in the simulation assumed a 50:50 sex ratio during the recruitment process however the OM did assume different growth and selectivity among the sexes. 5.1.1 Results In summary both approaches resulted in similar estimates in selectivities and SSBs. I prefer Approach 1 as it is a single observation compared with Approach 2 which has two observation types (need to consider how to avoid double counting of samples), but this simulation showed at least within the very small assumptions explored here they resulted in similar performance. This was all I was after in order to move forward to the spatial model. Another consideration about “Approach 2” is if the selectivity shape differs between sexes i.e., lower age at 50% retention. Then due to the sex ratio being derived by summing numbers over all ages, and the natural exponential decay in successive age-cohorts, selectivities that capture more younger fish will result in higher sex ratios. “Approach 1” Future research that was not considered in this simple simulation LF observations with sexual dimorphism in growth. A possible reason LF’s could be influencing assessment output is due to mis-specified growth à la Minte-Vera et al. (2017) Sample size between the two approaches Actual sex ratio skewed in the recruitment process, rather than just a selectivity effect which was of focus in the following simulation Look at the effect on \\(F\\)’s I only summarised SSB and selectivities Look at some residuals to see if that is a way to discredit some of these models ### Operating Model (OM) Parameters set.seed(123) n_sims = 5 bio_params = list( ages = 1:20, L_inf_m = 58, K_m = 0.133, t0_m = 0, L_inf_f = 62, K_f = 0.143, t0_f = 0, M = 0.15, a_m = 2.18e-9, ## tonnes b_m = 3.2, a_f = 2.08e-9, ## tonnes b_f = 3.3, m_a50 = 2.3, m_ato95 = 1.2, sigma = 0.6, h = 0.85, sigma_r = 0.6, R0 = 8234132, plus_group = 1 # 0 = No, 1 = Yes ) other_params = list( s_a50_m = 3.6, s_ato95_m = 2, s_a50_f = 4.6, s_ato95_f = 1.4, s_q = 0.2, s_alpha = 1, f_a50_m = 4.2, f_ato95_m = 1.17, f_a50_f = 4.7, f_ato95_f = 1.76, f_alpha = 1, ssb_prop_Z = 0.5, survey_prop_Z = 0.5, survey_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) fishery_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) survey_bio_cv = c(0.1) ) ages = bio_params$ages max_age = max(bio_params$ages) n_years = 30 years = (2020 - n_years + 1):2020 n_ages = length(ages) ## annual fishing mortality start_F = c(rlnorm(10, log(seq(from = 0.02, to = 0.1, length = 10)), 0.1), rlnorm(10, log(0.1), 0.1), rlnorm(10, log(0.07), 0.1)) recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r)) Figure 5.1: Examples of the two approaches for the survey (top row) and fishery (bottom row). The black and red line in approach 1 will sum to one, where as the black line and red line in approach will each sum to one. Approach 2 has an extra observation which is the proportion male (not shown). 5.1.2 Scenario 1 The first simulation assumed the OM had 50:50 males and female sex ratio at recruitment, and selectivities were as described in the above OM section. We simulated 100 data sets for each of the two approach’s for sexually disaggregated compositional data outlined in the introduction. These were then fitted to in two EM’s, where the EM’s differed in the approach they used. Both EM’s estimated a scalar on the female selectivity that allowed females to be more or less selected compared to males for both the fishery and survey. This was done be introducing an estimable \\(\\alpha\\) parameter into the selectivity. Males selectivities were constrained to have a max value = 1 using, \\[\\begin{equation} S^{male}_a = 1/(1+19^{(a_{50}-a)/a_{to95})}) \\tag{5.1} \\end{equation}\\] where as the female was \\[\\begin{equation} S^{female}_a = \\alpha/(1+19^{(a_{50}-a)/a_{to95})}) \\tag{5.2} \\end{equation}\\] Although this scenario assumed both male and female had the same max selectivity I wanted to see the effect of estimating this additional parameter. A third EM (EM3) was also explored, this structured compositional data using Approach 1 but fixed the female \\(\\alpha\\) = 1 in Equation (5.2). This is often the default approach. For scenario 1 this should be the best performing EM as it has the \\(\\alpha\\) set at the values of the OM. EM 1 (using approach 1) ## max gradient from 100 simualtions = 1.858256e-06 Figure 5.2: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 5.3: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 2 (using approach 2) ## max gradient from 100 simualtions = 5.591513e-11 Figure 5.4: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 5.5: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 3 (using approach 1 with female fixed at \\(\\alpha = 1\\)) ## max gradient from 100 simualtions = 6.455864e-07 Figure 5.6: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 5.7: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs 5.1.3 Scenario 2 The second scenario assumed sex ratio was 50:50 at recruitment and females were more selective than males to the fishery. This was done by setting \\(\\alpha\\) = 1.2 in Equation (5.2). true_pars$logit_f_alpha_f = logit_general(1.2, TMB_data$sel_alpha_bounds[1], TMB_data$sel_alpha_bounds[2]) EM 1 (using approach 1) ## max gradient from 100 simualtions = 6.54662e-07 Figure 5.8: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 5.9: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 2 (using approach 2) ## max gradient from 100 simualtions = 3.796794e-07 Figure 5.10: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 5.11: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs EM 3 (using approach 1 with female fixed at \\(\\alpha = 1\\)) ## max gradient from 100 simualtions = 2.748698e-07 Figure 5.12: Absolute SSBs, red line OM (truth), black lines are the estimated values form EMs Figure 5.13: Annual fishing mortality, red line OM (truth), black lines are the estimated values form EMs References "],["Fexplore.html", "Chapter 6 Fishing mortality approaches Set up a simulation Appendix - Hybrid approach", " Chapter 6 Fishing mortality approaches The current Alaskan sablefish stock assessment (Chapter 3) estimates annual fishing mortality values for each gear \\(g\\) denoted by \\(F^g_{y}\\). This parametersation poses to potential problems when considering future assessment models and spatial models. The first is, the number of parameters will increase as the number of gears increase. The fishery is currently going through a transformation whereby there is a switch from longline to pots. The second consideration is how to set this up in a spatially explicit model where catch have an added spatial dimension. There are two alternative approaches to the current approach which treat \\(F\\) as a derived quantity rather than an estimable parameter. The first is to use Newton Raphson method to solve for \\(F^g_{y}\\). This is the recommended approach in Stock Synthesis (Methot Jr and Wetzel 2013), termed the “hybrid” approach. The previous two methods assume the Baranov catch equation for mortality (Baranov 1918). An alternative is to assume Popes discrete formulation (Pope 1972) which uses exploitation proportions (sometimes called harvest rates or fishing pressure) and has a closed form solution. A good general overview on these methods can be found in Branch (2009). They describe and compared the continuous Baranov catch equation (Baranov 1918) with Pope’s discrete formulation (Pope 1972). Arguments for using the continuous case is that \\(M\\) and \\(F\\) occur simultaneously, also with the continuous case, \\(F\\) allows for multiple event encounters, this is assuming a fleet has the same selectivity and availability, that a fish that escapes one net can be caught in another. In contrast, the discrete formulation only allows a fish to be caught or escape from an instantaneous event. I have tried to summarize the benefits of the continuous equation in the following list, Allows the entire population to be caught (not sure this is that relevant) Allows simultaneous \\(M\\) and \\(F\\), no need to worry about order of operations. From a coding/practical perspective this is quite attractive. Once you have an F and M you can easily derive all mid-mortality quantities. Where as using a \\(U\\) approach you need save the population before and after to interpolate to derive mid-mortality quantities. The magnitude of \\(F\\) effects composition data, where as in the discrete case, composition is independent of the magniture of \\(U\\). Allows for multiple catch events of an individual Can fit to catch observations thus allows for uncertainty in catches. In practice the uncertainty/variance on catch is very small i.e., coeffecient of variations ranging from 0.01 to 0.1. This essentially states catch is observed with high confidence and in my opinion isn’t that much different to saying catch is known exactly. Note often this high precision on observed catch is needed in order to make the \\(F\\)’s identifiable. This high precision also muddies the “degrees of freedom” for the model. Although the \\(F\\)’s look like independent and free parameters they are heavily constrained by the assumptiosn on observed catch variance. The arguments for the discrete approximation is that there is an analytical solution for \\(U\\) and so is fast to calculate expected catch, where as \\(F\\) has to be either solved numerically or estimated as a free parameter (as mentioned earlier). Chris Francis’s wrote a response to this paper (Francis 2010) where he argues the discrete formulation does not preclude the multiple encounters and that only the data can truly tell us which catch equation is the best one to use. Need to make a point about how there may be Automatic differentiation issues with the \\(U\\) approach. Because there is an if(U &gt; 0.99) which can cause a fork in the chain rule which can equal a coding nightmare. The relationship between \\(F\\) (Instantaneous fishing mortality) and \\(U\\) exploitation rate for a simple scenario (single fishery) is illustrated in the following R code. exploitation_rates = seq(0,0.8,by = 0.02) ## calculate F given a U fishing_mortalites = -log(1 - exploitation_rates) ## back calculate U given a F # 1 - exp(-fishing_mortalites) The objective of this simulation Is the method efficient i.e., no loss of speed. Is the method numerically stable (No NaNs during optimization), particularly under high fishing pressure Figure 6.1: Illustration of how mortality is applied to an age cohort continuously over time (y). Set up a simulation To explore the above described methods a simple simulation was conducted using a simple age-structured stock assessment operating model. The model assumed 15 seperate fisheries all with a common selectivity. The purpose was to check that the derived methods were reliable (provided unbiased stock quantities) and that they are computationally efficient. bio_params = list( ages = 1:20, L_inf = 58, K = 0.133, t0 = 0, M = 0.15, a = 2.08e-9, ## tonnes b = 3.5, m_a50 = 6.3, m_ato95 = 1.2, sigma = 0.6, h = 0.85, sigma_r = 0.6, R0 = 8234132, plus_group = 1 # 0 = No, 1 = Yes ) other_params = list( s_a50 = 3.6, s_ato95 = 2, s_q = 0.2, f_a50 = 5, f_ato95 = 2, ssb_prop_Z = 0.5, survey_prop_Z = 0.5, survey_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) fishery_age_error = c(0.5, 0.4), ## sd, rho (ignored if iid) survey_bio_cv = c(0.1) ) ages = bio_params$ages max_age = max(bio_params$ages) n_years = 30 years = (2020 - n_years + 1):2020 n_ages = length(ages) ## annual fishing mortality start_F = c(rlnorm(10, log(seq(from = 0.05, to = 0.2, length = 10)), 0.1), rlnorm(10, log(0.13), 0.1), rlnorm(10, log(0.07), 0.1)) recruit_devs = log(rlnorm(n_years, -0.5 * bio_params$sigma_r * bio_params$sigma_r, bio_params$sigma_r)) length_at_age = vonbert(bio_params$ages, bio_params$K, bio_params$L_inf, bio_params$t0) fishery_ogive = logis(bio_params$ages, other_params$f_a50, other_params$f_ato95) survey_ogive = logis(bio_params$ages, other_params$s_a50, other_params$s_ato95) mat_age = logis(bio_params$ages, bio_params$m_a50, bio_params$m_ato95) weight_at_age = bio_params$a * length_at_age^bio_params$b ## observation temporal frequency survey_year_obs = years survey_ages = 1:20 fishery_year_obs = years fishery_ages = 1:20 ## simulate data set.seed(123) sim_data = ASM_obj$simulate(complete = T) ## Build AD TMB functions start_pars = ran_start_vals() est_model_est_F = MakeADFun(sim_data, true_pars, DLL= &quot;SimpleAgestructuredModelMultiFs&quot;, map = na_map, silent = T) sim_data$F_method = 1 sim_data$F_iterations = 4 est_model_hybrid_F = MakeADFun(sim_data, true_pars, DLL= &quot;SimpleAgestructuredModelMultiFs&quot;, map = na_map_hybrid, silent = T) ## optimise opt_model_est_F = nlminb(est_model_est_F$par, est_model_est_F$fn, est_model_est_F$gr, control = list(iter.max = 10000, eval.max = 10000)) opt_model_hybrid_F = nlminb(est_model_hybrid_F$par, est_model_hybrid_F$fn, est_model_hybrid_F$gr, control = list(iter.max = 10000, eval.max = 10000)) ## look at the number of iterations used to solve opt_model_hybrid_F$iterations ## [1] 187 opt_model_est_F$iterations ## [1] 697 ## get reports = rep_est_hybrid = est_model_hybrid_F$report(est_model_hybrid_F$env$last.par.best) rep_est_F = est_model_est_F$report(est_model_est_F$env$last.par.best) plot(TMB_data$years, rep_est_hybrid$ssb[-1], type = &quot;l&quot;, lwd = 3, xlab = &quot;Year&quot;, ylab = &quot;SSB&quot;, ylim = c(0,46000)) lines(TMB_data$years, rep_est_F$ssb[-1], type = &quot;l&quot;, lwd = 3, lty = 2, col = &quot;purple&quot;) lines(TMB_data$years, sim_data$ssb[-1], type = &quot;l&quot;, lwd = 4, lty = 3, col = &quot;red&quot;) legend(&quot;topright&quot;, col = c(&quot;black&quot;, &quot;purple&quot;, &quot;red&quot;), legend = c(&quot;Hybrid&quot;, &quot;Est F&quot;, &quot;OM&quot;), lwd = 3) est_F_bench = benchmark(obj = est_model_est_F, n = 1000) hybrid_F_bench = benchmark(obj = est_model_hybrid_F, n = 1000) est_F_bench ## elapsed ## template.likelihood 0.800 ## template.gradient 1.557 hybrid_F_bench ## elapsed ## template.likelihood 2.060 ## template.gradient 4.257 ben_est_F &lt;- benchmark(obj = est_model_est_F, n=20,expr=expression(do.call(&quot;optim&quot;,obj))) ben_hybrid_F &lt;- benchmark(obj = est_model_hybrid_F, n=20,expr=expression(do.call(&quot;optim&quot;,obj))) ben_est_F ## elapsed ## do.call(&quot;optim&quot;, obj) 14.077 ben_hybrid_F ## elapsed ## do.call(&quot;optim&quot;, obj) 11.661 These results have highlighted the following Both the Free \\(F\\) and hybrid estimate very similar model quantities i.e., SSB’s and F’s The Free \\(F\\) method is much faster on average for a single gradient calculation and function call compared to the hybrid method However, the hybrid method requires less iterations due to there being less estimated parameters. For this simulation where we assumed 15 fisheries both optimised in similar amounts of time Appendix - Hybrid approach The hybrid fishing mortality process uses the methods and algorithms applied in Stock Synthesis (Methot Jr and Wetzel 2013). The descriptions below are heavily based on the text describing this approach in the Appendix of (Methot Jr and Wetzel 2013). This process begins by calculating popes discrete approximation, and then converts this to Baranov fishing mortality coefficients. A tuning algorithm is then done to tune these coefficients to match input catch nearly exactly, rather than the full Baranov approach. Total mortality, denoted by \\(Z_{a,y,s,r}\\) for sex \\(s\\), region \\(r\\), age \\(a\\) and year \\(y\\) will hereby be denoted by \\(Z_{a,y,s}\\) i.e., drop the region index. This is because mortality rates are calculated independently (in isolation) among regions (NOTE consider parallelising this in the model). \\[\\begin{equation*} Z_{a,y,s} = M_{a,y,s} + \\sum\\limits_{f} S^g_{y,s} F^g_y \\end{equation*}\\] where, \\(M_{a,s}\\) is the natural mortality rate, \\(F^g_y\\) is fishing mortality and \\(S^g_{a,s}\\) is the selectivity. The hybrid fishing mortality method allows the \\(F\\) values to be “tuned” to match input catch nearly exactly, rather than estimating them as free model parameters. The process begins by calculating mid year exploitation rate using Pope’s approximation. This exploitation rate is then converted to an approximation of the Baranov continuous \\(F\\). The \\(F\\) values for all fisheries operating in that year and region are then tuned over a set number of iterations (f_iterations) to match the observed catch for each fishery with its corresponding \\(F\\). Differentiability is achieved by the use of Pope’s approximation to obtain the starting value for each \\(F\\) and then the use of a fixed number of tuning iterations, typically 4. Tests from Stock Synthesis have shown that modelling \\(F\\) as hybrid versus \\(F\\) as a parameter has trivial impact on the estimates of the variances of other model derived quantities. The hybrid method calculates the harvest rate using the Pope’s approximation then converts to an approximation of the corresponding F as: \\[\\begin{align} V^g_{y} &amp;= \\sum\\limits_s\\sum\\limits_a N_{a,y,s} \\exp\\left(-\\delta_t M_{a,s}\\right) \\nonumber \\\\ \\tilde{U}^g_{y} &amp;= \\frac{C^g_{y}}{V^g_{y} + 0.1 C^g_{y}}\\\\ j^g_{y} &amp;= \\left(1 + \\exp \\left(30 (\\tilde{U}^g_{y} - 0.95) \\right)\\right)^{-1}\\\\ U^g_{y} &amp;= j^g_{y} \\tilde{U}^g_{y} + 0.95 (1 - j^g_{y} )\\\\ \\tilde{F}^g_{y} &amp;= \\frac{-\\log\\left(1 - U^g_{y}\\right)}{\\delta_t} \\end{align}\\] where, \\(C^{g}_y\\) is the observed catch, \\(\\delta_t\\) is the duration of the period of observation within the year. In most situations where the entire catch has been observed in a time-step. This should be one. \\(V^g_{y}\\) is partway vulnerable biomass and \\(\\tilde{F}^g_{y}\\) is the initial \\(F\\). The formulation above is designed so that high exploitation rates (above 0.95) are converted into an F that corresponds to a harvest rate of close to 0.95, thus providing a more robust starting point for subsequent iterative adjustment of this F. The logistic joiner, \\(j\\), is used at other places in Stock Synthesis to link across discontinuities. The tuning algorithm begins by setting \\(F^g_{y} = \\tilde{F}^g_{y}\\) and repeating the following algorithm f_iteration times. \\[ \\widehat{C}_{a,y,s} = \\sum\\limits_g {F}^g_{y}S^g_{a,s} N_{a,y,s}\\bar{w}_{a,y,s} \\lambda^*_{a,y,s} \\] where, \\(\\lambda^*_{a,y,s}\\) denotes the survivorship and is calculated as: \\[\\begin{equation} \\lambda^*_{a,y,s} = \\frac{1 - \\exp\\left(-\\delta_t Z_{a,y,s} \\right) }{Z_{a,y,s}} \\tag{6.1} \\end{equation}\\] Total fishing mortality is then adjusted over several fixed number of iterations (typically four, but more in high F and multiple fishery situations). The first step is to calculate the ratio of the total observed catch over all fleets to the predicted total catch according to the current F estimates. This ratio provides an overall adjustment factor to bring the total mortality closer to what it will be after adjusting the individual \\(F\\) values. \\[ \\widehat{C}_{y} = \\sum\\limits_g \\sum\\limits_s\\sum\\limits_a {F}^g_{y}\\left(S^g_{a,s} N_{a,y,s}\\right) \\lambda^*_{a,y,s} \\] This is different from Equation A.1.25 in the Appendix of (Methot Jr and Wetzel 2013). They include \\(Z_{a,y,s}\\) in the denominator when describing \\({F}^g_{y}\\), I think this is a typo error because \\(Z_{a,y,s}\\) is already included in the denominator when calculating \\(\\lambda^*_{a,y,s}\\) (see Equation (6.1)). \\[ Z^{adj}_y = \\frac{\\sum\\limits_g C^g_{y}}{\\widehat{C}_{y}} \\] The total mortality if this adjuster was applied to all the Fs is then calculated: \\[ Z^*_{a,y,s} = M_{a,s} + Z^{adj}_y \\left(Z_{a,y,s} -M_{a,s} \\right) \\] \\[ \\lambda^*_{a,y,s} = \\frac{1 - \\exp\\left(-\\delta_t Z^*_{a,y,s} \\right) }{Z^*_{a,y,s}} \\] The adjusted mortality rate is used to calculate the total removals for each fishery, and then the new \\(F\\) estimate is calculated by the ratio of observed catch to total removals, with a constraint to prevent unreasonably high \\(F\\) calculations (max_f): \\[\\begin{align*} \\tilde{V}^g_{y} &amp;= \\sum\\limits_s\\sum\\limits_a \\left(N_{a,y,s} \\bar{w}_{a,y,s}S^g_{a,s} \\right)\\lambda^*_{a,y,s} \\\\ F^{g*}_{y} &amp;= \\frac{C^g_{y}}{\\tilde{V}^g_{y} + 0.0001}\\\\ j^{g*}_{y} &amp;= \\left(1 + \\exp \\left(30 (F^{g*}_{y} - 0.95 F_{max}) \\right)\\right)^{-1}\\\\ \\end{align*}\\] where, \\(F_{max}\\) is a user defined maximum fishing mortality f_max. The \\(F\\) at the end of each tuning iteration follows: \\[ F^g_{y} = j^{g*}_{y} F^{g*}_{y} + \\left(1 - j^{g*}_{y}\\right)F_{max} \\] After the tuning algorithm removals at age, and other derived quantities are recorded. The final total mortality is updated \\[ Z_{a,y,s} = M_{a,s} + \\sum\\limits_{g} S^g_{a,s} F^g_{y} \\] This process generates catch at age and sex for each year (and region) (\\(\\widehat{C}^g_{a,y,s}\\)) which can be accessed by process_removals observations. Numbers at age are calculated as \\[ \\widehat{C}^g_{a,y,s} = \\frac{F^g_{a,s,y}}{Z_{a,y,s}} N_{a,y,s} \\exp\\left(-Z_{a,y,s}\\right) \\] Total catch is the summed over all sexes and age \\[ \\widehat{C}^g_{y} = \\sum\\limits_s\\sum\\limits_a \\widehat{C}^g_{a,y,s} \\bar{w}_{a,y,s} \\] where \\(\\bar{w}_{a,y,s}\\) is the mean weight References "],["spatialInit.html", "Chapter 7 Initialising the plus group in spatial models", " Chapter 7 Initialising the plus group in spatial models In single area age-structured models, the plus age group is calculated using a solution to an infinite geometric series. This solution for an age-structured model is used to derive initial (equilibrium) state of the partition. The partition consists of a vector of numbers at age for each category denoted by \\(\\textbf{N}\\); \\[ \\textbf{N} = (N_1, N_2, ... , N_{a_+})^T \\] where \\(N_{a_+}\\) denotes the numbers in the plus group. The numbers at age for a single area population with no density-dependent processes is derived as, \\[ N_a = \\left\\{ \\begin{array}{lcl} R_0 &amp; \\mbox{for} &amp; a = 1 \\\\ R_0e^{-aM} &amp; \\mbox{for} &amp; 1 &lt; a &lt; a_+ \\\\ R_0e^{\\sum_{i = a_+}^\\infty-iM} &amp; \\mbox{for} &amp; a = a_+ \\end{array}\\right. \\] Initialization for ages \\(1 \\leq a &lt; a_+\\) is easy, all you need to do is iterate the model \\(a_+ - 1\\) times and the age classes will be populated with there respected initial numbers at age. However, for the plus group (\\(N_{a_+}\\)) the solution is needed. Although the plus group may start at let say 30 years old, it actually represents 30 and 31 and 32 up to some biological plausible value lets say 130, but mathematically can be thought of as \\(\\infty\\). The plus group is modeled for practical reasons and care should be given when choosing the cut-off maximum age. The plus group is an infinite geometric series that is defined by the common ratio \\(r_{a_+}\\). \\[\\begin{align} N_{a_+} &amp;= R_0e^{\\sum_{a = a_+}^\\infty-aM}\\\\ &amp;= R_0 \\frac{e^{M - a_+M}}{1 - e^{-M}} \\end{align}\\] M = 0.1 R0 = 4e6 plus_group_age = 30 N_age = R0 * exp(-M * 1:plus_group_age) ## numerically calculate it N_plus_group = tail(N_age, n = 1) for(i in 1:10000) { N_plus_group = N_plus_group * exp(-M) + tail(N_age, n = 1) * exp(-M) } N_plus_group ## [1] 1893568 ## using the geometric series calculation R0 * exp(-M - plus_group_age*M) / (1 - exp(-M)) ## [1] 1893568 The question becomes, how do we calculate this plus group when there is markovian movement as well as? This code shows how the same infinite geometric series solution works for the plus group with movement. Instead of using just natural mortality (\\(M\\)) you also need how much the plus group accumulates from the movement process. Let \\(c\\) denote the initial accumulation the plus group in a given region receives from ageing, natural mortality and movement. Then the plus group for that region can be \\[ N_{a+, r} = N_{a+ - 1, r} \\frac{1}{1 - c} \\] where, \\(N_{a+ - 1, r}\\) is the numbers at age for the second to last age cohort in the plus group. The following R code shows how this is equivalent to running the annual cycle for 1000 years. M = 0.1 R0 = 4e6 n_regions = 3 movement_matrix = matrix(0, nrow = n_regions, ncol = n_regions); movement_matrix[1,] = c(0.7, 0.2, 0.1) movement_matrix[2,] = c(0.1, 0.6, 0.3) movement_matrix[3,] = c(0.15, 0.05, 0.8) ## rows are &quot;from&quot; cols are &quot;to&quot; plus_group_age = 30 ## partition N_age = matrix(0, nrow = n_regions, ncol = plus_group_age) ## initialise with no movement initially N_age[1,] = R0 * exp(-M * 1:plus_group_age) ## N_age[2,] = R0 * exp(-M * 1:plus_group_age) ## N_age[3,] = R0 * exp(-M * 1:plus_group_age) ## ## apply an annual cycle 10000 times to see what the &quot;initial conditions should be&quot; N_next_year_age = N_age for(i in 1:1000) { ## recruitment N_next_year_age[,1] = R0 * exp(-M) ## ageing and mortality N_next_year_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) ## plus group N_next_year_age[,plus_group_age] = N_next_year_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) ## movement N_age = t(movement_matrix) %*% N_next_year_age } iterative_N_age = N_age plot(1:plus_group_age, N_age[3,], xlab = &quot;Age&quot;, ylab= &quot;Initial numbers&quot;, ylim = c(0,R0* 1.4), type = &quot;l&quot;, lwd = 3) lines(1:plus_group_age, N_age[2,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, N_age[1,], lwd = 3, col = &quot;blue&quot;, lty = 2) legend(&#39;topright&#39;, col = c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;), legend = c(&quot;Region 3&quot;, &quot;Region 2&quot;, &quot;Region 1&quot;), lwd = 3) N_age = matrix(0, nrow = n_regions, ncol = plus_group_age) update_N_age = N_age for(i in 1:(plus_group_age)) { # recruitment update_N_age[,1] = R0 * exp(-M) # ageing and mortality update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) # plus group update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) # movement N_age = t(movement_matrix) %*% update_N_age } ## calculate one more annual cycle # recruitment update_N_age[,1] = R0 * exp(-M) # ageing and mortality update_N_age[,2:plus_group_age] = N_age[,1:(plus_group_age - 1)] * exp(-M) # plus group update_N_age[,plus_group_age] = update_N_age[,plus_group_age] * exp(-M) + N_age[,plus_group_age] * exp(-M) # movement update_N_age = t(movement_matrix) %*% update_N_age ## approximate! c = update_N_age[,plus_group_age] / N_age[,plus_group_age] - 1 update_N_age[,plus_group_age] = N_age[,plus_group_age] * 1 / (1 - c) iterative_N_age[,plus_group_age] ## [1] 1758313 1217294 2705097 update_N_age[,plus_group_age] ## [1] 1758313 1217294 2705097 plot(1:plus_group_age, iterative_N_age[3,], xlab = &quot;Age&quot;, ylab= &quot;Initial numbers&quot;, ylim = c(0,R0* 1.4), type = &quot;l&quot;, lwd = 3) lines(1:plus_group_age, update_N_age[3,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, iterative_N_age[2,], lwd = 3, col = &quot;black&quot;, lty = 1) lines(1:plus_group_age, update_N_age[2,], lwd = 3, col = &quot;red&quot;, lty = 2) lines(1:plus_group_age, iterative_N_age[1,], lwd = 3, col = &quot;black&quot;, lty = 1) lines(1:plus_group_age, update_N_age[1,], lwd = 3, col = &quot;red&quot;, lty = 2) legend(&#39;topright&#39;, col = c(&quot;black&quot;,&quot;red&quot;), legend = c(&quot;Numerical&quot;, &quot;Analytical&quot;), lwd = 3, lty = c(1,2)) "],["spatialmodelInputs.html", "Chapter 8 Spatial model inputs Survey abundance Survey age-frequency", " Chapter 8 Spatial model inputs This chapter describes how raw age/length and catch data were utilised to derive assessment inputs for a myriad of spatially structured assessments. The chapter aims to standardize the methods so that we can easily re-work the data to be fit in an 1,2 or \\(n_r\\) area assessment model. Survey abundance I am thinking, when it comes to the real data application that we apply a geo-statistical model-based estimator. Currently the survey is a systematic design (Do the visit the same locations each year? obviously ignoring the AI BS switching), but they use a stratified survey estimator for the population mean and variance. I am wondering if this will over state the precision? Survey age-frequency "],["tagdata.html", "Chapter 9 Tagging data and studies 9.1 Integrating tagging observations in spatial age-structured models Releasing tags Tag recovery observations 9.2 Growth estimation using the Laslett–Eveson–Polacheck (LEP) method Simulation test the “LEP” method Next steps", " Chapter 9 Tagging data and studies Since 1972 there have been approximately 400 000 sablefish tagged in Alaska waters, of which over 38 500 have been recovered. Although there is extensive and long term tagging data, this information is not currently directly included in the stock assessment (Goethel et al. 2021). 9.1 Integrating tagging observations in spatial age-structured models This project intends to explore a range of methods for utilising tag-recovery observations in spatially disaggregated age-structured stock assessments. Releasing tags Tag release events involve releasing a tag-cohort at the beginning of a year within a specific area assumes tag cohort indexed by \\(k\\) has an implied year \\(y\\) and region \\(r\\) index. \\(\\boldsymbol{N}^k\\) is used to denote a vector of lengths or ages for tag-cohort \\(k\\). In general, only the length frequency is known at time of release for each tag-cohort. We explore two different methods for seeding tagged numbers at age for each tag-cohort within spatial age-structured models. The two methods are either do it internal or external. The internal method requires users to supply length frequency for each tag-cohort and the model will use the assumed growth assumptions to convert the lengths to ages. The external approach is to use an age-length key outside of the model to derive an age frequency that can be supplied to the model. A frequent assumption of age-structured tagging models in the literature (Maunder 1998; Vincent, Brenden, and Bence 2020) is that the age-frequency of each tag-cohort are known. Due to the fact that ageing is a fatal process, we assume they use an age-length key to convert lengths to ages. If the age-length key is representative of the vulnerable population at the time of tagging, then this method is expected to be have better computational performance. Factors to consider at time of release are; Gear method used to select releases, where releases occur, and time of releases. The internal method can attribute the correct age-distribution if the selectivity/availability by age is correct i.e. using the correct selectivity. Also, if growth is internally estimated within the assessment model, then the internal method may be prefered as to keep the growth assumptions consistent between LF observations and tagging observations. One consideration if the tag releases and recoveries are both length-based is the age-length transition assumptions. Due to age-structured modelling growth as length conditional on age. Moving individuals back and forwards through the age-length transition matrix (length \\(\\rightarrow\\) age \\(\\rightarrow\\) length) will cause “smearing” of length frequencies. This is demonstrated in Figures @(ref:addagelength) and @(ref:showagelengthtransition_problem), and needs to be considered when considering model fitted values for observations and corresponding likelihood assumptions. Given this phenomenon, it could be argued, that the external age-length key approach is better as it makes these assumptions explicit (more transparent). However, both methods will be affected by this growth transition phenomenon to one degree or another. Figure 9.1: An example of theoretical length at age, with overlapping length bins used to describe the effect of going back and fourth through the age-length transition matrix. ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. Figure 9.2: A visualisation of the effect of going back and forth through an age-length transition matrix. This can happen when tag releases and recaptures are input as length in an age-structured model. The model converts lengths to ages, then reconverts the age to length for observations. This is assuming the same age-length relationship in Figure 9.1 Internal method Age-structured stock assessment models contain growth models, which describe length conditioned on age. This requires assumptions on the distribution and associated parameters. The default is often the normal distribution with mean length at age denoted by \\(\\bar{l}_a\\) with standard deviation parameterised as a coefficient of variation (\\(\\sigma_a = cv*\\mu_a\\)). This information enables the model to derive a growth transition matrix \\(P_{l|a}\\). Given the lower and upper limits for each length bin denoted as \\(\\boldsymbol{b} = (b_1, b_2, \\dots, b_{max})&#39;\\), the probability of being in length bin \\(l\\) given age \\(a\\) \\[\\begin{equation} P_{l|a} = \\begin{cases} \\Phi(b_{l + 1}|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } l = 1\\\\ \\Phi(b_{l + 1}|\\mu_a,\\sigma_a) - \\Phi(b_l|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } 1 &lt; l &lt; n_l\\\\ 1 - \\Phi(b_{l}|\\mu_a,\\sigma_a)\\quad &amp;\\text{for } l = n_l \\end{cases} \\tag{3.6} \\end{equation}\\] where \\(\\Phi(x|\\mu,\\sigma)\\) is the cumulative normal (but could be generalised to any probability distribution). If growth varies by attributes such as sex, stock or region then this will need to be calculated for each growth model. In the SNA1 stock assessment each stock has a different growth curve and is denote as \\(P^s_{a|l}\\) At the point a tag cohort is released, the model can derive the length composition of the vulnerable population using the transition matrix derived in Equation (eq:agelengthtransition). Given the number of estimable parameters that govern the age-stricture at a point in time and growth model, an exploitation rate is calculated so that if there are not enough numbers in a length bin to be tagged, a penalty can be added to the objective function to dissuade the combination of parameters that generated this situation. Tag-release by length is a known quantity and so the model must allow for a minimum vulnerable length composition to that released. To enforce this a exploitation like rate by each length \\((u_l)\\) is calculated as follows, \\[\\begin{equation} u_l = \\frac{N^k_{l}}{\\sum_a}N_{y_k,a,r_k} P_{l|a} \\tag{9.1} \\end{equation}\\] During parameter estimation there are no constraints within the model to trial a set of parameters than will allow \\(u_l &gt; 1\\) i.e. more observed tag-releases than in the vulnerable population. To stop negative numbers at age \\(u_l\\) is set at a level less than 1 and a penalty added to the objective function to discourage parameters from allowing this condition. Finally tag-release at age is calculated as follows, \\[\\begin{equation} N^k_{a} = N_{y_k,a,r_k} P_{l|a} u_l \\tag{9.2} \\end{equation}\\] Once the tag cohort are created in the model it is assumed that tagged fish are exposed to the same dynamics as un-tagged fish. External method (Age-length key method) Once a tag-release event has occurred for tag group \\(k\\), the only known knowledge is the length distribution \\(N^k_l\\). Assuming there is an accessible forward age-length key which describes the proportion of ages for a given length bin \\(\\left(P_{a|l}\\right)\\) that is representative of the vulnerable population to tagging for the same area and time, then the “forward” or “classic” key method can be used Ailloud and Hoenig (2019). If tag-release coincide with a fishing season you could use fishery-dependent derived age length information, assuming the selectivity curves within a length bin are parallel. If only a subset of fish from each haul is released, it would be better to construct an age-length key from a representative sample of fish that were caught by not-tagged. This would be relevant for single vessel survey release events. \\[\\begin{equation} N^k_a = \\sum\\limits_{l = 1}P_{a|l}N^k_l \\end{equation}\\] where, \\(N^k_a\\) is used as an known input into the model with no error. Things to consider for tag release we don’t have much information regarding sex of tagged fish (36.5% of recovered tags have sex information). Does this lean towards the internal method? can allocate sex ratio based on vulnerable population which may be important, if there is quite a difference in sex disaggregated selectivities. Tag recovery observations There are tow types of tag-recovery observations that we will consider in this work, tag-release conditioned and tag-recapture conditioned. This conditioning relates to whether we relate recoveries to the release event or whether we only look at the recoveries relative to other recoveries within a year (Vincent, Brenden, and Bence 2020; McGarvey and Feenstra 2002). This conditioning relates more to the log-likelihood formulation rather than the model fitted values. We will also explore two different approaches regarding the scanned fish of which tag-recoveries are a subset. The first is recoveries were entirely from a fishery which requires some understanding or assumptions on reporting rates. The other method assumes scanned fish are known, which is the approach used in the Casal2 (Doonan et al. 2016) stock assessment program. This information can be recorded if the scanning is done either by observers who are recording LF’s for the catch or scientific/trained staff when shed sampling landed catch. Both these scanning approaches will require an assuming or information on detection rates. Things to consider for tag recovery data Years to retain tagged fish in the partition Reporting rates Scan detection rates Mixing time Tag loss Release conditioning vs recapture conditioning likelihood choice? 9.2 Growth estimation using the Laslett–Eveson–Polacheck (LEP) method Going to investigate the use of “Laslett–Eveson–Polacheck (LEP)” based on Laslett, Eveson, and Polacheck (2002) &amp; Eveson, Laslett, and Polacheck (2004) as described in Aires-da-Silva et al. (2015). The idea is to use a single growth model that fits to two observational data sets (ideally within the assessment, however we will start outside for now. When including it in the assessment you will also have LF data to help inform growth). The first will describe age-at-length data from direct ageing. The second will be length increment data from tagging experiments. Age-at-length growth model We start by using the Richards growth curve following Aires-da-Silva et al. (2015) (but this could be extended). The Richards growth formulation follows \\[\\begin{equation} \\bar{l}_{a} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a - a_0)\\}\\right)^{-p} \\tag{9.3} \\end{equation}\\] where, \\(\\bar{l}_{a}\\) is the mean length at age \\(a\\), \\(L_{\\infty}\\) is the asymptotic length, \\(K\\) is the growth coefficient and \\(p\\) is a shape parameter that is related to the ratio \\(\\bar{l}_{a} / L_{\\infty}\\) at the inflexion point. Tag recapture growth data Symbol Description \\(l_{1,i}\\) length of individual \\(i\\) at release \\(l_{2,i}\\) length of individual \\(i\\) at recapture \\(a_{1,i}\\) age of individual \\(i\\) at release. Denoted as \\(A\\) in Aires-da-Silva et al. (2015) \\(a_{2,i}\\) age of individual \\(i\\) at recapture \\(\\Delta_t\\) Time at liberty \\(\\Delta_t = a_{2,i} - a_{1,i}\\) Just one comment on notation!!! in most all the papers that use this method, they ignore the individual notation of \\(A\\). That is not an issue in general however it confuses me when they describe the prior on this. The sub-models for the release and recapture lengths follow, \\[\\begin{equation} l_{1,i} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a_{1,i} - a_0)\\}\\right)^{-p} \\tag{9.4} \\end{equation}\\] and, \\[\\begin{equation} l_{2,i} = L_{\\infty} \\left( 1 + \\frac{1}{p} \\exp \\{-K(a_{1,i} + \\Delta_t - a_0)\\}\\right)^{-p} \\tag{9.5} \\end{equation}\\] The above growth model assumes that we know the age at recovery \\(a_{2,i}\\). The problem we have is, we have 22 569 tag recoveries with length information but only a handful of these have been aged. This is dealt with by modelling \\(a_{1,i}\\) as a random effect i.e., \\(a_{1,i} \\sim LN \\left(\\mu, \\sigma^2\\right)\\). What confuses is me here is how to assign a hyper distribution like the one above for the random effect variables \\(a_{1,i}\\). \\(a_{1,i}\\) is expected to vary quite a bit because tagged fish at release have a broad length frequency and thus is expected to have a broad age at release? (ask someone about this because I may be misunderstanding something). Simulation test the “LEP” method ## going to use parameters from Aires-da-Silva et al. (2015) Table 1 integrated analysis L_inf = 200.8 k = 0.44 t_0 = 1.26 p = -4.27 cv = 0.15 ## cv of length around length at age ## selectivity paraemters sel_a50 = 1.3 sel_ato95 = 0.8 ## sample sizes for simulation n_sample_release = 1000 n_sample_recoveries = 1000 * 0.1 ## about the recovery rate from sablefish data n_sample_age_length = 1000 ## generate a pseudo age structure set.seed(123) R_0 = 200000 M = 0.29 ages = 1:20 n_ages = length(ages) #plot(ages, mean_length_at_age, type = &quot;l&quot;, lwd = 3, xlab = &quot;Age&quot;, ylab = &quot;Length (cm)&quot;) sel_at_age = logis(ages, sel_a50, sel_ato95) ## numbers at age N_age = vector(length = n_ages, &quot;numeric&quot;) for (age_ndx in 1:n_ages) N_age[age_ndx] = R_0 * exp(-ages[age_ndx] * M) * exp(rnorm(1,0,0.7)) N_age = N_age * sel_at_age ## vulnerable numbers at age plot(ages, N_age, ylab = &quot;Numbers&quot;, xlab = &quot;Age&quot;, main = &quot;Population age-structure&quot;, type = &quot;o&quot;) ## plot growth mean_length_at_age = richards_growth(ages, p, k, t_0, L_inf) ## randomly sample 1000 individuals with replacement for otolithing no ageing error!! ## individual_age_length_df = NULL for(i in 1:n_sample_age_length) { age_i = sample(1:n_ages, size = 1, prob = N_age) mean_length_i = richards_growth(age_i, p, k, t_0, L_inf) length_i = rnorm(1, mean_length_i, mean_length_i * cv) temp_df = data.frame(age = age_i, length = length_i) individual_age_length_df = rbind(individual_age_length_df, temp_df) } ## Simulate a tag-recapture experiment # releases release_ages = sample(1:n_ages, size = n_sample_release, prob = N_age, replace = T) release_mean_lengths = richards_growth(release_ages, p, k, t_0, L_inf) release_lengths = rnorm(n_sample_release, release_mean_lengths, release_mean_lengths * cv) individual_release_df = data.frame(release_age = release_ages, release_length = release_lengths, release_mean_length = release_mean_lengths) individual_release_df$fish_id = 1:nrow(individual_release_df) # recaptures sample uniformly without replacement fish_ndx = sample(1:nrow(individual_release_df), size = n_sample_recoveries, replace = F) individual_recovery_df = subset(individual_release_df, subset = individual_release_df$fish_id %in% fish_ndx) ## time-at liberty days randomly recovered on average between 100-600 days individual_recovery_df$time_at_liberty = rpois(n = n_sample_recoveries, lambda = runif(n_sample_recoveries,100,600)) individual_recovery_df$recovery_age = individual_recovery_df$release_age + individual_recovery_df$time_at_liberty/365 ## how to add the length increment between release and recovery? individual_recovery_df$recovery_mean_length = richards_growth(individual_recovery_df$recovery_age, p, k, t_0, L_inf) individual_recovery_df$recovery_mean_length_increment = with(individual_recovery_df, recovery_mean_length - release_mean_length) individual_recovery_df$recovery_length = with(individual_recovery_df, release_length + rlnorm(n_sample_recoveries, log(recovery_mean_length_increment), cv)) individual_recovery_df$growth_change = individual_recovery_df$recovery_length - individual_recovery_df$release_length ## visualise length at age samples ggplot(individual_age_length_df, aes(x = age, y = length)) + geom_point() + geom_line(data= data.frame(length = mean_length_at_age, age = ages), aes(x = age, y = length), col = &quot;red&quot;, linewidth = 1.2, inherit.aes = F) + labs(x = &quot;Age&quot;, y = &quot;Length&quot;) + ylim(0,NA) Assumptions in the above OM follow. \\[ l_{1,i} \\sim \\mathcal{N} \\left(\\bar{l}_{1,a}, \\sigma = \\bar{l}_{1,a} \\times cv\\right) \\] where the mean length at age release (\\(\\bar{l}_{1,a}\\)) follows the Richards growth curve defined in Equation (9.3). The age used to derive the mean length at age was a random sample with replacement from the population in shown in the earlier figure. Time at liberty was drawn from a Poisson distribution with a rate parameter randomly drawn from a uniform distribution between 100-600 days. The age at recovery \\(a_{2,i} = a_{1,i} + \\Delta_t\\). An approximation was made when calculating the length at recovery. The length increment (\\(l_{\\Delta_t}\\)) was simulated using a Log Normal distribution with the median set based on the difference between mean length at release age and mean length at recovery age. This was to ensure all recovered fish positively grew at a rate expected by the growth model (less than ideal but will do for now). \\[ l_{i,\\Delta_t} \\sim \\mathcal{LN} \\left(\\ln (\\bar{l}_{a_{2,i}} - \\bar{l}_{a_{1,i}}), \\sigma = cv\\right) \\] \\[ l_{2,i} = l_{1,i} + l_{i, \\Delta_t} \\] In theory we can now pass this data to our LEP model to back estimate growth parameters. setwd(file.path(&quot;TMB&quot;)) #sink(file = &quot;compile_output.txt&quot;) compile(file = &quot;LEPgrowth_model.cpp&quot;, flags = &quot;-Wignored-attributes -O3&quot;) #sink() dyn.load(dynlib(&quot;LEPgrowth_model&quot;)) #setwd(DIR$book) # data data = list() data$ages_from_age_length = individual_age_length_df$age data$lengths_from_age_length = individual_age_length_df$length data$lengths_at_release = individual_recovery_df$release_length data$lengths_at_recovery = individual_recovery_df$recovery_length data$time_at_liberty = individual_recovery_df$time_at_liberty / 365 data$ages_for_report = ages; data$p_bounds = c(-20, 20) data$t0_bounds = c(-6, 4) # parameters parameters = list() parameters$ln_cv_length_at_age = log(cv) parameters$ln_k = log(k) parameters$ln_L_inf = log(L_inf) parameters$logit_p = logit_general(p, data$p_bounds[1],data$p_bounds[2]) parameters$logit_t0 = logit_general(t_0, data$t0_bounds[1],data$t0_bounds[2]) parameters$ln_cv_length_release = log(0.1) parameters$ln_cv_length_recovery = log(0.1) parameters$ln_age_at_release = log(individual_recovery_df$release_age) parameters$ln_mu_age_release = log(3) parameters$ln_sd_age_release = log(1) obj_mixed_all &lt;- MakeADFun(data, parameters, random = &quot;ln_age_at_release&quot;, DLL=&quot;LEPgrowth_model&quot;) MLE_mixed_all = nlminb(start = obj_mixed_all$par, objective = obj_mixed_all$fn, gradient = obj_mixed_all$gr) MLE_mixed_all$convergence MLE_mixed_all_rep = obj_mixed_all$report(obj_mixed_all$env$last.par.best) MLE_mixed_all_sd_rep = sdreport(obj_mixed_all) plot(ages, MLE_mixed_all_rep$mean_length_at_age, type = &quot;l&quot;, lwd = 3, col = &quot;red&quot;, xlab = &quot;Age&quot;, ylab = &quot;Length (cm)&quot;, ylim = c(0, 240)) lines(ages, mean_length_at_age, col = &quot;blue&quot;, lty = 3, lwd = 3) legend(&#39;bottomright&#39;, legend = c(&quot;LEP obs error&quot;,&quot;True&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty = c(1,2), lwd = 3) Next steps Check sensitivity to the model to starting parameters Repeat with different sample sizes Repeat with a truncated age-structure for the age-length data using a selectivity Look at Sablefish data and see if the LEP approach can be used to it Explore alternative growth models i.e., Schnute (1981) References "],["refpoints.html", "Chapter 10 Review/summarise reference points", " Chapter 10 Review/summarise reference points Most of my experience with reference points are spawning biomass related i.e., \\(SSB_y/SSB_0\\). However, many of the reference points outside of New Zealand are \\(F\\) based i.e., \\(F_{35\\%}\\) which I don’t really understand. The purpose of this section is to define them mainly to help me understand, but also as a reference for when I forget in the future. Symbol Description/Calculation \\(SSB^{\\%B_0}_{y}\\) Percent \\(B_0\\) \\(= \\frac{SSB_y}{B_0}\\) \\(SPR\\) Spawner per recruit a measure/proxy of population fecundity \\(F_{35\\%spr}\\) \\(F\\) 35% The Fishing mortality that results in a 35% SPR \\(SPR_{msy}\\) SPR at MSY "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

--- 
title: "Alaskan sablefish research"
author: "C.Marsh"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
includes:
 before_body: preamble-mathjax.tex
#url: https:///r4Casal2/
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This Gitbook documents my post-doctoral research relating to Alaskan sablefish.
link-citations: yes

---

# Overview

This Gitbook documents my/our research for the Alaska sablefish (*Anoplopoma fimbria*). The objective is to develop and explore a spatially explicit stock assessment for Alaskan sablefish. However, there will be many other topics that I will likely only scratch the surface on. The following outlines the chapters in this document


## Future things to consider {-}
 
- How to reduce partition dimension when adding tag-release events
- When is the latest you can start the model? Currently the assessment model starts in 1960 because there is early survey and catch info along with some of the largest catches observed over the fishery. I want to explore starting the model at later period i.e., 1990's when start getting consistent survey data. This is a possible way to reduce the number of estimated parameters that have low information, however you may loose some information on production if you miss some of the periods with the largest catches.



## chapter overview  {-}
- Chapter \@ref(objectives) is a list of objectives that we have set or accomplished during this research project. Some of our research cannot be in this book/repo due to the confidential nature of the data. This checklist should include tasks for the wider research

- Chapter \@ref(modeldescription) documents the current stock assessment model and assumptions (work in progress). This first is the first step of the project and helps me get a grasp of data and dynamics that are important

- Chapter \@ref(spatialmodeldescription) documents the spatial stock assessment model used to explore spatially explicit models.


- Chapter \@ref(sexratios) explores how to include sex disaggregated composition observations that can include sex ratio information. It conducts a simple simulation to investigate two different approaches than what is currently done in the assessment


- Chapter \@ref(Fexplore) explores how to parameterise fishing mortality. The current approach is to estimate an annual fishing mortality parameter for each gear. I feel slightly uncomfortable about this approach moving towards a spatial model as the number of estimated parameters will explode. This chapter looks at two alternative approaches that either derive fishing mortality estimates using a Newton Raphson solver which is borrowed from the Stock Synthesis "hybrid" approach [@methot2013stock] and Pope's discrete approach [@pope1972investigation] which uses exploitation rates. All of these methods have been applied in the literature for decades. The aim of this chapter is to do a simulation and make sure the considered approaches are efficient and numerically stability under a range of fishing patterns


- Chapter \@ref(spatialInit) explores how to calculate the plus group in spatially explicit age-structured models that assume markovian movement.



- Chapter \@ref(tagdata) describes the tagging data and how it can be used within a spatial model but also used in a panmictic model for informing population dynamics such as growth.






```{r install_packages, results = 'hide', message=FALSE, warning=FALSE}
library(TMB)
#library(stockassessmenthelper)
library(ggplot2)
library(dplyr)
library(reshape2)
library(gridExtra)
library(RColorBrewer)
```

```{r auxillary_functions,echo = F,eval =T, results = 'hide', message=FALSE, warning=FALSE}
#' vonbert applies the Von Bertalanffy age-length relationship
#' @param age take an age look in globe scope for the rest of parameters
#' @param L_inf asympototic length
#' @param K growth rate parameter
#' @param t0 age for length = 0
#' @export
#' @return mean length at age
vonbert <- function(age,K,L_inf,t0) {
  return(L_inf * (1-exp(-K*(age -t0))))
}
#'
#' richards_growth provides the mean length at a give age
#' @param age true age
#' @param p is the shape parameter
#' @param k is the growth coefficient
#' @param l_inf is the asymptotic length
#' @param t_0 corresponds to an inflexion point on the curve.
#' @return mean length at age
#'
richards_growth = function(age, p, k, t_0, l_inf) {
  mean_length = l_inf * (1 + 1 / p * exp(-k * (age - t_0)))^-p
}
#' create a function for simulating starting values for model robustness
#' @param n <integer> number of draws you want
#' @param dist <string> distribution to use to draw starting values, allowed "unif", "norm" 
#' @param LB <scalar> Lower bound of starting value, shouldn't use lower bound of parameter
#' @param UB <scalar> Upper Bound of starting balues.
#' @param dist_pars <vector> has distributional parameters, i.e for norm = c(mu, sigma)
#' @return vector of starting values
ran_start = function(n = 100, dist = "unif", LB = -Inf, UB = Inf, dist_pars = NULL) {
  if (!any(dist %in% c("unif", "norm")))
    stop("parameter 'dist', needs to be either unif or norm")
  start_vals = vector();
  if (dist == "unif") {
    start_vals = runif(n, LB, UB)
  } else if (dist == "norm") {
    start_vals = rnorm(n, dist_pars[1],dist_pars[2])
    start_vals[start_vals < LB] = LB
    start_vals[start_vals > UB] = UB
    
  } else {
    stop("something went wrong")
  }
  return(start_vals)
}

#' Logistic selectivity
#' @export
logis<- function(X,a50,a95)
{
  1/(1+19^((a50-X)/a95)) 
}

#' bound_unit constrains Y from -inf -> inf to be between -1 -> 1 
#' @param Y scalar range [-inf, inf]
#' @return X to be between [-1,1] 
bound_unit = function(Y) {
  return(Y / sqrt(1.0 + Y * Y))
}

#' inv_bound_unit constrains Y from -inf -> inf to be between -1 -> 1 
#' @param X scalar range [-1,1] 
#' @return Y to be between [-inf, inf]
inv_bound_unit = function(X) {
  return(sqrt((X*X) / (1 - X*X)) * ifelse(X < 0, -1, 1))
}
#' logit bounds X which is between 0-1 to -inf -> inf based on the logit transformation
#' equivalent to qlogis(X)
#' @param X scalar range [0,1]
#' @return Y to be between [-inf, inf]
logit = function(X) {
  log(X / (1 - X)) 
}
#' invlogit Inverse logit transformation, equivalent to plogis(Y)
#' @param Y scalar between [-inf, inf] 
#' @return X between [0,1]
invlogit<- function(Y) {
  1/(1 + exp(-Y))
}
#' logit_general bounds X which is between [lb,ub] to -inf -> inf based on the logit transformation
#' @param X scalar range [lb,ub]
#' @param ub upper bound for X
#' @param lb lower bound for X
#' @return Y to be between [-inf, inf]
logit_general = function(X, lb, ub) {
  X1 = (X - lb) / (ub - lb)
  log(X1/(1 - X1))
}


simplex <- function (xk, sum_to_one = TRUE)  {
  zk = vector()
  if (!sum_to_one) {
    xk = xk/sum(xk)
  }
  else {
    if (abs(sum(xk) - 1) > 0.001) 
      stop("xk needs to sum = 1, otherwise speify sum_to_one = TRUE")
  }
  K = length(xk)
  zk[1] = xk[1]/(1)
  for (k in 2:(K - 1)) {
    zk[k] = xk[k]/(1 - sum(xk[1:(k - 1)]))
  }
  yk = stats::qlogis(zk) - log(1/(K - 1:(K - 1)))
  return(yk)
}
restoresimplex <- function (yk) {
  K = length(yk) + 1
  zk = stats::plogis(yk + log(1/(K - 1:(K - 1))))
  xk = vector()
  xk[1] = zk[1]
  for (k in 2:(K - 1)) {
    xk[k] = (1 - sum(xk[1:(k - 1)])) * zk[k]
  }
  xk[K] = 1 - sum(xk)
  return(xk)
}


#' invlogit_general bounds X which is between -inf -> inf to [lb,ub] based on the logit transformation
#' @param Y scalar range [-inf, inf]
#' @param ub upper bound for X
#' @param lb lower bound for X
#' @return X to be between [lb,ub]
invlogit_general = function(Y, lb, ub) {
  Y1 = 1 / (1 + exp(-Y))
  lb + (ub - lb)*Y1
}
#' fix_pars 
#' @author C.Marsh
#' @description TMB helper function this function returns a list of factors used in the map argument of the MakeADFun function
#' values with <NA> will not be estimated.
#' @param par_list a named list that you give to the par argument in the MakeADFun
#' @param pars_to_exclude a vector of strings with names of parameters you want to FIX in the objective object.
#' @param vec_elements_to_exclude a named list (names %in% pars_to_exclude) with number of elements = length(vec_pars_to_adjust). each list element 
#' @param array_elements_to_exclude a named list (names %in% pars_to_exclude) with a matrix each row corresponds to an element with the first column being the array row index and second column being the array column index to fix

#' contains a vector of elements that we want to exclude from estimation.
#' @return a list of factors used in the MakeADFun function
#' @export
fix_pars <- function(par_list, pars_to_exclude, vec_elements_to_exclude = NULL, array_elements_to_exclude = NULL) {
  if (!any(pars_to_exclude %in% names(par_list))) {
    stop(paste0("The parameters ", paste(pars_to_exclude[!pars_to_exclude %in% names(par_list)],collapse = " ")," in exclusion parameters could not be found in the 'par_list', please sort this out"))
  }
  pars = names(par_list)
  mapped_pars = list();
  if (!is.null(vec_elements_to_exclude)) {
    if (!all(names(vec_elements_to_exclude) %in% pars_to_exclude))
      stop("parameters names in vec_elements_to_exclude, need to also be in pars_to_exclude")
  }
  if (!is.null(array_elements_to_exclude)) {
    if (!all(names(array_elements_to_exclude) %in% pars_to_exclude))
      stop("parameters names in array_elements_to_exclude, need to also be in pars_to_exclude")
  }
  param_factor = 1;
  for(i in 1:length(pars)) {
    if (pars[i] %in% pars_to_exclude) {
      params_in_this_par = par_list[[pars[i]]];
      if (pars[i] %in% names(vec_elements_to_exclude)) {
        include_element_index = c(1:length(params_in_this_par))[-vec_elements_to_exclude[[pars[i]]]]
        params_vals = factor(rep(NA, length(params_in_this_par)), levels = factor(param_factor:(param_factor + length(include_element_index) - 1)))
        params_vals[include_element_index] = factor(param_factor:(param_factor + length(include_element_index) - 1))#, levels = factor(include_element_index))
        param_factor = param_factor + length(include_element_index)
        mapped_pars[[pars[i]]] = params_vals;
      } else if(pars[i] %in% names(array_elements_to_exclude)) {
        elements_to_drop = array_elements_to_exclude[[pars[i]]]
        mapped_vector = rep(NA, length(params_in_this_par))
        first_param_factor = param_factor
        vec_ndx = 1;
        ## TMB converts arrays to vectors down columns (not by rows)
        for(col_ndx in 1:ncol(params_in_this_par)) {
          for(row_ndx in 1:nrow(params_in_this_par)) {
            ## check if we need to drop this value
            for(drop_ndx in 1:nrow(elements_to_drop)) {
              if(!((row_ndx == elements_to_drop[drop_ndx, 1]) &  (col_ndx == elements_to_drop[drop_ndx, 2]))) {
                mapped_vector[vec_ndx] = param_factor
                param_factor = param_factor + 1
              }
            }
            vec_ndx = vec_ndx + 1;
          }
        }
        mapped_vector = factor(mapped_vector, levels = first_param_factor:max(mapped_vector, na.rm = T))
        mapped_pars[[pars[i]]] = mapped_vector;
      } else {
        ## exclude entire parameters
        mapped_pars[[pars[i]]] = rep(factor(NA),length(params_in_this_par));
        n_params_to_exclude = nrow(vec_elements_to_exclude[[pars[i]]])
      }
    } else {
      params_in_this_par = par_list[[pars[i]]];
      params_vals = factor(param_factor:(param_factor + length(params_in_this_par) - 1))
      param_factor = param_factor + length(params_in_this_par)
      mapped_pars[[pars[i]]] = params_vals
    }
  }
  return(mapped_pars);
}


#' set_pars_to_be_the_same 
#' @author C.Marsh
#' @description TMB helper function this function returns a list of factors used in the map argument of the MakeADFun function
#' values with the same factor level will be estimated as the same value
#' @details TMB will estimate parameters based on the index specified in by the map argument in MakeADFun
#' so parameters with the same factor in map will be estimated as the same value.
#' NOTE: this only works for within the same parameter. It doesn't work across parameters.
#' @param par_list a named list that you give to the par argument in the MakeADFun
#' @param map a list of factors that has been created by fix_pars(). parameters that you want fixed to other values should be set to <NA> in this object
#' @param base_parameters a named list (names) each element contains one index that will be used to set the value in copy_parameters
#' @param copy_parameters a named list (names) each element contains one index that will be set equal to the corresponding base_parameters
#' @return a list of factors used in the MakeADFun function
#' @export
set_pars_to_be_the_same <- function(par_list, map, base_parameters, copy_parameters) {
  if(length(base_parameters) != length(copy_parameters))
    stop("the number of elements in base_parameters must be the same as copy_parameters. Please check these")
  if(!class(map) == "list")
    stop("map needs to be a list")
  if(!any(names(base_parameters) %in% names(par_list)))
    stop(!paste0("The parameters in base_parameters ", paste(names(base_parameters)[!names(base_parameters) %in% names(par_list)],collapse = " ")," could not be found in the 'par_list', please sort this out"))
  if(!any(names(copy_parameters) %in% names(par_list)))
    stop(!paste0("The parameters in copy_parameters ", paste(names(copy_parameters)[!names(copy_parameters) %in% names(par_list)],collapse = " ")," could not be found in the 'par_list', please sort this out"))
  pars = names(par_list)
  
  for(i in 1:length(base_parameters)) {
    if(is.na(map[[names(base_parameters)[i]]][base_parameters[[i]]]))
      stop(paste0("In base_parameters for parameter ", names(base_parameters)[i], " at ndx ", base_parameters[[i]], ". We found an NA. This cannot be, please check"))
    if(!is.na(map[[names(copy_parameters)[i]]][copy_parameters[[i]]]))
      stop(paste0("In copy_parameters for parameter ", names(base_parameters)[i], " at ndx ", base_parameters[[i]], ". Was not an NA. This must be an NA value in 'map', please check"))

    temp_copy_parm = map[[names(copy_parameters)[i]]]
    temp_copy_parm = as.numeric(as.character(temp_copy_parm))
    base_value = as.numeric(as.character(map[[names(base_parameters)[i]]][base_parameters[[i]]]))
    temp_copy_parm[copy_parameters[[i]]] = base_value
    lvls = unique(temp_copy_parm[!is.na(temp_copy_parm)])
    map[[names(copy_parameters)[i]]] = factor(temp_copy_parm, levels = lvls)
  }
  
  return(map);
}

#' get_list_obj gets names objects out of simulated TMB reports.
#' @param est_ls a list of length n_sims
#' @param object_label a charachter that points to a name of an element of the TMB report
#' @return a matrix 

get_list_obj = function(est_ls, object_label) {
  val = Reduce(rbind, lapply(X = est_ls, FUN = function(x){
    temp = x[[object_label]]
    temp
    }))
  elements = nrow(val) / length(est_ls)
  
  cbind(sort(rep(1:length(est_ls), elements)), val)
}

```

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```
